<!DOCTYPE html><html lang="en" data-mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="[논문 리뷰] MMDetection: Open MMLab Detection Toolbox and Benchmark" /><meta name="author" content="JaeHo-YooN" /><meta property="og:locale" content="en" /><meta name="description" content="MMDetection에 대한 논문을 리뷰한 내용입니다. 혼자 공부하기 위해 정리한 내용으로 이해가 안되는 부분들이 많을 거라 생각됩니다. 참고용으로만 봐주세요." /><meta property="og:description" content="MMDetection에 대한 논문을 리뷰한 내용입니다. 혼자 공부하기 위해 정리한 내용으로 이해가 안되는 부분들이 많을 거라 생각됩니다. 참고용으로만 봐주세요." /><link rel="canonical" href="https://dkssud8150.github.io/posts/MMdetection/" /><meta property="og:url" content="https://dkssud8150.github.io/posts/MMdetection/" /><meta property="og:site_name" content="JaeHo Yoon" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-12-22T13:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="[논문 리뷰] MMDetection: Open MMLab Detection Toolbox and Benchmark" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@JaeHo-YooN" /><meta name="google-site-verification" content="znvuGsQGYxMZPBslC4XG6doCYao6Y-fWibfGlcaMHH8" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"JaeHo-YooN"},"dateModified":"2022-04-29T19:05:05+09:00","datePublished":"2021-12-22T13:00:00+09:00","description":"MMDetection에 대한 논문을 리뷰한 내용입니다. 혼자 공부하기 위해 정리한 내용으로 이해가 안되는 부분들이 많을 거라 생각됩니다. 참고용으로만 봐주세요.","headline":"[논문 리뷰] MMDetection: Open MMLab Detection Toolbox and Benchmark","mainEntityOfPage":{"@type":"WebPage","@id":"https://dkssud8150.github.io/posts/MMdetection/"},"url":"https://dkssud8150.github.io/posts/MMdetection/"}</script><title>[논문 리뷰] MMDetection: Open MMLab Detection Toolbox and Benchmark | JaeHo Yoon</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="JaeHo Yoon"><meta name="application-name" content="JaeHo Yoon"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/shin_chan.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">JaeHo Yoon</a></div><div class="site-subtitle font-italic">Mamba Mentality</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fab fa-angellist ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/dkssud8150" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['hoya58150','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="https://www.notion.so/18490713817d403696812c57d0abe730" aria-label="notion" target="_blank" rel="noopener"> <i class="fab fa-battle-net"></i> </a> <a href="https://www.linkedin.com/in/jaeho-yoon-90b62b230" aria-label="linkedin" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href="https://www.instagram.com/jai_ho8150/" aria-label="instagram" target="_blank" rel="noopener"> <i class="fab fa-instagram"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>[논문 리뷰] MMDetection: Open MMLab Detection Toolbox and Benchmark</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>[논문 리뷰] MMDetection: Open MMLab Detection Toolbox and Benchmark</h1><div class="post-meta text-muted"><div> By <em> <a href="https://github.com/dkssud8150">JaeHo-YooN</a> </em></div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6611243953442169" crossorigin="anonymous"></script><div class="d-flex"><div> <span> Posted <em class="timeago" date="2021-12-22 13:00:00 +0900" data-toggle="tooltip" data-placement="bottom" title="Wed, Dec 22, 2021, 1:00 PM +0900" >Dec 22, 2021</em> </span> <span> Updated <em class="timeago" date="2022-04-29 19:05:05 +0900 " data-toggle="tooltip" data-placement="bottom" title="Fri, Apr 29, 2022, 7:05 PM +0900" >Apr 29, 2022</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2365 words"> <em>13 min</em> read</span></div></div></div><div class="post-content"><p>MMDetection에 대한 논문을 리뷰한 내용입니다. 혼자 공부하기 위해 정리한 내용으로 이해가 안되는 부분들이 많을 거라 생각됩니다. 참고용으로만 봐주세요.</p><h1 id="abstract">Abstract</h1><p>mmdetection은 object detection과 instance segmentation을 다루는 유명하고 다양한 모델을 하나의 toolbox로 구현한 일종의 플랫폼이다. MMDetection은 training and inference 코드뿐만 아니라 200개 이상의 network 모델 weight를 제공한다. 코드는 pytorch를 사용하였다고 한다.</p><h1 id="1-introduction">1. Introduction</h1><p>주요 특징으로는</p><ol><li>Modular design: 모델이 모듈화되어 있어 사용자화를 쉽게 할 수 있다.<li>Support of multiple frameworks out of box: 인기있는 여러 프레임워크를 지원한다.<li>High efficiency: 모든 BBox와 mask 연산은 GPU에서 동작한다. 그리고, training 속도가 다른 detectron, maskrcnn-benchmark, simpleDet 보다 더 빠르다.<li>State of the art: 2018 COCO detection challenge에서 우승한 MMDet team의 코드를 토대로 만들었다.</ol><h1 id="2-supported-frameworks">2. Supported Frameworks</h1><p>MMDetection 안에 구성된 모델로는</p><ul><li>2.1 Single-stage Methods<ul><li>SSD(2015)<li>RetinaNet(2017): focal loss를 통한 고성능 단일 detector<li>GHM(2019): gradient harmonizing 메커니즘을 통한 단일 detector<li>FCOS(2019): fully convolutional anchor-free detector<li>FSAF(2019): feature selective anchor-free module detector</ul><li>2.2 Two-stage Methods<ul><li>Fast R-CNN(2015)<li>Faster R-CNN(2015)<li>R-FCN(2016): fully convolutional detector<li>Mask R-CNN(2017): instance segmentation method<li>Grid R-CNN(2018) grid를 통한 위치화 메커니즘을 통한 segmentation<li>Mask Scoring R-CNN(2019): IOU를 예측함으로써 Mask R-CNN 개선<li>Double-Head R-CNN(2019)</ul><li>2.3 Multi-stage Methods<ul><li>Cascade R-CNN(2017)<li>Hybrid Task Cascade(2019): multi branch를 통한 가장 높은 성능을 보인 모델</ul><li>2.4 General Modules and Methods<ul><li>Mixed Precision Training(2018): 반정밀 floating point 숫자를 이용해 훈련<li>Soft NMS(2017)<li>OHEM(2016): online hard sampling<li>DCN(2017): 변형 가능한 convolution 과 ROI Pooling<li>DCNv2(2018):<li>Train from Scratch(2018): imageNet 대신 random initialization<li>ScratchDet(2018):<li>M2Det(2018): 더 효과적인 feature pyramid를 위한 새로운 feature pyramid<li>GCNet(2019):<li>Generalized Attention(2019)<li>SyncBN<li>Group Normalization(2018)<li>Weight Standardization(2019)<li>HRNet(2019): 고해상도 이미지를 학습하는 데 집중한 새로운 backbone<li>Guided Anchoring(2019)<li>Libra R-CNN(2019)</ul></ul><h1 id="3-architecture">3. Architecture</h1><h2 id="31-model-representation">3.1 Model Representation <a href="#31-model-representation" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p><strong>backbone</strong>: 입력 이미지를 특징맵으로 변형시켜주는 부분, ResNet50과 같이 FC Layer(fully connected layer)가 없는 형태를 가짐</p><p><strong>Neck</strong>: backbone과 head를 연결해주는 부분으로, backbone을 통해 생성된 특징맵을 정제하고 재구성해준다. 예를 들면 FPN(Feature Pyramid Network)와 같다.</p><p><strong>DenseHead(AnchorHead/AnchorFreeHead)</strong>: anchorHead와 anchorFreeHead를 포함한 특징맵의 밀도 높은 위치에서 작동하는 요소</p><p><strong>RoIExtractor</strong>: 단일 또는 다중 특징맵으로부터 RoIPooling과 같은 연산을 통해 RoI-wise 특징들을 추출, 예를 들어 특정 수준의 특징 피라미드에 대한 RoI 특징은 singleRoIExtractor이 된다.</p><p><strong>RoIHead(BBoxHead/MaskHead)</strong>: RoI 특징을 입력으로 받고, RoI-wise한 task-specific 예측을 하는 부분이다. bounding box 분류/regression, mask 예측과 같다.</p><p>위의 과정들을 그림으로 나타내면 아래와 같다.</p><p><img data-src="/assets/img/mmdetection/MMDetection_figure1.png" width="100%" data-proofer-ignore></p><p><br /></p><h2 id="32-training-pipeline">3.2 Training Pipeline <a href="#32-training-pipeline" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>최소한의 파이프라인만 정의하고 나머지는 hooking 메커니즘을 통해 정의되도록 했다. 후킹 중에서 forward hook은 모델의 파라미터(weights)나 특징맵(feature map)을 신호 전달 중간에 가로채는 기법이라 할 수 있다. backward hook은 gradient exploding을 방지하기 위해 활용한다.</p><p>또한, before_run, before_train_epoch, after_train_epoch 등의 다양한 시점을 정의하고 관찰했다.</p><p><img data-src="/assets/img/mmdetection/MMDetection_figure2.png" width="100%" data-proofer-ignore></p><p>저자는 figure 2와 같이 다양한 시점으로 나누고, 사용자가 원하는대로 hook 설정을 변경할 수 있도록 했다. 이 figure2는 학습 과정이고, validation 과정은 평가 후크를 사용해 각 epoch 이후의 성능을 테스트 했기 때문에 보여주지 않았다. 아마 학습 과정과 비슷할 것이다.</p><p><br /></p><h1 id="4-benchmarks">4. Benchmarks</h1><h2 id="41-experimental-setting">4.1 Experimental Setting <a href="#41-experimental-setting" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p><strong>dataset</strong>: MS COCO 2017 데이터셋을 사용했다.</p><p><strong>Implementation Details</strong>: 명시하지 않을 경우 default 값을 사용한다.</p><ol><li>image는 비율 변화 없이 최대 1333x800으로 resize한다.<li>학습에서는 총 16개의 batch size의 8개의 V100 GPU와 추론에서는 단일 V100 GPU를 사용했다.<li>학습 과정은 detectron과 같다. 1x, 2x는 12epochs, 24epochs이고, 20e는 cascade 모델에서의 20 epochs를 의미한다.</ol><p><strong>Evaluation metrics</strong>: 0.5~0.95의 여러 IoU의 multiple IoU threshold 를 적용할 수 있는 COCO dataset에 대한 표준 평가 metrics를 선택한다. region proposal network(RPN)의 결과는 AR(Average Recall)로 평가했고, detection 결과는 mAP로 평가했다.</p><h2 id="42-benchmarking-results">4.2 Benchmarking Results <a href="#42-benchmarking-results" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p><strong>Main results</strong>: SSD, RetinaNet, Faster R-CNN, Mask R-CNN의 method를 사용했고, ResNet-50, ResNet-101, ResNet-101-32x4d와 같이 다양한 backbone을 사용했다. method간의 bbox/mask AP에 대한 추론 속도를 figure 3를 통해 확인할 수 있다.</p><p><strong>Comparison with other codebases</strong>: Detectron, maskrcnn-benchmark, SimpleDet 등을 비교했다. 결과는 table 2에서 확인가능하다.</p><p><img data-src="/assets/img/mmdetection/MMDetection_figure3.png" width="50%" data-proofer-ignore><img data-src="/assets/img/mmdetection/MMDetection_figure4.png" width="50%" data-proofer-ignore></p><p>위의 결과처럼 hybrid task cascade 모델이 가장 성능이 좋았다.</p><p><img data-src="/assets/img/mmdetection/MMDetection_table2.png" width="50%" data-proofer-ignore></p><p><br /></p><h1 id="5-extensive-studies">5. Extensive Studies</h1><h2 id="51-regression-losses">5.1 Regression Losses <a href="#51-regression-losses" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-src="/assets/img/mmdetection/MMDetection_table5.png" width="100%" data-proofer-ignore></p><p>여러 가지의 loss를 적용해보았으며, loss weight를 증가시켜가며 성능을 비교했다. 간단하게 Smooth L1 Loss의 loss weight를 증가시켜봄으로써 0.5% 정도 향상되었다.</p><p><br /></p><h2 id="52-normalization-layers">5.2 Normalization Layers <a href="#52-normalization-layers" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>GPU 메모리를 작게 하기 위해 detection 학습에서는 batch size가 비교적 작게 만든다. BN은 대체로 CNN에 적용되는데, 이 때, 통계량을 정확하게 추정하려면 큰 batch size를 요구한다. 하지만 object detection의 경우 batch size가 다소 작고, 보통 pretrained backbone을 사용하기에 학습할 때 weight나 BN이 업데이트 되지 않는다. 이 predtrained backbone을 Frozen BN이라고 부른다.</p><p>최근 개발된 SyncBN(Synchronized BN)이나 GN(Group Normalization) 은 좋은 효과를 보여주었다. SyncBN은 다수의 GPU를 사용하여 평균과 분산을 계산하고, GN은 group 별로 특징들에 대한 channel을 나누어 각각의 group별로 평균과 분산을 계산한다.</p><p><br /></p><p>그렇다면 각각의 normalization을 비교하고, 성능을 좋게 만들기 위해서는 어떻게 해야 할까?</p><p><img data-src="/assets/img/mmdetection/MMDetection_table7.png" width="100%" data-proofer-ignore></p><p>같은 method와 같은 ResNet-50-FPN을 사용하고 여기서 BN layer만 교체하면서 비교를 진행했다. 그 결과 BN layer를 업데이트하여도 성능에 큰 변화는 없었고, FPN이나 bbox/mask head를 추가해도 별다른 이점이 없었다. 하지만, bbox head를 2fc를 4conv-1fc로 바꾸고, normalization을 추가하면 1.5% 정도의 성능 향상을 보였다. 또한, 더 많은 conv 층을 추가할 때 더 좋은 성능을 보였다.</p><p><br /></p><h2 id="53-training-scales">5.3 Training scales <a href="#53-training-scales" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>이전 연구에서는 대체로 1000x600 이나 1333x800 의 이미지 사이즈를 선호했다. 우리도 마찬가지로 1333x800을 default scale로 사용했다. 하지만 모델의 강인함(robust)을 위해 multi scale을 사용하는 것이 좋을 것이다. 이전에도 이에 대한 방법을 아직 논의하지 않았다. multi scale을 훈련하기 위해 우리는 각 반복마다 무작위로 scale을 정하고, 그것에 대해 입력 이미지를 resize했다.</p><p>resize 하는 방법으로는</p><ol><li>value mode: 스케일셋을 미리 정해놓고 임의로 스케일을 선택한다.<li>range mode: 스케일 범위를 미리 정해놓고 최솟값과 최댓값 사이의 스케일을 임의로 만든다.</ol><p><img data-src="/assets/img/mmdetection/MMDetection_table8.png" width="100%" data-proofer-ignore></p><p>표를 보게 되면 mask rcnn에서 다양한 scale을 적용했다. 1333x[640:800:32]의 표기는 긴 방향은 1333으로 고정하고 짧은 방향을 {640,672,704,736,768,800} 중 무작위로 1개 선택하는데, 위의 경우 640~800 중 32 단위로 1개 정하는 것이다. 이는 value mode에 해당된다. 여기서 만약 1333x[640:800]이라면 range mode가 된다.</p><p>표에서 볼 수 있듯 range mode가 value mode보다 아주 조금 더 좋은 성능을 보인다.</p><p><br /></p><h2 id="54-other-hyperparameter">5.4 Other Hyperparameter <a href="#54-other-hyperparameter" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-src="/assets/img/mmdetection/MMDetection_table9.png" width="100%" data-proofer-ignore></p><p>간단하게 smoothL1_beta와 allowed_border을 볼 수 있다.</p><p><strong>smoothL1_beta</strong>: 대부분의 detection method는 regression loss로서 smoothL1 loss를 사용한다.</p><p><img data-src="/assets/img/mmdetection/mmdetection/smoothl1_beta.png" width="100%" data-proofer-ignore></p><p>beta는 L1과 MSELoss에서 threshold를 뜻한다. 1/9를 기본으로 사용한다.</p><p><strong>allowed_border</strong>: RPN에서 특징맵의 각 위치에 미리 정의된 anchor가 생성된다. 이 때 이미지 경계를 넘어가는 anchor은 무시된다. 기본적으로 이를 0으로 잡는다. 하지만 우리는 이것을 무시하지 않을 때 더 좋은 성능을 보인다는 것을 알아냈다. 이를 무한대라 정의한다면, allowed_border을 무한대로 설정했을 때 0.6% 이상의 성능 향상을 보인다.</p><p><strong>neg_pos_ub</strong>: 우리는 positive와 negative anchor라는 새롭게 하이퍼파라미터를 정의했다. 훈련 중 positive anchor이 충분하지 않을 경우 고정된 수의 훈련 샘플을 보장하기 위해 더 많은 음성 표본을 추출한다. negative sample 대비 positive sample의 비율이 더 많아지지 않게 하기 위해 neg_pos_ub를 설정한다. 이를 무한대로 설정하면 앞서 언급한 과정을 거친다. 3 또는 5로 설정한다는 것은 positive sample의 최대 3배 또는 5배까지는 negative sample을 허용하겠다는 뜻이다.</p><h1 id="reference">Reference</h1><ul><li>thesis: MMDetection:Open MMLab Detection Toolbox and Benchmark, https://arxiv.org/pdf/1906.07155.pdf<li>github URL: https://github.com/open-mmlab/mmdetection<li>Tutorial: <a href="https://colab.research.google.com/github/open-mmlab/mmdetection/blob/master/demo/MMDet_Tutorial.ipynb" target="_parent"><img data-src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" data-proofer-ignore></a><li>참고 블로그:<ul><li>https://wordbe.tistory.com/entry/MMDetection-%EB%85%BC%EB%AC%B8-%EC%A0%95%EB%A6%AC-%EB%B0%8F-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%ED%98%84</ul></ul></div><div class="post-tail-wrapper text-muted"><div style="text-align: left;"> <a href="http://hits.dwyl.com/dkssud8150.github.io/posts/MMdetection/" target="_blank"> <img data-src="http://hits.dwyl.com/dkssud8150.github.io/posts/MMdetection.svg" data-proofer-ignore> </a></div><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/review/'>Review</a>, <a href='/categories/object-detection/'>Object Detection</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/object-detection/" class="post-tag no-text-decoration" >Object Detection</a> <a href="/tags/mmdetection/" class="post-tag no-text-decoration" >mmdetection</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=[논문 리뷰] MMDetection: Open MMLab Detection Toolbox and Benchmark - JaeHo Yoon&amp;url=https://dkssud8150.github.io/posts/MMdetection/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=[논문 리뷰] MMDetection: Open MMLab Detection Toolbox and Benchmark - JaeHo Yoon&amp;u=https://dkssud8150.github.io/posts/MMdetection/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https://dkssud8150.github.io/posts/MMdetection/&amp;text=[논문 리뷰] MMDetection: Open MMLab Detection Toolbox and Benchmark - JaeHo Yoon" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://dkssud8150.github.io/posts/MMdetection/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6611243953442169" crossorigin="anonymous"></script></div><script src="https://utteranc.es/client.js" repo="dkssud8150/dkssud8150.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/gitpage/">[깃허브 프로필 꾸미기] github 프로필 만들기</a><li><a href="/posts/product/">[깃허브 프로필 꾸미기] productive box 만들기</a><li><a href="/posts/regex/">[데브코스] 2주차 - linux 기초(REGEX)</a><li><a href="/posts/Kfold/">KFold Cross Validation 과 StratifiedKFold</a><li><a href="/posts/cmake/">[데브코스] 17주차 - CMake OpenCV, Eigen, Pangolin install </a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/devcourse/">devcourse</a> <a class="post-tag" href="/tags/deeplearning/">deeplearning</a> <a class="post-tag" href="/tags/cs231n/">CS231N</a> <a class="post-tag" href="/tags/ros/">ros</a> <a class="post-tag" href="/tags/coding-test/">coding test</a> <a class="post-tag" href="/tags/linux/">linux</a> <a class="post-tag" href="/tags/kooc/">kooc</a> <a class="post-tag" href="/tags/opencv/">OpenCV</a> <a class="post-tag" href="/tags/pytorch-tutorial/">pytorch tutorial</a> <a class="post-tag" href="/tags/autonomous-driving/">Autonomous Driving</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/tusimple/"><div class="card-body"> <em class="timeago small" date="2022-04-29 03:20:00 +0900" >Apr 29, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[논문 리뷰] Ultra Fast Structure-aware Deep Lane Detection</h3><div class="text-muted small"><p> Lane Detection에 대한 논문을 리뷰한 내용입니다. 혼자 공부하기 위해 정리한 내용으로 이해가 안되는 부분들이 많을 거라 생각됩니다. 참고용으로만 봐주세요. Abstract 최근 Lane detection 방법들은 픽셀 단위의 segmentation 기반의 방법으로 다양한 환경과 처리 속도 문제를 해결하기 위해 노력해왔다. 사람의 인지 시...</p></div></div></a></div><div class="card"> <a href="/posts/YoloV5/"><div class="card-body"> <em class="timeago small" date="2021-09-05 13:00:00 +0900" >Sep 5, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[논문 리뷰] You Only Look Once v5 - blog</h3><div class="text-muted small"><p> YOLO review 입력된 이미지는 low-level feature 에서 high-level feature가 되고, classification을 위해 trainable classifier를 거친다. Yolo는 앞서 정리한 것을 참고하면 좋을 것 같다. 간단히 리뷰하자면, bounding box regression 과 classific...</p></div></div></a></div><div class="card"> <a href="/posts/YoloV5-2/"><div class="card-body"> <em class="timeago small" date="2021-09-06 13:00:00 +0900" >Sep 6, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>You Only Look Once v5 - Github</h3><div class="text-muted small"><p> Train Custom Data https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb Prepare start 시작 전 환경 설정을 위해 repogitory 를 clone 하고, requiements.txt를 설치한다. git clone https://github.com/ultral...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/lesioncontest/" class="btn btn-outline-primary" prompt="Older"><p>병변 검출 AI 경진대회</p></a> <a href="/posts/codingtestcpra/" class="btn btn-outline-primary" prompt="Newer"><p>Coding Test [C++] - 연습문제</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">JaeHo YooN</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/devcourse/">devcourse</a> <a class="post-tag" href="/tags/deeplearning/">deeplearning</a> <a class="post-tag" href="/tags/cs231n/">CS231N</a> <a class="post-tag" href="/tags/ros/">ros</a> <a class="post-tag" href="/tags/coding-test/">coding test</a> <a class="post-tag" href="/tags/linux/">linux</a> <a class="post-tag" href="/tags/kooc/">kooc</a> <a class="post-tag" href="/tags/opencv/">OpenCV</a> <a class="post-tag" href="/tags/pytorch-tutorial/">pytorch tutorial</a> <a class="post-tag" href="/tags/autonomous-driving/">Autonomous Driving</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { function updateMermaid(event) { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { const mode = event.data.message; if (typeof mermaid === "undefined") { return; } let expectedTheme = (mode === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* Re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } let initTheme = "default"; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); window.addEventListener("message", updateMermaid); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-NC7MWHVXJE"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-NC7MWHVXJE'); }); </script>