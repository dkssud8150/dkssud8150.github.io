<!DOCTYPE html><html lang="en" data-mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="[데브코스] 9주차 - DeepLearning AI &amp; machine learning" /><meta name="author" content="JaeHo YooN" /><meta property="og:locale" content="en" /><meta name="description" content="Do focus on developing ‘your ability’ rather than waste time on making you famous." /><meta property="og:description" content="Do focus on developing ‘your ability’ rather than waste time on making you famous." /><link rel="canonical" href="https://dkssud8150.github.io/posts/dplearn/" /><meta property="og:url" content="https://dkssud8150.github.io/posts/dplearn/" /><meta property="og:site_name" content="JaeHo Yoon" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-04-12T15:40:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="[데브코스] 9주차 - DeepLearning AI &amp; machine learning" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@JaeHo YooN" /><meta name="google-site-verification" content="znvuGsQGYxMZPBslC4XG6doCYao6Y-fWibfGlcaMHH8" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"JaeHo YooN"},"dateModified":"2022-05-17T02:56:35+09:00","datePublished":"2022-04-12T15:40:00+09:00","description":"Do focus on developing ‘your ability’ rather than waste time on making you famous.","headline":"[데브코스] 9주차 - DeepLearning AI &amp; machine learning","mainEntityOfPage":{"@type":"WebPage","@id":"https://dkssud8150.github.io/posts/dplearn/"},"url":"https://dkssud8150.github.io/posts/dplearn/"}</script><title>[데브코스] 9주차 - DeepLearning AI & machine learning | JaeHo Yoon</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="JaeHo Yoon"><meta name="application-name" content="JaeHo Yoon"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/shin_chan.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">JaeHo Yoon</a></div><div class="site-subtitle font-italic">Mamba Mentality</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fab fa-angellist ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/dkssud8150" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['hoya58150','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="https://www.notion.so/18490713817d403696812c57d0abe730" aria-label="notion" target="_blank" rel="noopener"> <i class="fab fa-battle-net"></i> </a> <a href="https://www.linkedin.com/in/jaeho-yoon-90b62b230" aria-label="linkedin" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href="https://www.instagram.com/jai_ho8150/" aria-label="instagram" target="_blank" rel="noopener"> <i class="fab fa-instagram"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>[데브코스] 9주차 - DeepLearning AI & machine learning</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>[데브코스] 9주차 - DeepLearning AI & machine learning</h1><div class="post-meta text-muted"><div> By <em> <a href="https://github.com/dkssud8150">JaeHo YooN</a> </em></div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6611243953442169" crossorigin="anonymous"></script><div class="d-flex"><div> <span> Posted <em class="timeago" date="2022-04-12 15:40:00 +0900" data-toggle="tooltip" data-placement="bottom" title="Tue, Apr 12, 2022, 3:40 PM +0900" >Apr 12, 2022</em> </span> <span> Updated <em class="timeago" date="2022-05-17 02:56:35 +0900 " data-toggle="tooltip" data-placement="bottom" title="Tue, May 17, 2022, 2:56 AM +0900" >May 17, 2022</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="5185 words"> <em>28 min</em> read</span></div></div></div><div class="post-content"><p><br /></p><h1 id="기계-학습">기계 학습</h1><p>어떤 컴퓨터 프로그램이 T라는 작업을 수행할 때, 이 프로그램의 성능이 P라는 척도로 평가했을 때 경험 E를 통해 성능이 개선된다면 이 프로그램은 학습한다고 말할 수 있다. 따라서 최적의 알고리즘을 찾는 행위를 기계 학습이라 할 수 있다. 기계 학습의 중심은 경험, 과업, 성능에 있다.</p><p>예전에는 지식 기반의 학습을 했다. 즉, 인간이 알고 있는 사실을 기계에 전달하여 학습을 하는 것을 말한다. 그러나 인간의 지식이 실제로는 틀린 것일 수 있기 떄문에 변화되었다. 그래서 기계학습으로 넘어왔다. 또한, 사람의 신경망을 모방하여 만든 심층 학습이 나오게 되면서 기계학습 분야가 더 발전하게 되었다.</p><p>기계학습으로 넘어오면서 데이터가 매우 중요해졌다. 데이터를 통해 학습하여 규칙을 찾고 그를 통해 다음을 예측하기 때문이다. 예측에는 회귀와 분류로 나뉘어진다. 회귀는 목표치가 실수이고, 분류는 특정 부류나 종류의 값을 출력한다. 예를 들어, 분류는 개와 고양이를 분류하는 것이고, 회귀는 좌표점 n개를 통해 다음 점을 예측하는 것이 회귀에 해당한다.</p><p>기계학습에서 훈련이란 주어진 task에 대해 가장 정확하게 할 수 있게 최적의 매개변수를 찾는 작업이다. 처음에는 임의의 매개변수를 지정하여 시작하지만, 학습하면서 최적의 성능에 도달한다.</p><p>훈련이 끝나면 추론, infernce를 수행한다. 훈련 데이터가 아닌 새로운 데이터를 입력으로 받아 예측을 한다. 기계학습의 궁극적인 목표는 추론에 대한 오류를 최소화하는 것이다. 테스트 데이터에서 높은 성능을 일반화,generalization 능력이라 부른다.</p><p>그렇다면 기계학습에서 필수로 있어야 할 것들은 학습을 위한 데이터를 가지고 있어야 하고, 데이터 사이의 규칙이 존재해야 한다.</p><p>데이터에는 training set, validation set, test set 이 있다. training set은 기계가 훈련하는 셋이고, test set은 훈련된 모델에 추론하고자 하는 데이터를 넣을 때 어떻게 출력되는지에 대한 셋이다. 그렇다면 validation set이 의미하는 것은, test와 비슷하다. 그러나 training set으로 훈련된 모델이 test set으로 바로 평가를 하게 되면 정확도가 떨러질 수 있다. 또한, training set만 사용하여 훈련 후 test set에 적용시키면 과적합,overfitting이 발생하기 쉽다. 그래서 validation set을 통해 훈련 시에도 평가를 함께 수행하며 학습할 수 있다.</p><p><br /></p><h2 id="특징-공간의-이해">특징 공간의 이해 <a href="#특징-공간의-이해" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>모든 데이터는 정량적으로 표현되며, 특징 공간 상에 존재한다. 1차원, 2차원 등이 있는데, 이 각각의 차원이 의미하는 바는 각각 서술하고 있는 특징의 개수라 할 수 있다. 즉, 특징이 1개뿐이라면 1차원, 2개가 있다면 2차원이라 할 수 있다.</p><p>iris 데이터는 4개의 특징 요소를 가지고 있다. 따라서 이는 4차원 특징 공간이라 할 수 있다. 사진을 생각해보면 각각의 픽셀이 값을 가지고 있으므로 4x4 픽셀이라면 각각의 픽셀값을 가질 수 있으므로 16차원이라 할 수 있다.</p><p>따라서 d차원의 데이터라 하면 d개의 특징 벡터를 가진다. d차원의 특징 공간인 직선 모델을 사용할 경우, 필요한 매개변수의 개수는 d+1이다.</p>\[y = w1x1 + w2x2 + ... + wdxd + b\]<p>d+1인 이유는 차수가 1인 x에 대해 d개를 가지고, 0차수인 상수, b를 가지기 때문이다. 그렇다면 2차원 곡선 모델을 사용한다면 매개변수의 수는 지수적으로 증가하여 d^2+d+1 개가 필요하다.</p><p>따라서 iris 데이터는 4차원이었으므로, 2차 곡선 모델을 사용한다면 4^2 + 4 + 1 이므로 21개의 매개변수가 필요하다. MNIST 데이터를 사용할 경우 d = 784 이므로 총 615,441개의 매개변수가 필요하다.</p><p><br /></p><p>이 특징 벡터 사이의 거리를 구할 때 다양한 거리 공식이 있다. 유클리디안 거리, 맨허튼 거리 등등이 존재하기 때문에 상황에 맞게 잘 적용해야 한다.</p><p><br /></p><blockquote><p>차원의 저주</p><p>차원이 높아짐에 따라 발생하는 현실적인 문제들이 있다. 차원이 높으면 예측이 더 잘 되지만, 차원이 높아질수록 유의미한 표현을 찾기 위해 지수적으로 더 많은 데이터가 필요하다. 그래서 이를 <strong>차원의 저주</strong>라 한다.</p></blockquote><p><br /></p><p>특징 공간을 직선 모델을 사용하여 분류한다면 규칙을 찾기 어렵다. 따라서 decision boundary, 경계선을 잘 설정해야 한다. 이를 위해서 데이터를 새로운 공간 좌표로 다시 변환하여 분류할 수 있다.</p><p>따라서 이 표현, 즉 데이터를 새로운 공간좌표로 변환하는 학습인 표현 학습도 중요하다. 표현 학습이란 기계가 예측하기 좋은 특징 공간을 자동으로 찾는 것을 말한다.</p><p>표현 학습에는 HOG(Histogram of oriented gradients)가 있다. nearest neighbor 알고리즘이 나오기 전에 사용되었던 방법으로 이미지에 대한 히스토그램을 그려 분석하는 방법이다. 표현 학습에도 심층 학습이 있다. NN 방법 이후에 이미지의 특징 벡터를 딥러닝이 학습해서 특징을 추출하여 최적의 계층적인 특징을 학습하는 방법을 말한다. low level에서는 선이나 구석점 등을 추출하고, high level에서는 조금 더 추상화된 특징(얼굴, 바퀴)를 추출한다. 이는 이미지 뿐만 아니라 텍스트, 언어 등 많은 곳에 이용된다.</p><p><img data-src="/assets/img/cs231n/2021-09-12/hog.png" data-proofer-ignore></p><p><img data-src="https://cs231n.github.io/assets/knn.jpeg" data-proofer-ignore></p><p><br /></p><h1 id="데이터-생성-과정">데이터 생성 과정</h1><p>기계학습에는 모델을 만드는 것 이외에도 데이터를 전처리하거나 수집하는 것도 중요하다. 데이터를 잘 수집하고, 잘 정제해야 정확도도 향상된다. 문제는 데이터의 양이 어느정도 많아야 할까? MNIST 데이터를 기준으로 보면 차원이 784차원이다. 이것이 흑백 이미지여서 0 또는 1로 이루어져 있다고 하더라도 서로 다른 총 샘플 수는 2^784가지가 된다. 그러나 MNIST의 경우 6만 개의 샘플로만 훈련되어 있다. 그렇다면 이 매우 작은 데이터로 어떻게 높은 성능을 보이는지 파악해봐야 할 것이다. 1과 2, 또는 2과 6의 데이터간에는 군집, 데이터가 모여있는 곳이 생긴다. 즉 scatter, 흩어져 있지 않고, 이미지마다 모여 있는 공간이 존재할 것이다.</p><p>또한, 온전한 이미지가 있는 이미지 외에 잘려있는 이미지는 입력시키지 않는다. 이도 비슷하게 이상한 데이터를 집어넣지 않음으로서 데이터들이 흩어져 있지 않을 것이다.</p><p>고차원의 공간을 저차원으로 바라보는 방법을 <strong>매니폴드 가정</strong> 이라 한다. 고차원의 데이터의 규칙은 관련된 낮은 차원에서도 특징이 연관되어 있을 것이다. 이를 매니폴드라 한다.</p><p>추가적으로, 데이터가 충분한 양만큼 수집하면 성능이 올라가지만, 데이터가 적다면 모델이 과적합(overfitting)이 발생하게 된다. 즉, 훈련 데이터에만 매우 높은 성능을 보이지만, 테스트에서는 좋지 않은 성능을 보이는 상황을 말한다. 이를 해결하기 위해서는 데이터를 많이 늘리거나, 데이터 증강을 통해 데이터를 늘려야 할 것이다.</p><p><br /></p><h2 id="데이터-가시화">데이터 가시화 <a href="#데이터-가시화" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>4차원 이상의 초공간(hyperplane)은 한꺼번에 가시화(visualization)가 불가능하다. 따라서 여러 가지 가시화 기법을 통해 특징 벡터를 나타낼 수 있다.</p><p><br /></p><h1 id="선형-회귀linear-regression">선형 회귀(linear regression)</h1><p>직선 모델을 사용하므로 두 개의 매개변수(w,b)를 가진다. 또한, 성능을 평가하기 위해 사용하는 함수를 <strong>목적 함수</strong>(object function) 또는 비용 함수(cost function)이라 한다. 선형 회귀에서는 MSE(mean squared error)를 사용한다.</p>\[J(\theta) = {1 \over n} \sum_{i=1}^n(f_\theta(x_i) - y_i)^2\]<p>f\theta는 우리가 설정한 직선을 말하고, f(x)는 예측값, y는 실제값에 해당한다. 즉, 우리가 예측한 예측값과 실제값의 차이의 평균을 오차로 평가하는 함수를 비용 함수라 한다. 처음에는 최적의 매개변수를 모르기 때문에 임의의 난수로 설정하고 개선해 나간다.</p><p>최적화에는 convex와 nonconvex가 존재한다. 회귀 문제에서는 최적값이 1개인 것과 정확한 최적값이 존재하지 않을 수 있다. 1개인 것을 convex, 신경망과 같이 완벽한 최적값이 없거나 찾기 너무 어려운 것을 non convex라 한다.</p><p>기계학습은 개선을 통해 오류를 줄이고, 그를 통해 최적의 해를 찾아간다. 이를 공식화하면 다음과 같다.</p>\[\widehat{\theta} = argmin(J(\theta))\]<p><br /></p><p>non convex에서 최적값을 찾기 위해서는 gradient를 사용한다. 그 이유는 미분값이 작아지는 방향으로 계속 가다보면 오류가 줄어들고, 결국에는 최적의 상황에 도달하기 떄문이다. 이는 산에서 골짜기를 연상하면 이해하기 쉽다.</p><p><img data-src="\assets\img\dev\week9\day2\gradient_descent.jpeg" data-proofer-ignore></p><p><br /></p><h1 id="과적합overfitting과소적합underfitting">과적합(overfitting)/과소적합(underfitting)</h1><p>과소적합이란 모델의 용량이 작아 오차가 클 수 밖에 없는 현상을 말한다. 간단하게 선형 모델을 사용하면 당연히 경계선을 설저아기 어려울 것이다. 차수가 높을 수록 주어진 데이터에 적합하게 설정할 수 있다. 그러나 너무 큰 차수를 사용하거나 데이터의 양이 너무 작아 훈련 데이터셋에만 적합시키게 되면 test시 성능이 잘 나오지 않는다. 모델의 용량이 너무 크기 떄문에 학습 과정에사 잡음까지 수용하여 훈련시켰기 때문일 것이다. 이를 간단하게 말해서 훈련 데이터셋을 단순 암기했다고 할 수 있다.</p><p>1~2차의 모델을 사용할 경우 훈련 데이터셋과 테스트 데이터셋 모두 낮은 성능을 보이는 과소적합이 발생한다. 12차와 같이 높은 차원의 모델의 경우 훈련 데이터셋에서는 높은 성능을 보이나 테스트 데이터셋에서는 낮은 성능을 보이는 과적합이 발생한다. 이는 낮은 일반화 능력을 가졌다고 할 수 있다.</p><p>대체로 딥러닝에는 파라미터가 매우 많기 때문에 과소적합보다는 과적합이 더 많이 발생한다.</p><p><br /></p><h2 id="편향bias-and-분산변동variance">편향(bias) and 분산/변동(variance) <a href="#편향bias-and-분산변동variance" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>훈련 데이터셋을 여러 번 수집하여 1~12차에 반복 적용해서 실험해보면</p><ul><li>2차는 매번 큰 오차 -&gt; 편향이 큼(underfitting), 하지만 비슷한 모델을 얻음 -&gt; 낮은 변동<li>12차는 매번 작은 오차 -&gt; 편향이 작음, 하지만 크게 다른 모델을 얻음 -&gt; 높은 변동 -&gt; overfitting 발생</ul><p>일반적으로 용량이 작은 모델은 편향이 크고 분산이 작다. 그러나 복잡한 ㅗㅁ델의 경우 편향이 작고 분산이 크다. 즉 낮은 차수의 경우 비슷한 모델이 수집되지만, 높은 차수의 경우 매번 아예 다른 모델이 수집될 수 있다.</p><p>기계 학습의 목표는 낮은 편향과 낮은 분산을 가진 예측 모델을 만드는 것이 목표다. 하지만 모델의 편향과 분산은 <strong>상충 관계</strong>에 있다. 따라서 적절한 optimal capacity를 잡아 <strong>편향을 최소로 유지하고 분산도 최대로 낮추는 전략이 필요</strong>하다. 최근에는 capacity를 크게 잡고, 점점 줄여나가는 방식을 사용한다.</p><p><img data-src="/assets/img/dev/week9/day2/capacity.png" data-proofer-ignore></p><p><br /></p><p>그러나 요즘에는 서로 다른 차수를 선택해서 학습하지 않는다. 지금은 용량이 충분히 큰 모델을 선택한 후 선택한 모델이 정상을 벗어나지 않도록 규제(regularization) 기법을 적용한다. 이 때 말하는 규제는 데이터 증강(data augmentation)이나 learning rate, weight decay 설정 등을 말한다.</p><p><a href="https://dkssud8150.github.io/posts/cs231n3/">regularization</a></p><p><br /></p><h2 id="validation-set-설정">Validation set 설정 <a href="#validation-set-설정" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>검증 데이터를 사용하여 훈련 데이터셋으로 훈련된 모델의 성능을 측정한다. 그래서 가장 높은 성능을 보인 모델을 선택한다. 그것을 사용하여 테스트에서 예측을 수행하면 좋은 성능을 보인다.</p><h3 id="k-fold-cross-validation">K-fold Cross validation <a href="#k-fold-cross-validation" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>데이터의 양이 적은 경우 검증 데이터셋을 돌아가며 사용하는 것을 말한다. k-fold라는 것은 훈련 데이터셋을 10개로 나누고, epoch, 반복마다 1개씩 validation set으로 설정하여 검증한다. 그래서 추출된 검증 데이터셋의 성능이 총 10개가 나오는데, 이를 평균내서 가장 좋은 성능의 모델을 선택한다.</p><p><a href="https://dkssud8150.github.io/posts/Kfold/">kfold cross validation 코드</a></p><p><br /></p><h3 id="부트스트랩bootstrap">부트스트랩(bootstrap) <a href="#부트스트랩bootstrap" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>데이터 분포가 불균형할 때 사용하는 방법으로, 임의의 복원 추출 샘플링(sampling with replacement)을 반복한다. 데이터 불균형은 이상탐지(보안 분야)에서 많이 발생한다.</p><p><img data-src="/assets/img/dev/week9/day2/bootstrap.png" data-proofer-ignore></p><p>예를 들어, 1과 2를 분류하는데 1에 대한 데이터셋이 10000개고 2에 대한 데이터셋이 100개라면 이는 데이터 불균형에 해당된다. 200개의 데이터셋을 사용하고자 할 때는 1에 대해서는 계속 다른 데이터를 사용할 수 있지만, 2에 대해서는 100개 전체를 계속해서 추출해서 학습을 시킨다. 그렇게 많은 성능들을 어샘블링해서 판단한다.</p><p><br /></p><h1 id="regularization">Regularization</h1><h2 id="data-augmentation">Data Augmentation <a href="#data-augmentation" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>데이터를 많이 수집할수록 일반화 능력이 향상된다. 그러나 수집할 수 있는 데이터의 양은 한정적이다. 또한 데이터를 실측자료(ground truth)를 사용하려면 사람이 직접 라벨링해야 한다. 그러므로 현재 가지고 있는 데이터로 crop, perspective, rotation, warping 등과 같은 이미지를 변형(transform)함으로써 데이터를 증강시켜 robust한 모델을 생성한다. 단 원 데이터의 고유 특성이 변하지 않도록 주의해야 한다.</p><p><br /></p><h2 id="weight-decay">Weight Decay <a href="#weight-decay" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>가중치를 줄이는 기법으로, 모델의 용량을 낮추면서 overfitting을 방지한다. overfitting이라는 것은 모델의 용량이 커서 발생하는 것이므로, 이를 감소시키게 하여 overfitting이 발생하지 않도록 조절해야 한다.</p>\[J(\theta) = {1 \over n} \sum_{i=1}^n(f_\theta(x_i) - y_i)^2 + \lambda \parallel \theta \parallel ^2\]<p>원래 있던 훈련 집합의 오차에 선호(preference) 항을 추가하여 가중치를 감소시키도록 최적화를 시킨다.</p><p><br /></p><p>이는 optimizer을 생성할 때 <code class="language-plaintext highlighter-rouge">weight decay</code>라는 인자를 통해 설정한다.</p><p><a href="https://dkssud8150.github.io/posts/overfitting/">overfitting 방지하는 방법</a></p><p><br /></p><p>규제에는 다양한 방법들이 있다.</p><ul><li>parameter norm penalty<li>early stopping<li>bagging (bootstrap aggregation)<li>dropout<li>ensemble</ul><p>여기서 dropout과 ensemble을 많이 사용한다.</p><p><a href="https://dkssud8150.github.io/posts/cs231n7/">dropout/ensemble 참고 자료</a></p><p><br /></p><p><br /></p><h1 id="기계-학습-유형">기계 학습 유형</h1><h2 id="지도-방식에-따른-유형">지도 방식에 따른 유형 <a href="#지도-방식에-따른-유형" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>지도 학습(supervised learning)</ul><p>특징 벡터 X와 목표치 Y가 모두 주어지는 상황을 말한다. 즉 데이터와 라벨이 모두 주어진다. 회귀와 분류 문제로 구분한다.</p><p><br /></p><ul><li>비지도 학습(unsupervised learning)</ul><p>특징 벡터 X만 주고, 라벨 Y를 주지 않는 상황을 말한다. 군집화(clustering)작업을 할 때 사용한다. 또는 밀도 추정, 특징 공간 변환 작업도 한다.</p><p><br /></p><ul><li>강화 학습(reinforcement learning)</ul><p><img data-src="https://dkssud8150.github.io/assets/img/cs231n/2021-11-09/0013.jpg" data-proofer-ignore></p><p>목표치가 주어지는데 지도 학습과는 다른 형태로, 강화학습에는 에이전트, 환경, 행동이 존재한다. 에이전트는 행동에 따른 적절한 보상(reward)를 받는다. 에이전트는 어떤 행동을 했을 때 보상을 받는지에 대해 학습한다.</p><p>바둑에서 강화학습이 사용되는데, 수를 두는 행위가 샘플이고, 게임이 끝나면 목표치 하나가 부여된다. 이기면 1, 패하면 -1이다.</p><blockquote><p>예를 들어, 고양이가 있고, 빨간색 버튼을 누르면 간식이 나오는 기계가 있다고 가정해보자. 고양이는 어떻게 해야 간식이 나오는지 모를 것이다. 아무거나 다 시도해보다가 버튼을 눌렀을 때 간식이 나오는 것을 확인한다. 이 때, 고양이(agent)는 간식이 나오는 기계(environment)의 버튼을 누르면(action) 간식 나온다는(rewards) 것을 학습한 것이다.</p></blockquote><p><br /></p><ul><li>준지도 학습(semi-supervised learning)</ul><p>일부는 X와 Y를 모두 가지지만, 나머지는 X만 가진 상황이다. 대부분의 데이터가 X의 수집은 쉽지만 Y는 수작업이 필요했기 때문에 주목받고 있다.</p><p><br /></p><h2 id="다양한-기준에-따른-유형">다양한 기준에 따른 유형 <a href="#다양한-기준에-따른-유형" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>오프라인 학습(offline learning)과 온라인 학습(online learning)</ul><p>오프라인 학습이란 데이터를 수집해놓고 수집된 데이터로부터 학습을 진행하는 것을 말하고, 온라인 학습은 스트리밍 형태로 데이터를 계속 받으면서 능동적으로 학습하는 것을 말한다. 보통은 오프라인 학습을 다룬다. 온라인 학습은 IoT 등에서 추가로 발생하는 데이터 샘플을 가지고 점증적 학습을 수행한다.</p><p><br /></p><ul><li>결정록적 학습(deterministic learning)과 확률적 학습(stochastic learning)</ul><p>결정론적 학습은 같은 데이터를 주면 똑같은 결과가 나오는 것이고, 확률적 학습은 같은 데이터라도 확률 분포를 사용하여 다른 모델이 만들어질 수 있는 것을 말한다. RBM/DBN이 확률적 학습에 해당된다.</p><p><br /></p><ul><li>분별 모델(discriminative models)와 생성 모델(generative models)</ul><p>분별 모델은 부류 예측에만 관심이 있다. 즉, x에 대한 타겟 y를 추정하는 P(y|x)에 관심이 있지만, 생성 모델은 P(x) 또는 P(x|y) 처럼 x에 관심을 두는 것을 말한다. 따라서 새로운 샘플을 생성할 수 있다. GAN/RBM이 이에 해당된다.</p><p><a href="https://dkssud8150.github.io/posts/cs231n13/">generative models</a></p></div><div class="post-tail-wrapper text-muted"><div style="text-align: left;"> <a href="http://hits.dwyl.com/dkssud8150.github.io/posts/dplearn/" target="_blank"> <img data-src="http://hits.dwyl.com/dkssud8150.github.io/posts/dplearn.svg" data-proofer-ignore> </a></div><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/classlog/'>Classlog</a>, <a href='/categories/devcourse/'>devcourse</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/devcourse/" class="post-tag no-text-decoration" >devcourse</a> <a href="/tags/deeplearning/" class="post-tag no-text-decoration" >deeplearning</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=[데브코스] 9주차 - DeepLearning AI &amp; machine learning - JaeHo Yoon&amp;url=https://dkssud8150.github.io/posts/dplearn/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=[데브코스] 9주차 - DeepLearning AI &amp; machine learning - JaeHo Yoon&amp;u=https://dkssud8150.github.io/posts/dplearn/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https://dkssud8150.github.io/posts/dplearn/&amp;text=[데브코스] 9주차 - DeepLearning AI &amp; machine learning - JaeHo Yoon" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://dkssud8150.github.io/posts/dplearn/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6611243953442169" crossorigin="anonymous"></script></div><script src="https://utteranc.es/client.js" repo="dkssud8150/dkssud8150.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/gitpage/">[깃허브 프로필 꾸미기] github 프로필 만들기</a><li><a href="/posts/product/">[깃허브 프로필 꾸미기] productive box 만들기</a><li><a href="/posts/regex/">[데브코스] 2주차 - linux 기초(REGEX)</a><li><a href="/posts/Kfold/">KFold Cross Validation 과 StratifiedKFold</a><li><a href="/posts/cmake/">[데브코스] 17주차 - CMake OpenCV, Eigen, Pangolin install </a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/devcourse/">devcourse</a> <a class="post-tag" href="/tags/deeplearning/">deeplearning</a> <a class="post-tag" href="/tags/cs231n/">CS231N</a> <a class="post-tag" href="/tags/ros/">ros</a> <a class="post-tag" href="/tags/coding-test/">coding test</a> <a class="post-tag" href="/tags/linux/">linux</a> <a class="post-tag" href="/tags/kooc/">kooc</a> <a class="post-tag" href="/tags/opencv/">OpenCV</a> <a class="post-tag" href="/tags/pytorch-tutorial/">pytorch tutorial</a> <a class="post-tag" href="/tags/autonomous-driving/">Autonomous Driving</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/numpy/"><div class="card-body"> <em class="timeago small" date="2022-04-11 14:40:00 +0900" >Apr 11, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[데브코스] 9주차 - DeepLearning Numpy & Matplotlib</h3><div class="text-muted small"><p> Numpy Numpy 설치 및 불러오기 pip install numpy import numpy as np 파이썬의 리스트는 머신러닝에서 가장 많이 사용되는 구조 중 하나일 것이다. 그러나 이 리스트는 연산 속도가 느리다. 그래서 연산을 효과적으로 할 수 있도록 하기 위해 만든 것이 Numpy이다. Numpy 연산 속도 nump...</p></div></div></a></div><div class="card"> <a href="/posts/mlmath/"><div class="card-body"> <em class="timeago small" date="2022-04-13 15:40:00 +0900" >Apr 13, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[데브코스] 9주차 - DeepLearning Mathematics for Machine Learning</h3><div class="text-muted small"><p> 기계 학습에서 수학은 손실함수를 정의하고 손실함수의 최저점을 찾아주는 최적화 이론에 사용된다. 제어를 함에 있어서도 수학이 필요하다. 선형대수 데이터는 벡터나 행렬, 텐서 형태로 되어 있는데, 이에 대한 공간을 이해하고, 연산을 하기 위해서는 선형대수가 필요하다. 벡터와 행렬 벡터는 요소의 종료와 크기를 표현한다. \[x \in R^n\]...</p></div></div></a></div><div class="card"> <a href="/posts/multiperceptron/"><div class="card-body"> <em class="timeago small" date="2022-04-14 15:40:00 +0900" >Apr 14, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[데브코스] 9주차 - DeepLearning Multi Layer Perceptron</h3><div class="text-muted small"><p> 신경망 사람의 뉴런의 집합을 신경망이라 한다. 뉴런은 두뇌의 가장 작은 정보처리 단위이고, 세포체는 연산을하고, 수상돌기는 신호를 수신, 축삭은 처리 결과를 전송한다. 이러한 사람의 뉴런을 따럿 컴퓨터에 인공지능으로 구성하여 퍼셉트론, 인공신경망을 만들었다. 세포체, 수상돌기, 축삭, 시냅스가 인공신경망에서 각각 노드, 입력, 출력, 가중치에 해...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/numpy/" class="btn btn-outline-primary" prompt="Older"><p>[데브코스] 9주차 - DeepLearning Numpy & Matplotlib</p></a> <a href="/posts/mlmath/" class="btn btn-outline-primary" prompt="Newer"><p>[데브코스] 9주차 - DeepLearning Mathematics for Machine Learning</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">JaeHo YooN</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/devcourse/">devcourse</a> <a class="post-tag" href="/tags/deeplearning/">deeplearning</a> <a class="post-tag" href="/tags/cs231n/">CS231N</a> <a class="post-tag" href="/tags/ros/">ros</a> <a class="post-tag" href="/tags/coding-test/">coding test</a> <a class="post-tag" href="/tags/linux/">linux</a> <a class="post-tag" href="/tags/kooc/">kooc</a> <a class="post-tag" href="/tags/opencv/">OpenCV</a> <a class="post-tag" href="/tags/pytorch-tutorial/">pytorch tutorial</a> <a class="post-tag" href="/tags/autonomous-driving/">Autonomous Driving</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-NC7MWHVXJE"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-NC7MWHVXJE'); }); </script>