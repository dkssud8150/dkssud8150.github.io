<!DOCTYPE html><html lang="en" data-mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="CS231N chapter 9 - CNN Architectures" /><meta name="author" content="JaeHo-YooN" /><meta property="og:locale" content="en" /><meta name="description" content="8강 리뷰 1) Tensorflow 2) Pytorch 3) static Vs dynamic graph" /><meta property="og:description" content="8강 리뷰 1) Tensorflow 2) Pytorch 3) static Vs dynamic graph" /><link rel="canonical" href="https://dkssud8150.github.io/posts/cs231n9/" /><meta property="og:url" content="https://dkssud8150.github.io/posts/cs231n9/" /><meta property="og:site_name" content="JaeHo Yoon" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-09-30T13:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="CS231N chapter 9 - CNN Architectures" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@JaeHo-YooN" /><meta name="google-site-verification" content="znvuGsQGYxMZPBslC4XG6doCYao6Y-fWibfGlcaMHH8" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"JaeHo-YooN"},"dateModified":"2022-03-22T22:14:30+09:00","datePublished":"2021-09-30T13:00:00+09:00","description":"8강 리뷰 1) Tensorflow 2) Pytorch 3) static Vs dynamic graph","headline":"CS231N chapter 9 - CNN Architectures","mainEntityOfPage":{"@type":"WebPage","@id":"https://dkssud8150.github.io/posts/cs231n9/"},"url":"https://dkssud8150.github.io/posts/cs231n9/"}</script><title>CS231N chapter 9 - CNN Architectures | JaeHo Yoon</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="JaeHo Yoon"><meta name="application-name" content="JaeHo Yoon"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/shin_chan.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">JaeHo Yoon</a></div><div class="site-subtitle font-italic">Mamba Mentality</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fab fa-angellist ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/dkssud8150" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['hoya58150','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="https://www.notion.so/18490713817d403696812c57d0abe730" aria-label="notion" target="_blank" rel="noopener"> <i class="fab fa-battle-net"></i> </a> <a href="https://www.linkedin.com/in/jaeho-yoon-90b62b230" aria-label="linkedin" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href="https://www.instagram.com/jai_ho8150/" aria-label="instagram" target="_blank" rel="noopener"> <i class="fab fa-instagram"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>CS231N chapter 9 - CNN Architectures</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>CS231N chapter 9 - CNN Architectures</h1><div class="post-meta text-muted"><div> By <em> <a href="https://github.com/dkssud8150">JaeHo-YooN</a> </em></div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6611243953442169" crossorigin="anonymous"></script><div class="d-flex"><div> <span> Posted <em class="timeago" date="2021-09-30 13:00:00 +0900" data-toggle="tooltip" data-placement="bottom" title="Thu, Sep 30, 2021, 1:00 PM +0900" >Sep 30, 2021</em> </span> <span> Updated <em class="timeago" date="2022-03-22 22:14:30 +0900 " data-toggle="tooltip" data-placement="bottom" title="Tue, Mar 22, 2022, 10:14 PM +0900" >Mar 22, 2022</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="8281 words"> <em>46 min</em> read</span></div></div></div><div class="post-content"><blockquote><p>8강 리뷰</p><p>1) Tensorflow</p><p>2) Pytorch</p><p>3) static Vs dynamic graph</p></blockquote><p><br /></p><p><br /></p><h1 id="cnn-architecture">CNN Architecture</h1><p>크게 AlexNet, VGGNet, GoogLeNet, ResNet 등이 있다.</p><p><br /></p><h2 id="lenet">LeNet <a href="#lenet" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>LeNet은 산업에 성공적으로 적용된 최초의 ConvNet이다.</p><p><img data-src="/assets/img/cs231n/2021-09-29/0008.jpg" alt="image" data-proofer-ignore></p><p>이미지를 입력으로 받아 stride = 1인 5x5 필터를 거치고 몇 개의 conv Layer과 pooling layer를 거친다. 끝단에 FC layer가 붙는다.</p><p><br /></p><p>간단한 모델이지만, 엄청난 성공을 거둔 모델이다.</p><p><br /></p><p><br /></p><h2 id="alexnet">AlexNet <a href="#alexnet" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-src="/assets/img/cs231n/2021-09-29/0009.jpg" alt="image" data-proofer-ignore></p><p>2012년에 AlexNet이 나왔다. 최초의 Large scale CNN이다. ImageNet을 아주 잘 수행했다.</p><p>LeNet와 유사하나 layer 수가 더 많아졌다.</p><p><br /></p><p>AlexNet의 전체 layer이다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre><td class="rouge-code"><pre><span class="nc">AlexNet</span><span class="p">(</span>
  <span class="p">(</span><span class="n">features</span><span class="p">):</span> <span class="nc">Sequential</span><span class="p">(</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">6</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">192</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">7</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">9</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">10</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">11</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">12</span><span class="p">):</span> <span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
  <span class="p">)</span>
  <span class="p">(</span><span class="n">avgpool</span><span class="p">):</span> <span class="nc">AdaptiveAvgPool2d</span><span class="p">(</span><span class="n">output_size</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
  <span class="p">(</span><span class="n">classifier</span><span class="p">):</span> <span class="nc">Sequential</span><span class="p">(</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="nc">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">9216</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">):</span> <span class="nc">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">6</span><span class="p">):</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">)</span>
<span class="p">)</span>
</pre></table></code></div></div><p>기본적으로 conv- pool - normalization이 2번 반복되고, conv layer가 조금 더 붙고 (conv 3,4,5…), 그 뒤에 pooling layer(Maxpooling)가 있다. 마지막에는 FC layer가 몇 개 붙어있다.</p><p>따라서, 5개의 conv layer과 3개의 FC layer로 구성되어 있다.</p><p><br /></p><p>기본적으로 imageNet으로 학습시킨 모델이므로 입력 크기는 227x227x3이다.</p><p><br /></p><p><br /></p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></table></code></div></div><p>첫 레이어인 conv1은 96개의 stride = 4인 11x11 필터가 존재한다. 그렇다면 출력은 (227-11)/4 + 1 = 55 x 55 x 96의 activiation map이 생성된다.</p><p><br /></p><p>또한, 입력 depth(channel)는 3이다. 따라서 첫번째 layer는 11x11x3 필터가 96개 있으므로, (11x11x3)x96 개의 파라미터를 가지고 있다.</p><p><br /></p><p><br /></p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></table></code></div></div><p>두번째 layer는 pooling layer이다.</p><p>여기에는 stride = 2 인 3x3 필터가 있다. 따라서 이 레이어의 출력의 크기는 27x27x96이다. pooling layer은 depth가 변하지 않는다.</p><p><br /></p><p>pooling layer에는 파라미터가 존재하지 않으므로 0개다. 파라미터는 우리가 학습시키는 가중치다. conv layer에는 학습할 수 있는 가중치가 있지만, pooling layer는 학습시킬 파라미터가 존재하지 않는다.</p><p><br /></p><p><br /></p><p>모든 레이어의 파라미터 사이즈와 갯수를 계산해보자.</p><ul><li>INPUT : [227 x 227 x 3]<li>CONV1 : 96개의 11x11 filter at stride 4, padding 0 -&gt; (227 - 11)/4 + 1 = 55 -&gt; [55 x 55 x 96], p = (11x11x3)x96<li>MAX POOL1 : 3x3 filters at stride 2 -&gt; (55 - 3)/2 + 1 = 27 -&gt; [27 x 27 x 96], p=0<li>NORM1 : [27 x 27 x 96]<li>CONV2 : 256 5x5 filters at stride 1, pad 2 -&gt; (27 + 2*2 - 5)/1 + 1 = 27 -&gt; [27 x 27 x 256], p=(5x5x96)x256<li>MAX POOL2 : 3x3 filters at stride 2 -&gt; (27 - 3)/2 + 1 = 13 -&gt; [13 x 13 x 256], p=0<li>NORM2 : [13 x 13 x 256]<li>CONV3 : 384 3x3 filters at stride 1, pad 1 -&gt; (13 + 2*1 - 3)/1 + 1 -&gt; 13 -&gt; [13 x 13 x 384], p=(3x3x256)x384<li>CONV4 : 384 3x3 filters at stride 1, pad 1 -&gt; (13 + 2*1 - 3)/1 + 1 -&gt; 13 -&gt; [13 x 13 x 384], p=(3x3x384)x384<li>CONV5 : 256 3x3 filters at stride 1, pad 1 -&gt; (13 + 2*1 - 3)/1 + 1 -&gt; 13 -&gt; [13 x 13 x 256], p=(3x3x384)x256<li>MAX POOL3 : 3x3 filters at stride 2 -&gt; (13 -3)/2 + 1 = 6 -&gt; [6 x 6 x 256], p=0<li>FC1 : p=4096<li>FC2 : p=4096<li>FC3 : p=1000</ul><p>사실 이것은 summary 함수를 통해 확인해볼 수 있다.</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
</pre><td class="rouge-code"><pre>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 56, 56]          23,296
              ReLU-2           [-1, 64, 56, 56]               0
         MaxPool2d-3           [-1, 64, 27, 27]               0
            Conv2d-4          [-1, 192, 27, 27]         307,392
              ReLU-5          [-1, 192, 27, 27]               0
         MaxPool2d-6          [-1, 192, 13, 13]               0
            Conv2d-7          [-1, 384, 13, 13]         663,936
              ReLU-8          [-1, 384, 13, 13]               0
            Conv2d-9          [-1, 256, 13, 13]         884,992
             ReLU-10          [-1, 256, 13, 13]               0
           Conv2d-11          [-1, 256, 13, 13]         590,080
             ReLU-12          [-1, 256, 13, 13]               0
        MaxPool2d-13            [-1, 256, 6, 6]               0
AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0
          Dropout-15                 [-1, 9216]               0
           Linear-16                 [-1, 4096]      37,752,832
             ReLU-17                 [-1, 4096]               0
          Dropout-18                 [-1, 4096]               0
           Linear-19                 [-1, 4096]      16,781,312
             ReLU-20                 [-1, 4096]               0
           Linear-21                 [-1, 1000]       4,097,000
================================================================
Total params: 61,100,840
Trainable params: 61,100,840
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.59
Forward/backward pass size (MB): 8.49
Params size (MB): 233.08
Estimated Total Size (MB): 242.16
</pre></table></code></div></div><p>구조를 자세히보면 모델 끝에는 3개의 FC layer가 있다. 2개의 fc layer은 4096 node를 가지고, 마지막 layer은 FC layer은 softmax를 통과하여 1000개의 imageNet 클래스를 분류한다.</p><p><strong>ReLU</strong>, <strong>dropout</strong>을 사용하였고, <strong>batch size</strong>는 128이다. optimization으로는 <strong>SGD momentum</strong>을 사용했다. 초기의 lr은 1e-2이었다가 <code class="language-plaintext highlighter-rouge">val accuracy</code>가 올라가지 않는 지점에서는 학습이 종료되는 시점까지 1e-10까지 줄였다. <strong>weight decay</strong>를 사용했고, 마지막에는 <strong>모델 앙상블</strong>로 성능을 향상시켰다.</p><p>이 당시에는 Batch Normalization이 존재하지 않았기 때문에, flip, jitter, colo norm 등의 data augmentation을 많이 사용했다.</p><p><br /></p><p><img data-src="/assets/img/cs231n/2021-09-29/0019.jpg" alt="image" data-proofer-ignore></p><p>다른 Network와의 차이점이라 하면 모델이 두개로 나뉘어져 서로 교차한다는 점이다. 그 당시의 GPU의 메모리가 3GB뿐이었기에, 분산시켜 넣은 것이다. 즉, 각 GPU에의 Depth는 48이다.</p><p><br /></p><p><img data-src="/assets/img/cs231n/2021-09-29/0020.jpg" alt="image" data-proofer-ignore></p><p>conv1,2,4,5 는 같은 gpu내에 있는 feature map만 사용하기 때문에 각 gpu는 48개의 feature map만 사용한다.</p><p><br /></p><p><img data-src="/assets/img/cs231n/2021-09-29/0021.jpg" alt="image" data-proofer-ignore></p><p>그러나 conv3, FC6,7,8 은 이전 계층의 <code class="language-plaintext highlighter-rouge">전체 feature map</code>과 연결되어 있다. 이 layer 들은 gpu간의 통신을 하기 떄문에 전체 depth를 전부 가져올 수 있는 것이다.</p><p><br /></p><p><br /></p><p>alexnet은 2012년 image classification benchmark에서 우승한 모델이다. 최초의 CNN 기반 우승 모델이고, CNN을 보편화시킨 모델이라 볼 수 있다.</p><p><br /></p><p><br /></p><h2 id="zfnet">ZFNet <a href="#zfnet" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>ZFNet은 2013년 imageNet challange에서 우승한 모델이다.</p><p><img data-src="/assets/img/cs231n/2021-09-29/0024.jpg" alt="image" data-proofer-ignore></p><p>alexnet과 레이어 수가 같고, 기본적인 구조가 같다. stride size, 필터 수 와 같은 하이퍼파라미터를 조절하여 개선한 모델이다.</p><p><br /></p><p><br /></p><h2 id="vggnet">VGGNet <a href="#vggnet" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>2014년에는 엄청난 변화가 있었다. architecture도 변하고, 성능도 훨씬 향상되었다. 가장큰 차이점은 <strong>네트워크가 훨씬 깊어</strong>진 것이다. 이전의 8개 layer에서 19개의 layer와 22개의 layer로 늘어났다.</p><p>2014년의 우승 모델은 GoogLeNet이고 VGGNet이 2등이었다. 하지만, 다른 트랙에서 VGGNet이 1위를 차지했다.</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
</pre><td class="rouge-code"><pre>VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (17): ReLU(inplace=True)
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (24): ReLU(inplace=True)
    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (26): ReLU(inplace=True)
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): ReLU(inplace=True)
    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (33): ReLU(inplace=True)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): ReLU(inplace=True)
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
</pre></table></code></div></div><p>우선 VGGNet을 살펴보자면, 네트워크가 훨씬 더 깊어졌고, 더 작은 필터를 사용했다. 16~19개의 layer을 사용하고, 3x3필터만 사용했다. 주기적으로 pooling을 수행하였다. vggnet은 아주 간단하면서도 고급진 아키텍처이다.</p><p><br /></p><p>3x3 필터를 사용한 이유는 필터가 작으면 파라미터의 수가 작아진다. 따라서 큰 필터에 비해 layer를 조금 더 많이 쌓을 수 있다. 즉, <code class="language-plaintext highlighter-rouge">depth</code>를 더 키울 수 있는 것이다.</p><p>그렇다면, stride = 1인 3x3 필터를 3 개 쌓을 때의 <strong>receptive field</strong>는 어떻게 될까?</p><p>receptive field는 필터가 한번에 볼 수 있는 입력의 영역을 의미한다.</p><p>첫번째 layer의 receptive field는 3x3이다. 두번째 layer의 경우 첫번째의 layer 출력의 3x3만큼 보고, 3x3중 각 사이드는 한 픽셀씩 더 볼 수 있다. 따라서 두번째 layer는 실제로 5x5 receptive field를 가진다. 세번째 layer는 두번째 layer의 3x3을 보게 되므로 입력 layer의 7x7을 보게 된다.</p><p>따라서, 3x3 필터를 3개 쌓는 것은 하나의 7x7 필터를 사용하는 것과 같다. ????????? <img data-src="https://theaisummer.com/static/490be17ee7f19b78003c3fdf5a6bbafc/83b75/receptive-field-in-convolutional-networks.png" alt="image" data-proofer-ignore></p><p>실질적인 receptive field를 동일하게 가지면서 파라미터 개수를 줄일 수 있고, non-linearity를 늘릴 수 있기 때문에 3x3 필터가 이점을 가질 수 있는 것이다.</p><ul><li>3x3 필터의 파라미터 수는 depth가 3이라는 가정하에, (filter 크기) x feature map depth = (3X3X3) X 3 = 81, 3개를 쌓아야 하므로 81x3 = 243<li>7x7 의 경우 7x7x3x3x1 = 441</ul><p>따라서 3x3필터를 3개 쓰는 것이 7x7 필터 1개 쓰는 것보다 개수가 적다.</p><p><br /></p><p><br /></p><p>전체 구조와 파라미터 수는 다음과 같다.</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
</pre><td class="rouge-code"><pre>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 227, 227]           1,792
              ReLU-2         [-1, 64, 227, 227]               0
            Conv2d-3         [-1, 64, 227, 227]          36,928
              ReLU-4         [-1, 64, 227, 227]               0
         MaxPool2d-5         [-1, 64, 113, 113]               0
            Conv2d-6        [-1, 128, 113, 113]          73,856
              ReLU-7        [-1, 128, 113, 113]               0
            Conv2d-8        [-1, 128, 113, 113]         147,584
              ReLU-9        [-1, 128, 113, 113]               0
        MaxPool2d-10          [-1, 128, 56, 56]               0
           Conv2d-11          [-1, 256, 56, 56]         295,168
             ReLU-12          [-1, 256, 56, 56]               0
           Conv2d-13          [-1, 256, 56, 56]         590,080
             ReLU-14          [-1, 256, 56, 56]               0
           Conv2d-15          [-1, 256, 56, 56]         590,080
             ReLU-16          [-1, 256, 56, 56]               0
           Conv2d-17          [-1, 256, 56, 56]         590,080
             ReLU-18          [-1, 256, 56, 56]               0
        MaxPool2d-19          [-1, 256, 28, 28]               0
           Conv2d-20          [-1, 512, 28, 28]       1,180,160
             ReLU-21          [-1, 512, 28, 28]               0
           Conv2d-22          [-1, 512, 28, 28]       2,359,808
             ReLU-23          [-1, 512, 28, 28]               0
           Conv2d-24          [-1, 512, 28, 28]       2,359,808
             ReLU-25          [-1, 512, 28, 28]               0
           Conv2d-26          [-1, 512, 28, 28]       2,359,808
             ReLU-27          [-1, 512, 28, 28]               0
        MaxPool2d-28          [-1, 512, 14, 14]               0
           Conv2d-29          [-1, 512, 14, 14]       2,359,808
             ReLU-30          [-1, 512, 14, 14]               0
           Conv2d-31          [-1, 512, 14, 14]       2,359,808
             ReLU-32          [-1, 512, 14, 14]               0
           Conv2d-33          [-1, 512, 14, 14]       2,359,808
             ReLU-34          [-1, 512, 14, 14]               0
           Conv2d-35          [-1, 512, 14, 14]       2,359,808
             ReLU-36          [-1, 512, 14, 14]               0
        MaxPool2d-37            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-38            [-1, 512, 7, 7]               0
           Linear-39                 [-1, 4096]     102,764,544
             ReLU-40                 [-1, 4096]               0
          Dropout-41                 [-1, 4096]               0
           Linear-42                 [-1, 4096]      16,781,312
             ReLU-43                 [-1, 4096]               0
          Dropout-44                 [-1, 4096]               0
           Linear-45                 [-1, 1000]       4,097,000
================================================================
Total params: 143,667,240
Trainable params: 143,667,240
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.59
Forward/backward pass size (MB): 242.32
Params size (MB): 548.05
Estimated Total Size (MB): 790.96
----------------------------------------------------------------
</pre></table></code></div></div><p>VGG19를 불러왔다. forward/backward pass 시 필요한 메모리양이 242MB로 다른 아키텍처에 비해 많은 편이다.</p><p>전체 파라미터의 경우 alexnet보다 훨씬 많다. 가장 많은 파라미터를 사용하는 layer는 FC layer이다. FC layer가 fully connected(dense connection)되었기 때문이다. 최근 네트워크의 경우 파라미터를 줄이기 위해 FC layer를 없애기도 한다.</p><p>동일하게 활성함수로 relu를 사용하고, fc layer에서 dropout을 사용했다.</p><blockquote><p>Q. 네트워크가 깊어질수록 layer의 필터 개수를 늘려야 하는가?(channel depth를 늘려야 하는지) =&gt; 필수는 아니지만 depth를 늘리는 경우가 많은데, 계산량을 일정하게 유지시키기 위해서다. downsampling을 하면 Width와 Height가 작아져서 depth를 늘려도 부담이 적어진다.</p></blockquote><p><br /></p><p>모델 성능을 향상시키기 위해 앙상블 기법을 사용했다.</p><p>layer를 보면 conv3-64 라는 것이 있는데, 이는 64개 필터를 가진 3x3 conv 필터라는 뜻이다.</p><p>마지막 FC7은 1000 class를 분류하기 위한 layer로 아주 좋은 feature represetation(특징 표현)을 가지고 있다. 다른 task에서도 능력이 뛰어나기에 vgg가 많이 사용된다.</p><p><br /></p><p><br /></p><h2 id="googlenet">GoogLeNet <a href="#googlenet" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
</pre><td class="rouge-code"><pre><span class="nc">GoogLeNet</span><span class="p">(</span>
  <span class="p">(</span><span class="n">conv1</span><span class="p">):</span> <span class="nc">BasicConv2d</span><span class="p">(</span>
    <span class="p">(</span><span class="n">conv</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="p">(</span><span class="n">bn</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">)</span>
  <span class="p">(</span><span class="n">maxpool1</span><span class="p">):</span> <span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="n">conv2</span><span class="p">):</span> <span class="nc">BasicConv2d</span><span class="p">(</span>
    <span class="p">(</span><span class="n">conv</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="p">(</span><span class="n">bn</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">)</span>
  <span class="p">(</span><span class="n">conv3</span><span class="p">):</span> <span class="nc">BasicConv2d</span><span class="p">(</span>
    <span class="p">(</span><span class="n">conv</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="p">(</span><span class="n">bn</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">192</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">)</span>
  <span class="p">(</span><span class="n">maxpool2</span><span class="p">):</span> <span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="n">inception3a</span><span class="p">):</span> <span class="nc">Inception</span><span class="p">(</span>
    <span class="p">(</span><span class="n">branch1</span><span class="p">):</span> <span class="nc">BasicConv2d</span><span class="p">(</span>
      <span class="p">(</span><span class="n">conv</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">192</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="n">branch2</span><span class="p">):</span> <span class="nc">Sequential</span><span class="p">(</span>
      <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="nc">BasicConv2d</span><span class="p">(</span>
        <span class="p">(</span><span class="n">conv</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">192</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="n">bn</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">)</span>
      <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="nc">BasicConv2d</span><span class="p">(</span>
        <span class="p">(</span><span class="n">conv</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="n">bn</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">)</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="n">branch3</span><span class="p">):</span> <span class="nc">Sequential</span><span class="p">(</span>
      <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="nc">BasicConv2d</span><span class="p">(</span>
        <span class="p">(</span><span class="n">conv</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">192</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="n">bn</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">)</span>
      <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="nc">BasicConv2d</span><span class="p">(</span>
        <span class="p">(</span><span class="n">conv</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="n">bn</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">)</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="n">branch4</span><span class="p">):</span> <span class="nc">Sequential</span><span class="p">(</span>
      <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="nc">BasicConv2d</span><span class="p">(</span>
        <span class="p">(</span><span class="n">conv</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">192</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="n">bn</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">)</span>
    <span class="p">)</span>
  <span class="p">)</span>
  <span class="p">(</span><span class="n">inception3b</span><span class="p">):</span> <span class="nc">Inception</span><span class="p">(</span>
    <span class="p">(</span><span class="n">branch1</span><span class="p">):</span> <span class="nc">BasicConv2d</span><span class="p">(</span>
      <span class="p">(</span><span class="n">conv</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="n">branch2</span><span class="p">):</span> <span class="nc">Sequential</span><span class="p">(</span>
      <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="nc">BasicConv2d</span><span class="p">(</span>
        <span class="p">(</span><span class="n">conv</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="n">bn</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">)</span>
      <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="nc">BasicConv2d</span><span class="p">(</span>
        <span class="p">(</span><span class="n">conv</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="n">bn</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">192</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">)</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="n">branch3</span><span class="p">):</span> <span class="nc">Sequential</span><span class="p">(</span>
      <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="nc">BasicConv2d</span><span class="p">(</span>
        <span class="p">(</span><span class="n">conv</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="n">bn</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">)</span>
      <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="nc">BasicConv2d</span><span class="p">(</span>
        <span class="p">(</span><span class="n">conv</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="n">bn</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">)</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="n">branch4</span><span class="p">):</span> <span class="nc">Sequential</span><span class="p">(</span>
      <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="nc">BasicConv2d</span><span class="p">(</span>
        <span class="p">(</span><span class="n">conv</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="n">bn</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">)</span>
    <span class="p">)</span>
  <span class="p">)</span>
</pre></table></code></div></div><p>GoogLeNet은 총 22개의 layer을 가지고 있다.</p><p>GoogLeNet에서 가장 중요한 것은 효율적인 계산에 관한 그들만의 특별한 관점이 있고, 높은 계산량을 아주 효율적으로 수행하도록 네트워크가 디자인되어 있다.</p><p>GoogLeNet은 inception module을 여러 개 쌓아져 있다. 그리고 FC layer가 없다. 파라미터를 줄이기 위해서이다. 전체 파라미터가 6M 정도이다. 60M인 alexNet보다 훨씬 적은 양이다. 그럼에도 더욱 깊다.</p><p><br /></p><h3 id="inception-module">Inception module <a href="#inception-module" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>구글은 좋은 로컬 네트워크 typology를 디자인하고자 했고, network-in-network라는 개념으로 이를 구현했다.</p><p>여기서 local network를 inceptino module이라 한다. 내부에는 동일한 입력을 받는 다양한 필터가 <code class="language-plaintext highlighter-rouge">병렬</code>로 존재하고, 이 layer의 입력을 받아서 다양한 conv 연산을 수행한다.</p><p><img data-src="/assets/img/cs231n/2021-09-29/0037.jpg" alt="image" data-proofer-ignore></p><p>중간의 그림을 보면 1x1, 3x3, 5x5 conv에 3x3 pooling도 있다. 각 layer에서 각각의 출력 값이 나오는데, 이 출력은 모두 depth방향으로 합쳐진다.(concatenate) 이런 방식으로 합치면 하나의 tensor로 출력이 결정되고, 이 하나의 출력을 다음 layer로 전달하는 것이다.</p><p>지금까지는 다양한 연산을 수행하고 이를 하나로 합쳐준다는 단순한 방식(naive way)를 살펴보았다.</p><ul><li>naive way의 문제점</ul><p>계산 비용이 크다.</p><p><br /></p><p><img data-src="/assets/img/cs231n/2021-09-29/0049.jpg" alt="image" data-proofer-ignore></p><p>128개의 1x1 필터, 192개의 3x3필터, 96개의 5x5 필터가 있다고 하자. 그리고 입력 크기는 28x28x256이라고 하자.</p><p>stride를 조절하여 입/출력 간의 spatial dimension(receptive field)를 유지시킨다.</p><p><br /></p><p>이 경우 1x1 conv필터 하나당 28x28 feature map을 생성하게 되기 때문에, 1x1x128 conv의 출력은 28x28x128이 된다. 1x1 conv의 경우 입력 depth가 256이므로 동일하게 256인데, 128개의 필터 하나당 28x28 feature map을 생성하게 된다.</p><p>똑같이 3x3x192 conv를 하면 28x28x192 가, 5x5x96 conv를 하면 28x28x96이 출력될 것이다.</p><p>conv는 입력 depth인 256만 가지고 내적을 한다고 볼 수 있기 때문이다.</p><blockquote><p>즉, conv는 (입력 데이터 크기 W x H) x (filter 개수) 의 출력값을 가진다.</p></blockquote><p><br /></p><p>이 때, spatial dimention을 유지하기 위해 zero padding한다.</p><p>3x3 pooling layer의 경우 입력 그대로 28x28x256으로 나온다.</p><p><br /></p><p>이를 다 합치면 28x28x(128+192+96+256) = 28x28x672 의 출력값이 된다. 결론적으로 dimention은 변하지 않았지만, depth가 엄청나게 커졌다.</p><p><br /></p><p>1x1 conv에서의 전체 연산량은 28x28x128x256으로 엄청 많다. 3x3/5x5 도 마찬가지일 것이다. 특히 pooling layer에서는 더더욱 많다. 총 연산을 합치면 850M 정도가 된다.</p><p>레이어를 거칠수록 점점 더 늘어나게 된다. 이 문제를 해결하기 위해서 <strong>bottleneck layer</strong>를 이용한다.</p><p>bottleneck layer는 conv연산을 시작하기 전 입력을 더 낮은 차원으로 보내는 방법이다.</p><p><br /></p><p><img data-src="/assets/img/cs231n/2021-09-29/0052.jpg" alt="image" data-proofer-ignore></p><p>1x1 conv를 살펴보자. 1x1 conv는 내적을 수행한다. 그러면서 filter 개수를 활용해 depth만 줄일 수 있다. <strong>입력의 depth를 더 낮은 차원으로 만드</strong>는 것이다.</p><p>이를 input feature map들 간의 선형결합(linear combination) 이라고 하기도 한다.</p><p><br /></p><p><br /></p><p><img data-src="/assets/img/cs231n/2021-09-29/0055.jpg" alt="image" data-proofer-ignore></p><p>따라서, 3x3/5x5 conv 이전에 1x1 conv 64개를 추가한다. 또, pooling layer 이후에도 1x1 conv를 추가한다.</p><p>1x1 conv를 <strong>bottleneck layer</strong>의 역할로 추가되는 것이다.</p><p><br /></p><p>이전과 비교했을 때,</p><ul><li>1x1 conv 64 =&gt; 28x28x64x1x1x256<li>1x1 conv 64 =&gt; 28x28x64x1x1x256<li>1x1 conv 128 =&gt; 28x28x128x1x1x256<li>3x3 conv 192 =&gt; 28x28x192x3x3x64<li>5x5 conv 96 =&gt; 28x28x96x5x5x64<li>1x1 conv 64 =&gt; 28x28x64x1x1x256 =&gt; total 350M « 850M</ul><p>전과 확연히 차이나게 줄어들었다.</p><p>자세하게 보자면, 입력은 28x28x256이고, 3x3 conv 앞쪽의 1x1 conv 출력은 28x28x64이다.</p><p>따라서 28x28x64로 전의 28x28x256보다 줄었다.</p><p><strong>정리하면, 1x1 conv를 추가함으로써 계산량을 조절할 수 있다</strong></p><p>1x1 conv를 추가한다고 해서 데이터 변형이 일어나지 않는다.</p><p><br /></p><p><img data-src="/assets/img/cs231n/2021-09-29/0057.jpg" alt="image" data-proofer-ignore></p><p>GoogLeNet의 앞단(초기 6개 layer)에는 일반적인 네트워크 구조다. 이때는 conv-pool를 반복한다.</p><p>이후 inception module을 쌓는데, 모두 조금씩 다르다. 그리고 마지막에는 classifier 결과를 출력한다.</p><p><br /></p><p><img data-src="/assets/img/cs231n/2021-09-29/0061.jpg" alt="image" data-proofer-ignore></p><p>아래 부분을 보면 추가적으로 줄기가 뻗어져 있다. 이들은 보조분류기(auxiliary classifier)이다. 이것들은 작은 미니 네트워크다. average pooling과 1x1 conv가 있고 FC layer도 몇개 붙고, softmax로 1000개의 imageNet class를 구분한다.</p><p>이 부분에서도 loss를 계산한다. 네트워크 끝에서 뿐만 아니라 이 두곳에서도 계산하는 이유는 네트워크가 꽤 깊기 때문이다.</p><p>보조분류기를 중간 layer에 달아주면 추가적인 gradient를 얻을 수 있고, 중간 layer의 학습도 도울 수 있다.</p><p><br /></p><p>googleNet 학습 시 보조 분류기에서 나온 loss의 모든 합의 평균을 계산한다.</p><p>또, 보조분류기에서 추가적인 gradient를 얻는 이유는 네트워크가 엄청 깊은 경우 gradient 신호가 점점 작아지게 되고 결국 0에 가깝게 된다. 그래서 보조분류기를 이용해서 추가적인 gradient 신호를 추가한다.</p><p><br /></p><p><br /></p><h2 id="resnet">ResNet <a href="#resnet" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>resnet은 152개의 layer를 가진 엄청나게 깊은 네트워크다. ResNet은 residual connections 라는 방식을 사용한다.</p><p>맨 처음 생각한 방법은 conv-pool layer을 계속해서 깊게 쌓으면 성능이 좋아질까 라는 것이었다.</p><p>하지만 성능은 좋이지지 않았다.</p><p><br /></p><p>네트워크가 깊어지게 되면 어떤 일이 발생할까?</p><p><br /></p><p><br /></p><ul><li>20 layer Vs 56 layers</ul><p><img data-src="/assets/img/cs231n/2021-09-29/0067.jpg" alt="image" data-proofer-ignore></p><p>기본적으로 네트워크가 깊어지면 파라미터가 엄청 많아지기 때문에 overfit이 발생할 것이다. overfit이 발생하면 test error는 높더라도, training error는 아주 낮아야 정상이다.</p><p>하지만 56 layer을 보면 training error가 20 layer보다 안좋다.</p><p>따라서 더 깊은 모델임에도 test 성능이 낮은 이유는 overfitting 문제가 아니라는 것을 알 수 있다.</p><p><br /></p><p>여기서 ResNet 저자들은 더 깊은 모델 학습 시 최적화(optimization) 가 더 어려워진다는 가설을 세웠다.</p><p><br /></p><p>모델이 더 깊다면 적어도 더 얕은 모델만큼은 성능이 나와야 정상아닌가 생각할 것이다.</p><p>그래서 해결책으로 일단 더 얕은 모델의 가중치를 깊은 모델의 일부 레이어에 복사했다. 나머지 레이어는 identity mapping을 했다. identity mapping이란 input을 output으로 내보내는 것을 말한다.</p><p>이와 같이 얕은 모델을 복사해왔기 때문에, 비슷한 성능이 나올 수 있다.</p><p><br /></p><p>이 방식을 녹여 모델을 만들고자 했다.</p><p>ResNet의 아이디어는 단순히 layer를 쌓는 방법(direct mapping)이 아니라 <strong>residual mapping</strong>의 방법이었다.</p><p><br /></p><p><img data-src="/assets/img/cs231n/2021-09-29/0072.jpg" alt="image" data-proofer-ignore></p><p>레이어가 직접 <code class="language-plaintext highlighter-rouge">H(x)</code>를 학습하기보다 이와 같이 <code class="language-plaintext highlighter-rouge">H(x) - x</code>를 학습할 수 있도록 만들어준다. 이를 위해 <strong>skip connection</strong>를 도입한다.</p><p><br /></p><p><img data-src="/assets/img/cs231n/2021-09-29/0073.jpg" alt="image" data-proofer-ignore></p><p>오른쪽 고리 모양을 보면, skip connection은 가중치가 없으며 입력을 indentity mapping을 통해 그대로 출력단으로 보낸다.</p><p>실제 레이어는 변화량(delta)만 학습하면 된다. 입력 x에 대한 잔차(residual)이라 할 수 있다.</p><blockquote><p>즉, 원래의 출력인 <code class="language-plaintext highlighter-rouge">H(x)</code> 대신 <code class="language-plaintext highlighter-rouge">입력 x를 그대로</code> 가져와 <code class="language-plaintext highlighter-rouge">H(x)와 x의 차이(변화량)</code>인 <strong>F(x)만을 학습</strong>시킨다.</p></blockquote><p>그래서, 최종 출력 값은 input X + 변화량(residual) 이다.</p><p><br /></p><p>이 방법을 사용하면 학습이 더 쉬워진다. 가령 input = output 인 상황이라면 F(x)(residual) = 0 이므로 모든 가중치를 0 으로 만들어주면 된다.</p><p>네트워크는 residual만 학습하면 되기 때문에 한층 더 쉬워졌다. 전체 full mapping을 학습하는 대신, residual mapping 만 학습하는 것이고, 출력 값도 결국엔 입력 x와 가까운 값이기 때문이다.</p><p><br /></p><p>이때, layer의 출력과 skip connection의 출력은 같은 차원이다. 같지 않더라도 depth-wise padding으로 차원을 맞춰줄 수 있다.</p><p><br /></p><p><br /></p><p>사실 이것들은 ResNet 저자의 가설이었기에, 입증된 바는 없다. 그러나 실제로 ResNet을 사용할 때 성능이 더 좋아지기도 한다.</p><p><br /></p><p><br /></p><p><img data-src="/assets/img/cs231n/2021-09-29/0075.jpg" alt="image" data-proofer-ignore></p><p>전체 ResNet 구조를 나타낸 것이다. 아래는 직접 resnet을 불러온 결과를 가져와봤다.</p><p><br /></p><p><br /></p><p>하나의 residual blocks는 두개의 3x3 conv layer로 이루어져 있다. 이렇게 구성해야 잘 동작한다. 이 Residual block을 아주 깊게 쌓는다.</p><p>또한, 주기적으로 필터를 두배씩 늘리고, stride 2를 이용하여 downsampling한다.</p><p><br /></p><p><img data-src="/assets/img/cs231n/2021-09-29/0076.jpg" alt="image" data-proofer-ignore></p><p>그리고 맨 처음에 7x7 conv-64를 붙였고, 네트워크 끝에는 FC layer가 없다. 그 대신 global average pooling layer를 사용한다. 맨 마지막에 존재하는 FC 1000 은 클래스 분류를 위한 노드이다.</p><p>GAP(global average pooling layer)는 하나의 map 전체를 average pooling 하는 것을 말한다.</p><p><br /></p><p><br /></p><p>ResNet 중에서도 가장 많이 사용되고 있는 모델은 resnet101 이다. 101은 모델의 depth(layer)를 말한다. 101말고도 34, 50 100, 152 등이 있다.</p><p><img data-src="/assets/img/cs231n/2021-09-29/0079.jpg" alt="image" data-proofer-ignore></p><p>depth가 50이상일 때 1x1 conv를 도입하여 depth를 줄이는 bottleneck layer를 도입한다. 이는 GoogLeNet에서 사용한 방법과 유사하다.</p><p>bottleneck layer을 통해 3x3 conv의 계산량을 줄인다. 그리고 뒤에 다시 1x1 conv를 추가하여 depth를 다시 원래대로 늘린다.</p><p><br /></p><p><strong>정리하자면</strong></p><ul><li>모든 conv layer 다음에 batch norm 을 사용한다.<li>초기화로는 Xavier을 사용하는데, 추가적으로 scaling factor(2로 나눔)를 더 수행한다. 이 방법은 SGD + momentum 에서 좋은 초기화 성능을 보인다.<li>learning rate는 validation error가 줄어들지 않는 시점에서 조금씩 줄여주며 조절한다.<li>minibatch size = 256<li>weight dacay 사용, 1e-5<li>dropout 사용 x</ul><p><br /></p><p><br /></p><p>ResNet의 top-5 error은 3.6%로 인간의 성능(5%)보다 뛰어나다고 한다.</p><p><br /></p><p>아래는 ResNet 아키텍처를 직접 가져와봤다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
</pre><td class="rouge-code"><pre><span class="s">''' ResNet101 structure '''</span>
<span class="nc">ResNet</span><span class="p">(</span>
  <span class="p">(</span><span class="n">conv1</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
  <span class="p">(</span><span class="n">bn1</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="n">relu</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">(</span><span class="n">maxpool</span><span class="p">):</span> <span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
  <span class="p">(</span><span class="n">layer1</span><span class="p">):</span> <span class="nc">Sequential</span><span class="p">(</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="nc">Bottleneck</span><span class="p">(</span>
      <span class="p">(</span><span class="n">conv1</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn1</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">conv2</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn2</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">conv3</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn3</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">relu</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">downsample</span><span class="p">):</span> <span class="nc">Sequential</span><span class="p">(</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">)</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="nc">Bottleneck</span><span class="p">(</span>
      <span class="p">(</span><span class="n">conv1</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn1</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">conv2</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn2</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">conv3</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn3</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">relu</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="nc">Bottleneck</span><span class="p">(</span>
      <span class="p">(</span><span class="n">conv1</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn1</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">conv2</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn2</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">conv3</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn3</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">relu</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">)</span>
  <span class="p">)</span>
  <span class="p">(</span><span class="n">layer2</span><span class="p">):</span> <span class="nc">Sequential</span><span class="p">(</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="nc">Bottleneck</span><span class="p">(</span>
      <span class="p">(</span><span class="n">conv1</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn1</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">conv2</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn2</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">conv3</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn3</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">relu</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">downsample</span><span class="p">):</span> <span class="nc">Sequential</span><span class="p">(</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">)</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="nc">Bottleneck</span><span class="p">(</span>
      <span class="p">(</span><span class="n">conv1</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn1</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">conv2</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn2</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">conv3</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn3</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">relu</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="nc">Bottleneck</span><span class="p">(</span>
      <span class="p">(</span><span class="n">conv1</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn1</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">conv2</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn2</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">conv3</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn3</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">relu</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">):</span> <span class="nc">Bottleneck</span><span class="p">(</span>
      <span class="p">(</span><span class="n">conv1</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn1</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">conv2</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn2</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">conv3</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">bn3</span><span class="p">):</span> <span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">relu</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">)</span>
  <span class="p">)</span>
</pre></table></code></div></div><p><br /></p><p><br /></p><h3 id="resnet과-관련된-최근-연구들">ResNet과 관련된 최근 연구들 <a href="#resnet과-관련된-최근-연구들" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>Identity Mapping in Deep Residual Networks</ul><p>이 논문에서는 ResNet의 블록 디자인을 향상시켰다. 그 방법으로 ResNet block path를 조절했다.</p><p><img data-src="/assets/img/cs231n/2021-09-29/0093.jpg" alt="image" data-proofer-ignore></p><p>새로운 구조는 direct path 간격을 늘려서 정보들이 앞으로 더욱 더 잘 전달되고 backprop도 더 잘 될 수 있도록 한 것이다.</p><p><br /></p><ul><li>Wide Residual Networks</ul><p>기존의 ResNet 논문은 깊게 쌓는 것에 집중했지만, 사실 중요한 것은 depth가 아니라 residual이라 주장한 논문이다.</p><p>residual connection이 있다면 네트워크가 굳이 더 깊게 필요가 없다고 주장한다.</p><p><img data-src="/assets/img/cs231n/2021-09-29/0094.jpg" alt="image" data-proofer-ignore></p><p>그래서 깊이 대신 residual block을 더 넓게 만들었다. 즉, <code class="language-plaintext highlighter-rouge">conv layer의 필터를 더 많이 추가</code>한 것이다.</p><p>원래 F개의 filter가 존재했다면 여기서는 F * k개의 필터를 사용한다.</p><p><br /></p><p>그렇게 하여 50 layer만 있어도 152 layer의 resnet보다 성능이 좋다는 것을 입증했다.</p><p><br /></p><p>이 방법의 또 다른 이점은 계산 효율이 증가한 것이다. 왜냐하면 병렬화가 더 잘되기 때문이다.</p><p>네트워크의 depth를 늘리는 것은 sequential의 증가, 즉 위아래로 늘어나는 것이라면, conv 필터를 늘리는 것은 width가 넓어지는 것이다.</p><p><br /></p><p><br /></p><ul><li>ResNeXt</ul><p>ResNet의 저자의 논문으로 residual block의 width를 계속 연구한다. filter 수를 늘리는 것이다. 각 redisual block 내에 다중 병렬 경로를 추가한다. 이들은 pathway(경로)의 총 합을 cardinality(관계수)라고 불렀다.</p><p>하나의 bottleneck ResNet block은 비교적 작지만 이런 얇은 block들이 병렬로 여러 개를 묶었다.</p><p>layer를 병렬로 묶는다는 것에서 inception module과도 연관이 있다.</p><p><br /></p><p><br /></p><ul><li>Stochastic Depth</ul><p>이 논문의 주제는 depth이다. 네트워크가 깊어질수록 vanishing gradient가 발생한다. 뒤로 전달될수록 점점 grdient가 작아진다.</p><p>그래서 train time에서 layer의 일부를 제거하여 short network를 만들어 training 능력을 약간 향상시키는 것이다.</p><p>그 방법으로 일부 네트워크를 골라 identity connection으로 만들어버린다. dropout과 유사하다고 볼 수 있다. 동일하게 test time에서는 full layer를 사용한다.</p><p><br /></p><p><br /></p><p>이제 좀 다른 아키텍처들을 살펴보고자 한다.</p><p><br /></p><h2 id="other-network-architecture">Other Network architecture <a href="#other-network-architecture" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>Network in Network (NiN)</ul><p><img data-src="/assets/img/cs231n/2021-09-29/0092.jpg" alt="image" data-proofer-ignore></p><p>기본 아이디어는 MLP conv layer이다. 네트워크 안에 작은 네트워크를 삽입하는 것이다. 각 conv layer 안에 (MLP(Multi-layer perceptron) = FC layer)을 쌓는다.</p><p>단순히 conv filter만 사용하지 않고, 좀더 복잡한 계층을 만들어서 feature map을 얻어보자는 아이디어다.</p><p>NIN은 기본적으로 FC layer을 사용한다. 이를 1x1 conv layer라고도 한다.</p><p><br /></p><p>GoogLeNet이나 ResNet보다 먼저 bottleneck 개념을 정립했다.</p><p><br /></p><p><br /></p><ul><li>FractalNet</ul><p>이 논문에서는 residual connection이 필요없다고 주장한다. 그래서 FractalNet에서는 residual connection이 전혀 없다.</p><p><img data-src="/assets/img/cs231n/2021-09-29/0097.jpg" alt="image" data-proofer-ignore></p><p>그들은 오른쪽 그림과 같이 fractal(차원분열도형)한 모습이다.</p><p>FactalNet에서는 shallow(얕은)/deep 경로를 출력에 모두 연결한다. 다양한 경로가 존재하지만 train time에는 dropout과 같이 일부 경로만을 이용해서 train한다.</p><p><br /></p><p><br /></p><ul><li>DenseNet</ul><p><img data-src="/assets/img/cs231n/2021-09-29/0098.jpg" alt="image" data-proofer-ignore></p><p>densely connected convolutional network, 즉 빼곡하게 연결된 convolutional network 이다.</p><p>dense block을 사용하는데, 한 layer가 그 layer 하위의 모든 layer와 연결된다. 네트워크의 입력 이미지가 모든 layer의 입력으로 들어가는 것이다. 그 모든 layer의 출력이 각 layer의 출력과 concat(합침)된다.</p><p><br /></p><p>이 dense block을 통해 vanishing gradient 문제를 완화시킬 수 있다고 주장한다.</p><p>그리고 dense connection은 feature을 더 잘 전달하고 더 잘 사용할 수 있게 해준다고 한다. 각 layer의 출력을 다른 layer에서도 여러번 사용하기 때문이다.</p><p><br /></p><p><br /></p><ul><li>SqueezeNet</ul><p><img data-src="/assets/img/cs231n/2021-09-29/0099.jpg" alt="image" data-proofer-ignore></p><p>여기서는 fire module이라는 것을 도입했다. squeeze layer는 1x1 filter들로 구성되고, 출력 값이 1x1,3x3 filter들로 구성되는 expand layer의 입력이 된다. squeezeNet은 AlexNet 과 비슷한 accuracy를 보이지만 파라미터는 50배 더 적다.</p><p><br /></p><p><br /></p><p><br /></p><h2 id="comparing-model-complexity">Comparing Model Complexity <a href="#comparing-model-complexity" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-src="/assets/img/cs231n/2021-09-29/0084.jpg" alt="image" data-proofer-ignore></p><p>지금까지 배운 모델이거나 조금 변형된 모델들이다.</p><p>incetion을 보면 V2,V3 등이 있는데 가장 좋은 모델은 당연히 V4이다. v4는 resnet + inception 모델이다.</p><p>오른쪽 그래프를 보면 계산 복잡성이 추가하여 볼 수 있다. y축은 top-1 accuracy로 높을수록 좋다. x축은 연산량으로 오른쪽일수록 연산량이 많다. 원의 크기는 메모리 사용량이다.</p><p><br /></p><p>초록색 원은 VGGNet이다. 가장 효율성이 작다. 메모리는 크면서 계산량이 많다. 성능은 나쁘지 않다.</p><p>파란색 원은 GoogLeNet인데, 가장 효율적인 네트워크다. 거의 왼쪽에 있으며 메모리 사용량도 작다.</p><p>초기 AlexNet 모델은 accuracy가 낮다. 계산량은 작지만, 메모리 사용량이 비효율적이다.</p><p>ResNet의 경우 적당한 효율성을 가지고 있다. 메모리 사용량과 계산량은 중간이지만, accuracy가 최상위에 있다.</p><p><br /></p><p><img data-src="/assets/img/cs231n/2021-09-29/0090.jpg" alt="image" data-proofer-ignore></p><p>왼쪽 그래프틑 forward pass 시간이다. 단위는 ms인데, VGG가 제일 오래걸린다. 200ms, 즉 초당 5정도 처리한다.</p><p>오른쪽은 전력소모량인데, 이는 논문을 참고하길 바란다.</p><p><a href="https://arxiv.org/abs/1605.07678">https://arxiv.org/abs/1605.07678</a></p><p><br /></p><p><br /></p><p><br /></p><h1 id="reference">Reference</h1><ul><li><a href="http://cs231n.stanford.edu/2017/syllabus.html">http://cs231n.stanford.edu/2017/syllabus.html</a><li><a href="https://velog.io/@guide333/%ED%92%80%EC%9E%8E%EC%8A%A4%EC%BF%A8-CS231n-9%EA%B0%95-Training-Neural-Networks-Part-2-2">https://velog.io/@guide333/%ED%92%80%EC%9E%8E%EC%8A%A4%EC%BF%A8-CS231n-9%EA%B0%95-Training-Neural-Networks-Part-2-2</a><li><a href="https://velog.io/@cha-suyeon/CS231n-Lecture-9-%EA%B0%95%EC%9D%98-%EC%9A%94%EC%95%BD">https://velog.io/@cha-suyeon/CS231n-Lecture-9-%EA%B0%95%EC%9D%98-%EC%9A%94%EC%95%BD</a></ul></div><div class="post-tail-wrapper text-muted"><div style="text-align: left;"> <a href="http://hits.dwyl.com/dkssud8150.github.io/posts/cs231n9/" target="_blank"> <img data-src="http://hits.dwyl.com/dkssud8150.github.io/posts/cs231n9.svg" data-proofer-ignore> </a></div><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/classlog/'>Classlog</a>, <a href='/categories/cs231n/'>CS231N</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/cs231n/" class="post-tag no-text-decoration" >CS231N</a> <a href="/tags/cnn-architecture/" class="post-tag no-text-decoration" >CNN-architecture</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=CS231N chapter 9 - CNN Architectures - JaeHo Yoon&amp;url=https://dkssud8150.github.io/posts/cs231n9/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=CS231N chapter 9 - CNN Architectures - JaeHo Yoon&amp;u=https://dkssud8150.github.io/posts/cs231n9/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https://dkssud8150.github.io/posts/cs231n9/&amp;text=CS231N chapter 9 - CNN Architectures - JaeHo Yoon" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://dkssud8150.github.io/posts/cs231n9/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6611243953442169" crossorigin="anonymous"></script></div><script src="https://utteranc.es/client.js" repo="dkssud8150/dkssud8150.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/gitpage/">[깃허브 프로필 꾸미기] github 프로필 만들기</a><li><a href="/posts/product/">[깃허브 프로필 꾸미기] productive box 만들기</a><li><a href="/posts/regex/">[데브코스] 2주차 - linux 기초(REGEX)</a><li><a href="/posts/Kfold/">KFold Cross Validation 과 StratifiedKFold</a><li><a href="/posts/cmake/">[데브코스] 17주차 - CMake OpenCV, Eigen, Pangolin install </a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/devcourse/">devcourse</a> <a class="post-tag" href="/tags/deeplearning/">deeplearning</a> <a class="post-tag" href="/tags/cs231n/">CS231N</a> <a class="post-tag" href="/tags/ros/">ros</a> <a class="post-tag" href="/tags/coding-test/">coding test</a> <a class="post-tag" href="/tags/linux/">linux</a> <a class="post-tag" href="/tags/kooc/">kooc</a> <a class="post-tag" href="/tags/opencv/">OpenCV</a> <a class="post-tag" href="/tags/pytorch-tutorial/">pytorch tutorial</a> <a class="post-tag" href="/tags/autonomous-driving/">Autonomous Driving</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/cs231n1/"><div class="card-body"> <em class="timeago small" date="2021-09-04 13:00:00 +0900" >Sep 4, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>CS231N chapter 1 - Course Introduction</h3><div class="text-muted small"><p> A brief history of Computer Vision Biological Vision 아주 먼 옛날, 눈을 통해 동물들은 진화했다. Human Vision 카메라와 같이 사람의 눈과 유사하게 사진을 담을 수 있도록 만들어졌다. Computer Vision ** David Mars** 이미지를 인식하고 최종...</p></div></div></a></div><div class="card"> <a href="/posts/cs231n2/"><div class="card-body"> <em class="timeago small" date="2021-09-04 13:00:00 +0900" >Sep 4, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>CS231N chapter 2 - Image Classification</h3><div class="text-muted small"><p> numpy를 이용한 텐서 사용이 익숙하지 않는 사람들을 위한 튜토리얼 Image Classification 이미지를 볼 때 컴퓨터는 거대한 숫자 그리드로 표현한다. 그것을 통해 컴퓨터는 미리 정의된 class 레이블 중 하나를 지정한다. 이 이미지의 경우 800x600 픽셀로 이루어져 있다. 또한, 3채널 즉, RGB로 표현되기 때문에 8...</p></div></div></a></div><div class="card"> <a href="/posts/cs231n3/"><div class="card-body"> <em class="timeago small" date="2021-09-12 13:00:00 +0900" >Sep 12, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>CS231N chapter 3 - Loss function and Optimizations</h3><div class="text-muted small"><p> 2강 리뷰 1) image deformation 2) 그를 해결하기 위한 data-driven approach 3) Nearest Neighbor method, K-Nearest Neighbor(KNN) 4) cross validation 5) hyperparameter 6) linear cl...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/cs231n8/" class="btn btn-outline-primary" prompt="Older"><p>CS231N chapter 8 - Deep Learning Softwares</p></a> <a href="/posts/cs231n10/" class="btn btn-outline-primary" prompt="Newer"><p> CS231N chapter 10 - Recurrent Neural Networks</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">JaeHo YooN</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/devcourse/">devcourse</a> <a class="post-tag" href="/tags/deeplearning/">deeplearning</a> <a class="post-tag" href="/tags/cs231n/">CS231N</a> <a class="post-tag" href="/tags/ros/">ros</a> <a class="post-tag" href="/tags/coding-test/">coding test</a> <a class="post-tag" href="/tags/linux/">linux</a> <a class="post-tag" href="/tags/kooc/">kooc</a> <a class="post-tag" href="/tags/opencv/">OpenCV</a> <a class="post-tag" href="/tags/pytorch-tutorial/">pytorch tutorial</a> <a class="post-tag" href="/tags/autonomous-driving/">Autonomous Driving</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { function updateMermaid(event) { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { const mode = event.data.message; if (typeof mermaid === "undefined") { return; } let expectedTheme = (mode === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* Re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } let initTheme = "default"; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); window.addEventListener("message", updateMermaid); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-NC7MWHVXJE"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-NC7MWHVXJE'); }); </script>