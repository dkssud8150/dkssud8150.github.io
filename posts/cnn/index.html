<!DOCTYPE html><html lang="en" data-mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="[데브코스] 10주차 - DeepLearning CNN" /><meta name="author" content="JaeHo YooN" /><meta property="og:locale" content="en" /><meta name="description" content="Do focus on developing ‘your ability’ rather than waste time on making you famous." /><meta property="og:description" content="Do focus on developing ‘your ability’ rather than waste time on making you famous." /><link rel="canonical" href="https://dkssud8150.github.io/posts/cnn/" /><meta property="og:url" content="https://dkssud8150.github.io/posts/cnn/" /><meta property="og:site_name" content="JaeHo Yoon" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-04-19T02:40:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="[데브코스] 10주차 - DeepLearning CNN" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@JaeHo YooN" /><meta name="google-site-verification" content="znvuGsQGYxMZPBslC4XG6doCYao6Y-fWibfGlcaMHH8" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"JaeHo YooN"},"dateModified":"2022-05-17T02:56:35+09:00","datePublished":"2022-04-19T02:40:00+09:00","description":"Do focus on developing ‘your ability’ rather than waste time on making you famous.","headline":"[데브코스] 10주차 - DeepLearning CNN","mainEntityOfPage":{"@type":"WebPage","@id":"https://dkssud8150.github.io/posts/cnn/"},"url":"https://dkssud8150.github.io/posts/cnn/"}</script><title>[데브코스] 10주차 - DeepLearning CNN | JaeHo Yoon</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="JaeHo Yoon"><meta name="application-name" content="JaeHo Yoon"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/shin_chan.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">JaeHo Yoon</a></div><div class="site-subtitle font-italic">Mamba Mentality</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fab fa-angellist ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/dkssud8150" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['hoya58150','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="https://www.notion.so/18490713817d403696812c57d0abe730" aria-label="notion" target="_blank" rel="noopener"> <i class="fab fa-battle-net"></i> </a> <a href="https://www.linkedin.com/in/jaeho-yoon-90b62b230" aria-label="linkedin" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href="https://www.instagram.com/jai_ho8150/" aria-label="instagram" target="_blank" rel="noopener"> <i class="fab fa-instagram"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>[데브코스] 10주차 - DeepLearning CNN</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>[데브코스] 10주차 - DeepLearning CNN</h1><div class="post-meta text-muted"><div> By <em> <a href="https://github.com/dkssud8150">JaeHo YooN</a> </em></div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6611243953442169" crossorigin="anonymous"></script><div class="d-flex"><div> <span> Posted <em class="timeago" date="2022-04-19 02:40:00 +0900" data-toggle="tooltip" data-placement="bottom" title="Tue, Apr 19, 2022, 2:40 AM +0900" >Apr 19, 2022</em> </span> <span> Updated <em class="timeago" date="2022-05-17 02:56:35 +0900 " data-toggle="tooltip" data-placement="bottom" title="Tue, May 17, 2022, 2:56 AM +0900" >May 17, 2022</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="5544 words"> <em>30 min</em> read</span></div></div></div><div class="post-content"><p><br /></p><p>CNN을 들어가기 전에 DMLP에 대해 잠깐 살펴보고자 한다.</p><h2 id="dmlpdeep-multi-layer-perceptron">DMLP(Deep Multi Layer Perceptron) <a href="#dmlpdeep-multi-layer-perceptron" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>딥러닝을 들어가기에 앞서 DMLP의 형태가 있다. 이는 다층 퍼셉트론보다 더 깊게 layer를 쌓은 것을 말하는데, 이는 완전 연결 구조를 가진다. 그에 따라 복잡도가 높아지고, 학습이 매우 느려진다. 또한 과잉적합(overfitting)이 발생할 수 있다.</p><p><img data-src="\assets\img\dev\week11\day1\dmlp.png" data-proofer-ignore></p><p>그러나 CNN(convolutional neural network)의 경우 부분적으로 연결되어 있는 구조로 인해 격자 구조를 갖는 데이터에 적합하다.컨볼루션 연산을 통해 특징을 추출하고 영상 분류나 문자 인식 등 인식문제에서 높은 성능을 보인다.</p><p><br /></p><p><br /></p><h1 id="convolutional-neural-network">Convolutional Neural Network</h1><h2 id="convolution">Convolution <a href="#convolution" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>padding : add zero in boundary of input image<li>stride : elements of sliding window of convolution kernel</ul><p>output shape</p><ul><li>output height : (input height - kernel height + padding size * 2) // stride + 1<li>output width : (input width - kernel width + padding size * 2) // stride + 1</ul><p><code class="language-plaintext highlighter-rouge">A * w = B</code>의 연산의 경우</p><ul><li>A shape : [batch, input channel, input height, input width]<li>w shape : [output channel ,input channel, kernel height, kernel width]<li>B shape : [batch, output channel, output height ,output width]</ul><p><br /></p><p>연산량을 따질 때는 MAC(Multiply Accumulation Operation)단위를 사용한다.</p><p>convolution MAC : kw*kh*kc*oc*ow*oh*b(k:kernel, o:output, b:batch)</p><p>이 convolution은 sliding window 방식을 통해 연산을 수행하기 되고, 이를 for문으로 나타내면 다음과 같다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">oh</span> <span class="ow">in</span> <span class="n">output_height</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">ow</span> <span class="ow">in</span> <span class="n">output_width</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">oc</span> <span class="ow">in</span> <span class="n">output_channel</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">kc</span> <span class="ow">in</span> <span class="n">kernel_channel</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">kh</span> <span class="ow">in</span> <span class="n">kernel_height</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">kw</span> <span class="ow">in</span> <span class="n">kernel_width</span><span class="p">:</span>
</pre></table></code></div></div><p>총 7번의 루프로 동작한다.</p><p><br /></p><p>이는 너무 비효율적이기 때문에 <code class="language-plaintext highlighter-rouge">IM2COL &amp; GEMM</code> 방식을 통해 더 간편한 연산 방식을 사용할 수 있다.</p><ul><li>IM2COL</ul><p>n-dimension의 data를 2D matrix data로 변환시켜 더 효율적으로 연산한다.</p><p><img data-src="/assets/img/dev/week10/day2/im2col.png" data-proofer-ignore> <img data-src="/assets/img/dev/week10/day2/im2col2.png" data-proofer-ignore></p><p>data와 kernel을 2차원으로 변환하여 연산하면 2차원의 값이 출력될 것이다. 이를 다시 원래의 차원으로 변환하면 연산이 효율적으로 진행된다.</p><ul><li>kernel : [oc, kh*kw*ic]<li>input : [kh*kw*ic, oh*ow]<li>output : [oc, oh*ow]</ul><p>이렇게 변환된 matrix를 연산하는 과정 자체를 <strong>GEMM(General Matrix to Matrix Multiplication)</strong>이라고 한다.</p><p><a href="https://welcome-to-dewy-world.tistory.com/94">참고자료</a></p><p><br /></p><p><br /></p><h1 id="cnn-numpy">CNN (numpy)</h1><p>이 CNN의 연산을 pytorch나 tensorflow가 아닌 numpy만을 사용하여 구현해보고자 한다.</p><p>과정</p><ol><li>sliding window convolution<li>IM2COL GEMM convolution</ol><p><br /></p><h2 id="sliding-window-방식">sliding window 방식 <a href="#sliding-window-방식" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>function/convolution.py</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">class</span> <span class="nc">Conv</span><span class="p">:</span>
    <span class="c1"># dilation : kernel이 얼마나 간격을 띄우고 연산할지에 대한 값
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">in_c</span><span class="p">,</span> <span class="n">out_c</span><span class="p">,</span> <span class="n">in_h</span><span class="p">,</span> <span class="n">in_w</span><span class="p">,</span> <span class="n">k_h</span><span class="p">,</span> <span class="n">k_w</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">pad</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">self</span><span class="p">.</span><span class="n">in_c</span> <span class="o">=</span> <span class="n">in_c</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out_c</span> <span class="o">=</span> <span class="n">out_c</span>
        <span class="n">self</span><span class="p">.</span><span class="n">in_h</span> <span class="o">=</span> <span class="n">in_h</span>
        <span class="n">self</span><span class="p">.</span><span class="n">in_w</span> <span class="o">=</span> <span class="n">in_w</span>
        <span class="n">self</span><span class="p">.</span><span class="n">k_h</span> <span class="o">=</span> <span class="n">k_h</span>
        <span class="n">self</span><span class="p">.</span><span class="n">k_w</span> <span class="o">=</span> <span class="n">k_w</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dilation</span> <span class="o">=</span> <span class="n">dilation</span>
        <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="n">self</span><span class="p">.</span><span class="n">pad</span> <span class="o">=</span> <span class="n">pad</span>

        <span class="n">self</span><span class="p">.</span><span class="n">out_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">in_h</span> <span class="o">-</span> <span class="n">k_h</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">pad</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out_w</span> <span class="o">=</span> <span class="p">(</span><span class="n">in_w</span> <span class="o">-</span> <span class="n">k_w</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">pad</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">check_out</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">b</span>

    <span class="c1"># naive convolution, sliding window matric
</span>    <span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">):</span>
        <span class="c1"># A * B = C
</span>        <span class="c1"># defice C size
</span>        <span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">batch</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">out_c</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">out_h</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">out_w</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># 7 loop
</span>        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">batch</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">oc</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_c</span><span class="p">):</span>
                <span class="c1"># each channel of output
</span>                <span class="k">for</span> <span class="n">oh</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_h</span><span class="p">):</span>
                    <span class="k">for</span> <span class="n">ow</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_w</span><span class="p">):</span>
                        <span class="c1"># each pixel of output shape
</span>                        <span class="n">a_j</span> <span class="o">=</span> <span class="n">oh</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">pad</span> <span class="c1"># a's y value == input's y value
</span>                        <span class="k">for</span> <span class="n">kh</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">k_h</span><span class="p">):</span>
                            <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="nf">check_out</span><span class="p">(</span><span class="n">a_j</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">in_h</span><span class="p">)</span> <span class="o">==</span> <span class="bp">False</span><span class="p">:</span> <span class="c1"># a_j 가 in_h보다 크다면 연산 x
</span>                                <span class="n">C</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">oc</span><span class="p">,</span> <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">0</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">a_i</span> <span class="o">=</span> <span class="n">ow</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">pad</span> <span class="c1"># a's x value == input's x value
</span>                                <span class="k">for</span> <span class="n">kw</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">k_w</span><span class="p">):</span>
                                    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="nf">check_out</span><span class="p">(</span><span class="n">a_i</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">in_w</span><span class="p">)</span> <span class="o">==</span> <span class="bp">False</span><span class="p">:</span>
                                        <span class="n">C</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">oc</span><span class="p">,</span> <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">0</span>
                                    <span class="k">else</span><span class="p">:</span>
                                        <span class="n">C</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">oc</span><span class="p">,</span> <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="p">:,</span> <span class="n">a_j</span><span class="p">,</span> <span class="n">a_i</span><span class="p">],</span> <span class="n">B</span><span class="p">[</span><span class="n">oc</span><span class="p">,</span> <span class="p">:,</span> <span class="n">kh</span><span class="p">,</span> <span class="n">kw</span><span class="p">])</span>
                                    <span class="n">a_i</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="c1"># add x direction moving unit for kernel 
</span>                            <span class="n">a_j</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="c1"># add y direction moving unit for kernel
</span>        <span class="k">return</span> <span class="n">C</span>
</pre></table></code></div></div><p>C는 결과를 저장하기 위한 저장소이다.</p><p>batch단위별로 결과 채널만큼 반복하고, 그것을 또 높이 단위로, 넓이 단위로 하나하나 루프를 돈다. 즉, [batch, out channel, out height, out width]의 형태만큼 순환을 해야 한다. output 결과를 계산해야 하는데, 계산을 위해 kernel크기만킄도 루프를 돌아야 한다. 반복을 하기 전에 입력의 row, col을 지정해주고, 예외 처리를 하여 연산에 오류가 나지 않는지 체크한다. 오류가 난다면 연산을 하지 않는다. row를 구할 때 kernel이 stride만큼씩 움직이므로 이를 곱한다. padding은 경계면에 0을 추가하여 중앙과 가장자리의 연산 수를 동일하게 맞춰주는 용도이다. 따라서 시작을 padding을 포함하여 시작할 수 있도록 (-)를 해준다.</p><p><img data-src="https://blog.kakaocdn.net/dn/8AsqI/btqEzZVNeIx/wrH1PMu4uIaV3rhFfYt38k/img.gif" data-proofer-ignore></p><p><br /></p><ul><li>main.py</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="kn">from</span> <span class="n">function.convolution</span> <span class="kn">import</span> <span class="n">Conv</span>

<span class="k">def</span> <span class="nf">convolution</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="s">"convolution"</span><span class="p">)</span>

    <span class="c1"># define the shape of input &amp; weight
</span>    <span class="n">in_w</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">in_h</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">in_c</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">out_c</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">k_w</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">k_h</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="c1"># define matrix
</span>    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="nf">reshape</span><span class="p">([</span><span class="n">batch</span><span class="p">,</span> <span class="n">in_c</span><span class="p">,</span> <span class="n">in_h</span><span class="p">,</span> <span class="n">in_w</span><span class="p">])</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">standard_normal</span><span class="p">([</span><span class="n">out_c</span><span class="p">,</span> <span class="n">in_c</span><span class="p">,</span> <span class="n">k_h</span><span class="p">,</span> <span class="n">k_w</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="c1">#print(x,"\n\n", w)
</span>
    <span class="n">Convolution</span> <span class="o">=</span> <span class="nc">Conv</span><span class="p">(</span><span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="p">,</span>
                        <span class="n">in_c</span> <span class="o">=</span> <span class="n">in_c</span><span class="p">,</span>
                        <span class="n">out_c</span> <span class="o">=</span> <span class="n">out_c</span><span class="p">,</span>
                        <span class="n">in_h</span> <span class="o">=</span> <span class="n">in_h</span><span class="p">,</span>
                        <span class="n">in_w</span> <span class="o">=</span> <span class="n">in_w</span><span class="p">,</span>
                        <span class="n">k_h</span> <span class="o">=</span> <span class="n">k_h</span><span class="p">,</span>
                        <span class="n">k_w</span> <span class="o">=</span> <span class="n">k_w</span><span class="p">,</span>
                        <span class="n">dilation</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                        <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                        <span class="n">pad</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

    <span class="nf">print</span><span class="p">(</span><span class="s">"x shape : "</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="s">"w shape : "</span><span class="p">,</span> <span class="n">w</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">L1</span> <span class="o">=</span> <span class="n">Convolution</span><span class="p">.</span><span class="nf">conv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>
    <span class="c1">#print(L1)
</span>    <span class="nf">print</span><span class="p">(</span><span class="s">"C shape : "</span><span class="p">,</span> <span class="n">L1</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># batch, out_c, out_h, out_w
</span>
<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="nf">convolution</span><span class="p">()</span>

<span class="c1"># ------------ # 
</span>
<span class="n">x</span> <span class="n">shape</span> <span class="p">:</span>  <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># batch, in_c, in_h, in_w
</span><span class="n">w</span> <span class="n">shape</span> <span class="p">:</span>  <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># out_c, in_c, k_h, k_w
</span><span class="n">C</span> <span class="n">shape</span> <span class="p">:</span>  <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># batch, out_c, out_h, out_w
</span></pre></table></code></div></div><p><br /></p><h2 id="im2col-방식">im2col 방식 <a href="#im2col-방식" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>function/convolution.py</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
</pre><td class="rouge-code"><pre>    <span class="c1"># IM2COL, change n-dim input to 2-dim matrix
</span>    <span class="k">def</span> <span class="nf">im2col</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">A</span><span class="p">):</span>

        <span class="c1"># define output 
</span>        <span class="n">mat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">in_c</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">k_h</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">k_w</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">out_w</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">out_h</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> 

        <span class="c1"># matrix index
</span>        <span class="n">mat_i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">mat_j</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># transform from A to mat
</span>        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">in_c</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">kh</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">k_h</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">kw</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">k_w</span><span class="p">):</span>
                    <span class="n">in_j</span> <span class="o">=</span> <span class="n">kh</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">dilation</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">pad</span>
                    <span class="k">for</span> <span class="n">oh</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_h</span><span class="p">):</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="n">self</span><span class="p">.</span><span class="nf">check_out</span><span class="p">(</span><span class="n">in_j</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">in_h</span><span class="p">):</span>
                            <span class="k">for</span> <span class="n">ow</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_w</span><span class="p">):</span>
                                <span class="n">mat</span><span class="p">[</span><span class="n">mat_j</span><span class="p">,</span> <span class="n">mat_i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                                <span class="n">mat_i</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">in_i</span> <span class="o">=</span> <span class="n">kw</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">dilation</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">pad</span>
                            <span class="k">for</span> <span class="n">ow</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_w</span><span class="p">):</span>
                                <span class="k">if</span> <span class="ow">not</span> <span class="n">self</span><span class="p">.</span><span class="nf">check_out</span><span class="p">(</span><span class="n">in_i</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">in_w</span><span class="p">):</span>
                                    <span class="n">mat</span><span class="p">[</span><span class="n">mat_j</span><span class="p">,</span> <span class="n">mat_i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                                    <span class="n">mat_i</span> <span class="o">+=</span> <span class="mi">1</span>
                                <span class="k">else</span><span class="p">:</span>
                                    <span class="n">mat</span><span class="p">[</span><span class="n">mat_j</span><span class="p">,</span> <span class="n">mat_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">in_j</span><span class="p">,</span> <span class="n">in_i</span><span class="p">]</span> <span class="c1"># [batch, ic, ih, iw],   batch = 1이므로 0index
</span>                                    <span class="n">mat_i</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># 1 x direction move
</span>                                <span class="n">in_i</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="c1"># move the stride unit as x axis
</span>                        <span class="n">in_j</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="c1"># move the stride unit as y axis
</span>                    <span class="n">mat_i</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># initialization
</span>                    <span class="n">mat_j</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># move next row at input
</span>
        <span class="k">return</span> <span class="n">mat</span>
    
    <span class="c1"># gemm, 2D matrix multiplication
</span>    <span class="k">def</span> <span class="nf">gemm</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">):</span>
        <span class="n">a_mat</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">im2col</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
        <span class="n">b_mat</span> <span class="o">=</span> <span class="n">B</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># kernel 4차원 텐서 차원을 reshape로 바꿀 수 있음, kernel은 [output channel ,input channel, kernel height, kernel width] 로 되어 있는데, 이를 [oc, kh*kw*ic]로 변환하기에
</span>        <span class="n">c_mat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">b_mat</span><span class="p">,</span> <span class="n">a_mat</span><span class="p">)</span>

        <span class="n">c</span> <span class="o">=</span> <span class="n">c_mat</span><span class="p">.</span><span class="nf">reshape</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">batch</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">out_c</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">out_h</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">out_w</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">c</span>
</pre></table></code></div></div><p>이 때는 매번 루프를 돌 때마다 연산하는 것이 아닌 4d 차원을 2d로 변환한 후 연산을 진행한다. 따라서 변환해주기 위한 im2col을 먼저 선언한다.</p><p><br /></p><ul><li>main.py</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>    <span class="n">L2</span> <span class="o">=</span> <span class="n">Convolution</span><span class="p">.</span><span class="nf">gemm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>

    <span class="nf">print</span><span class="p">(</span><span class="n">L2</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="s">"L2 shape : "</span><span class="p">,</span> <span class="n">L2</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># batch, out_c, out_h, out_w
</span></pre></table></code></div></div><p><br /></p><h2 id="pytorch와-위의-두-방식-시간-비교">pytorch와 위의 두 방식 시간 비교 <a href="#pytorch와-위의-두-방식-시간-비교" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre><td class="rouge-code"><pre><span class="c1"># main.py
</span><span class="kn">import</span> <span class="n">time</span>

    <span class="n">l1_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">L1</span> <span class="o">=</span> <span class="n">Convolution</span><span class="p">.</span><span class="nf">conv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="s">"L1 time : "</span><span class="p">,</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">l1_time</span><span class="p">)</span>


    <span class="n">l2_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">L2</span> <span class="o">=</span> <span class="n">Convolution</span><span class="p">.</span><span class="nf">gemm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="s">"L2 time : "</span><span class="p">,</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">l2_time</span><span class="p">)</span>


    <span class="c1"># pytorch
</span>    <span class="n">torch_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">in_c</span><span class="p">,</span>
                            <span class="n">out_c</span><span class="p">,</span>
                            <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">k_h</span><span class="p">,</span>
                            <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                            <span class="n">padding</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                            <span class="n">bias</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
                            <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">torch_conv</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">w</span><span class="p">))</span> <span class="c1"># 우리가 직접 생성한 weight를 집어넣음
</span>
    <span class="n">l3_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">L3</span> <span class="o">=</span> <span class="nf">torch_conv</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">))</span> <span class="c1"># x가 numpy로 생성되었기 때문에 tensor로 변환하여 실행
</span>    <span class="nf">print</span><span class="p">(</span><span class="s">"L3 time : "</span><span class="p">,</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">l3_time</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">L3</span><span class="p">)</span>

<span class="c1"># ------------------- #
</span>
<span class="n">L1</span> <span class="n">time</span> <span class="p">:</span>  <span class="mf">0.40502333641052246</span>
<span class="n">L2</span> <span class="n">time</span> <span class="p">:</span>  <span class="mf">0.017976760864257812</span>
<span class="n">L3</span> <span class="n">time</span> <span class="p">:</span>  <span class="mf">0.00850367546081543</span>
</pre></table></code></div></div><p>L1 » L2 » L3 순으로 시간이 단축되는 것을 볼 수 있다.</p><p><br /></p><h1 id="cnn---pooling">CNN - pooling</h1><p>pooling은 feature map의 크기를 줄이는 것을 말한다.</p><p>종류로는 max pooling / average pooling이 있다. max pooling의 작동 방식은 다음과 같다.</p><p><img data-src="https://dkssud8150.github.io/assets/img/cs231n/2021-09-14/maxpooling.png" data-proofer-ignore></p><p>영역에서 최대값만 추출하므로 엣지부분을 많이 잡히게 출력된다.</p><p>그에 반해 average pooling의 경우 평균값을 사용하므로 스무딩한 형상을 띄게 된다.</p><p><img data-src="/assets/img/dev/week10/day2/pooling.png" data-proofer-ignore></p><h2 id="pooling-직접-구현">pooling 직접 구현 <a href="#pooling-직접-구현" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>function/pool.py</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># 2d pooling
</span><span class="k">class</span> <span class="nc">Pool</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">in_c</span><span class="p">,</span> <span class="n">out_c</span><span class="p">,</span> <span class="n">in_h</span><span class="p">,</span> <span class="n">in_w</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">pad</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">self</span><span class="p">.</span><span class="n">in_c</span> <span class="o">=</span> <span class="n">in_c</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out_c</span> <span class="o">=</span> <span class="n">out_c</span>
        <span class="n">self</span><span class="p">.</span><span class="n">in_h</span> <span class="o">=</span> <span class="n">in_h</span>
        <span class="n">self</span><span class="p">.</span><span class="n">in_w</span> <span class="o">=</span> <span class="n">in_w</span>
        <span class="n">self</span><span class="p">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dilation</span> <span class="o">=</span> <span class="n">dilation</span>
        <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="n">self</span><span class="p">.</span><span class="n">pad</span> <span class="o">=</span> <span class="n">pad</span>

        <span class="n">self</span><span class="p">.</span><span class="n">out_w</span> <span class="o">=</span> <span class="p">(</span><span class="n">in_w</span> <span class="o">-</span> <span class="n">kernel</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">pad</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">in_h</span> <span class="o">-</span> <span class="n">kernel</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">pad</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">maxpool</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">A</span><span class="p">):</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">batch</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">out_c</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">out_h</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">out_w</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">batch</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">in_c</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">oh</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_h</span><span class="p">):</span> <span class="c1"># output 크기만큼 결과를 낼 것이므로
</span>                    <span class="n">a_j</span> <span class="o">=</span> <span class="n">oh</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">pad</span> <span class="c1"># 연산 시작 row
</span>                    <span class="k">for</span> <span class="n">ow</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_w</span><span class="p">):</span>
                        <span class="n">a_i</span> <span class="o">=</span> <span class="n">ow</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">pad</span> <span class="c1"># 연산 col
</span>                        <span class="c1"># kernel 크기만큼 중에서 가장 큰 값을 지정
</span>                        <span class="n">C</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">amax</span><span class="p">(</span><span class="n">A</span><span class="p">[:,</span> <span class="n">c</span><span class="p">,</span> <span class="n">a_j</span><span class="p">:</span><span class="n">a_j</span><span class="o">+</span><span class="n">self</span><span class="p">.</span><span class="n">kernel</span><span class="p">,</span> <span class="n">a_i</span><span class="p">:</span><span class="n">a_i</span><span class="o">+</span><span class="n">self</span><span class="p">.</span><span class="n">kernel</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">C</span>
</pre></table></code></div></div><p>for문을 통해 하나하나 연산한다. amax라는 array안의 가장 큰 값을 추출해주는 메서드를 통해 2x2크기의 공간에서 최대값을 C array에 넣는다.</p><ul><li>main.py</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
</pre><td class="rouge-code"><pre><span class="c1"># 간단한 forward 구조 생성
</span><span class="k">def</span> <span class="nf">forward_net</span><span class="p">():</span>
    <span class="c1"># define
</span>    <span class="n">batch</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">in_c</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">in_w</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="n">in_h</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="n">k_h</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">k_w</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">out_c</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">batch</span><span class="o">*</span><span class="n">in_c</span><span class="o">*</span><span class="n">in_w</span><span class="o">*</span><span class="n">in_h</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="nf">reshape</span><span class="p">([</span><span class="n">batch</span><span class="p">,</span> <span class="n">in_c</span><span class="p">,</span> <span class="n">in_w</span><span class="p">,</span> <span class="n">in_h</span><span class="p">])</span>
    <span class="n">w1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">standard_normal</span><span class="p">([</span><span class="n">out_c</span><span class="p">,</span> <span class="n">in_c</span><span class="p">,</span> <span class="n">k_h</span><span class="p">,</span> <span class="n">k_w</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">Convolution</span> <span class="o">=</span> <span class="nc">Conv</span><span class="p">(</span><span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="p">,</span>
                    <span class="n">in_c</span> <span class="o">=</span> <span class="n">in_c</span><span class="p">,</span>
                    <span class="n">out_c</span> <span class="o">=</span> <span class="n">out_c</span><span class="p">,</span>
                    <span class="n">in_h</span> <span class="o">=</span> <span class="n">in_h</span><span class="p">,</span>
                    <span class="n">in_w</span> <span class="o">=</span> <span class="n">in_w</span><span class="p">,</span>
                    <span class="n">k_h</span> <span class="o">=</span> <span class="n">k_h</span><span class="p">,</span>
                    <span class="n">k_w</span> <span class="o">=</span> <span class="n">k_w</span><span class="p">,</span>
                    <span class="n">dilation</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                    <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                    <span class="n">pad</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

    <span class="n">L1</span> <span class="o">=</span> <span class="n">Convolution</span><span class="p">.</span><span class="nf">gemm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w1</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="s">"L1 shape"</span><span class="p">,</span> <span class="n">L1</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># L1 shape (1, 1, 4, 4)
</span>    <span class="nf">print</span><span class="p">(</span><span class="s">"L1"</span><span class="p">,</span> <span class="n">L1</span><span class="p">)</span>

    <span class="n">Pooling</span> <span class="o">=</span> <span class="nc">Pool</span><span class="p">(</span><span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="p">,</span> <span class="c1"># L1의 출력 Shape를 입력으로 넣어줘야 한다.
</span>                    <span class="n">in_c</span> <span class="o">=</span> <span class="n">L1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                    <span class="n">out_c</span> <span class="o">=</span> <span class="n">L1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                    <span class="n">in_h</span> <span class="o">=</span> <span class="n">L1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                    <span class="n">in_w</span> <span class="o">=</span> <span class="n">L1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                    <span class="n">kernel</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="c1"># pooling의 커널 2x2
</span>                    <span class="n">dilation</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                    <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
                    <span class="n">pad</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

    <span class="n">L1_max</span> <span class="o">=</span> <span class="n">Pooling</span><span class="p">.</span><span class="nf">maxpool</span><span class="p">(</span><span class="n">L1</span><span class="p">)</span>

    <span class="nf">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">L1 max shape : "</span><span class="p">,</span> <span class="n">L1_max</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="s">"L1 max"</span><span class="p">,</span><span class="n">L1_max</span><span class="p">)</span>

<span class="c1"># ---------------------- #
</span>
<span class="n">L1</span> <span class="nf">shape </span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">L1</span> <span class="p">[[[[</span><span class="mf">484.84863</span> <span class="mf">491.3175</span>  <span class="mf">497.78632</span> <span class="mf">504.2552</span> <span class="p">]</span>
   <span class="p">[</span><span class="mf">523.6616</span>  <span class="mf">530.1305</span>  <span class="mf">536.5993</span>  <span class="mf">543.0681</span> <span class="p">]</span>
   <span class="p">[</span><span class="mf">562.47455</span> <span class="mf">568.9434</span>  <span class="mf">575.4122</span>  <span class="mf">581.88104</span><span class="p">]</span>
   <span class="p">[</span><span class="mf">601.28754</span> <span class="mf">607.75635</span> <span class="mf">614.2252</span>  <span class="mf">620.694</span>  <span class="p">]]]]</span>

<span class="n">L1</span> <span class="nb">max</span> <span class="n">shape</span> <span class="p">:</span>  <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">L1</span> <span class="nb">max</span> <span class="p">[[[[</span><span class="mf">530.1305</span>  <span class="mf">543.0681</span> <span class="p">]</span>
   <span class="p">[</span><span class="mf">607.75635</span> <span class="mf">620.694</span>  <span class="p">]]]]</span>

</pre></table></code></div></div><p>간단하게 forward과정만 보기 위해 함수를 선언해주었다. x를 input 형태로 만들어주고, w1을 생성해준다. 그 후 conv 이후에 pooling을 진행하므로 convolution을 먼저 진행해준다. conv는 gemm 함수를 사용했다. 이로 인해 출력되는 값은 (1,1,4,4) 형태로 리턴된다. 이를 pooling 해줄 때는 in_c, out_c 가 아닌 L1 conv 한 출력값 형태로 넣어줘야 한다.</p><p>당연히 <code class="language-plaintext highlighter-rouge">input -&gt; conv -&gt; pooling -&gt; output</code> 순서로 진행되기 때문이다. 그렇게 maxpooling을 진행하면 <code class="language-plaintext highlighter-rouge">[batch, in_c, in_h, in_w] -&gt; [batch, out_c, (in_h - kernel + 2 * pad) // stride + 1,(in_w - kernel + 2 * pad) // stride + 1]</code> 로 변환된다.</p><p>output : [1, 1, (4 - 2 + 2 * 0) // 2 + 1, (4 - 2 + 2 * 0) // 2 + 1] = [1,1,2,2]</p><p><br /></p><h1 id="cnn---fc-layer">CNN - FC layer</h1><p>Fully Connected Layer로써 2d 특징맵을 1d 특징맵으로 변환한 후 fc weight와 연산하여 최종 결과를 출력하는 층이다.</p><p>이는 2d를 1d로 변환한 층이므로 연산랴이 엄청 크게 되고, 파라미터의 수가 이곳에 가장 많이 분포되어 있는 경우가 많다.</p><p>그래서 이를 해결하기 위해 1x1 convolutional layer로 바꿔서 만드는 모델도 많다.</p><h2 id="fc-layer-코드-구현">fc layer 코드 구현 <a href="#fc-layer-코드-구현" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>funtion/fc.py</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">class</span> <span class="nc">FC</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">in_c</span><span class="p">,</span> <span class="n">out_c</span><span class="p">,</span> <span class="n">in_h</span><span class="p">,</span> <span class="n">in_w</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_classes</span> <span class="o">=</span> <span class="n">n_classes</span>
        <span class="n">self</span><span class="p">.</span><span class="n">in_c</span> <span class="o">=</span> <span class="n">in_c</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out_c</span> <span class="o">=</span> <span class="n">out_c</span>
        <span class="n">self</span><span class="p">.</span><span class="n">in_h</span> <span class="o">=</span> <span class="n">in_h</span>
        <span class="n">self</span><span class="p">.</span><span class="n">in_w</span> <span class="o">=</span> <span class="n">in_w</span>

    <span class="k">def</span> <span class="nf">fc</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">W</span><span class="p">):</span>
        <span class="c1"># A shape : [b,in_c, in_h, in_w] -&gt; [b, in_c*in_h*in_w]
</span>        <span class="n">a_mat</span> <span class="o">=</span> <span class="n">A</span><span class="p">.</span><span class="nf">reshape</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">a_mat</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">)))</span> 
        <span class="k">return</span> <span class="n">B</span>
</pre></table></code></div></div><p>A, 입력의 shape은 [b,in_c, in_h, in_w] 이다. 이 4-dim 을 2-dim으로 변환한 후 fc layer 연산을 수행해야 하므로 [b, in_c*in_h*in_w]로 변환해준다.</p><p>B의 경우 출력값인데, vector 내적 연산을 수행하는 dot을 사용했고, w는 입력이 [1, in_c*in_h*in_w] 이므로 연산을 위해서는 순서를 바꿔줘야 한다. 그러므로 transpose 시켜준다.</p><p><br /></p><ul><li>main.py</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre>    <span class="c1"># fully connected layer
</span>    <span class="n">w2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">standard_normal</span><span class="p">([</span><span class="n">L1_max</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">L1_max</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">L1_max</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">L1_max</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">Fc</span> <span class="o">=</span> <span class="nc">FC</span><span class="p">(</span><span class="n">n_classes</span> <span class="o">=</span> <span class="n">L1_max</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">in_c</span> <span class="o">=</span> <span class="n">L1_max</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">out_c</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="c1"># 출력은 1채널이어야 함
</span>            <span class="n">in_h</span> <span class="o">=</span> <span class="n">L1_max</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
            <span class="n">in_w</span> <span class="o">=</span> <span class="n">L1_max</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>

    <span class="n">L2</span> <span class="o">=</span> <span class="n">Fc</span><span class="p">.</span><span class="nf">fc</span><span class="p">(</span><span class="n">L1_max</span><span class="p">,</span> <span class="n">w2</span><span class="p">)</span>

    <span class="nf">print</span><span class="p">(</span><span class="s">"L2 shape : "</span><span class="p">,</span> <span class="n">L2</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">L2</span><span class="p">)</span>

<span class="c1"># ------------------- #
</span>
<span class="n">L2</span> <span class="n">shape</span> <span class="p">:</span>  <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">[[</span><span class="mf">1205.8112</span><span class="p">]]</span>
</pre></table></code></div></div><p>이렇게 출력된 형태는 (1,1) == (n_classes, out_c) , 즉 각각의 클래스에 따른 확률값이다.</p><p><br /></p><h1 id="cnn---activation">CNN - Activation</h1><p>activation, 활성 함수는 비선형 함수로 sigmoid, tanh, ReLU, LeakyReLU 등이 있다.</p><p><img data-src="/assets/img/dev/week10/day2/activation.png" data-proofer-ignore></p><p>sigmoid와 tanh는 역전파시 gradient vanishing 현상이 발생하므로 최근에는 사용하지 않는다. 또한, ReLU는 max 함수이므로 연산이 더 빠르기 때문에 ReLU를 많이 사용한다.</p><h2 id="activation-코드-구현">Activation 코드 구현 <a href="#activation-코드-구현" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>function/activation.py</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># max(0,x)
</span><span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">x_shape</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># 몇 차원인지 모르기 때문에 1차원으로 변환
</span>    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="nf">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">x</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">leaky_relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">x_shape</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="nf">max</span><span class="p">(</span><span class="mf">0.1</span><span class="o">*</span><span class="n">v</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">x</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
    
<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">x_shape</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">v</span><span class="p">))</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">x</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">x_shape</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">tanh</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">x</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></table></code></div></div><p><br /></p><ul><li>main.py</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre><td class="rouge-code"><pre>
<span class="k">def</span> <span class="nf">plot_activation</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">out_relu</span> <span class="o">=</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">out_leaky</span> <span class="o">=</span> <span class="nf">leaky_relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">out_sigmoid</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">out_tanh</span> <span class="o">=</span> <span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
    <span class="n">output</span> <span class="o">=</span> <span class="p">{</span><span class="s">'out_relu'</span><span class="p">:</span><span class="n">out_relu</span><span class="p">,</span> <span class="s">'out_leaky'</span><span class="p">:</span><span class="n">out_leaky</span><span class="p">,</span> 
                <span class="s">'out_sigmoid'</span><span class="p">:</span><span class="n">out_sigmoid</span><span class="p">,</span> <span class="s">'out_tanh'</span><span class="p">:</span><span class="n">out_tanh</span><span class="p">}</span>
    <span class="n">key</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="nf">keys</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">key</span><span class="p">)):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">key</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">output</span><span class="p">[</span><span class="n">out</span><span class="p">],</span> <span class="s">'o-'</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img data-src="/assets/img/dev/week10/day/2/plot.png" data-proofer-ignore></p><p><br /></p><p><br /></p><h1 id="cnn-전체-구성">CNN 전체 구성</h1><p>얕은 CNN을 프레임워크를 사용하지 않고, numpy로만 구성해보고자 한다.</p><p><img data-src="/assets/img/dev/week10/day2/shallow.png" data-proofer-ignore></p><p>layer는 다음과 같다.</p><ul><li>input : x [1,1,6,6]<li>conv : w [1,1,3,3], k [3x3], stride=1, pad=0<li>max pooling : k [2x2], stride=2, pad=0<li>fc layer : w [4,1]<li>L2 norm</ul><p>역전파까지 진행해서 학습이 진행되는지를 볼 것이다. 역전파를 할 때는 chain rule을 사용하여 좀 더 간편하게 weight를 갱신한다.</p><p>max pooling을 역전파할 때는 다시 되돌리기 위해서는 max값을 가져온 위치를 알고 있어야 한다. 그것을 max unpooling 방식을 사용한다. 이를 통해 가져온 위치만 활성화하고, 나머지는 0으로 된다.</p><p><img data-src="/assets/img/cs231n/2021-10-06/0027.jpg" data-proofer-ignore></p><p><br /></p><h2 id="data-label-weight-hw-선언">data, label, weight, h,w 선언 <a href="#data-label-weight-hw-선언" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">shallow_network</span><span class="p">():</span>
    <span class="c1"># input [1,1,6,6], 2 iter
</span>    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">standard_normal</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span>
         <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">standard_normal</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">6</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)]</span>
    <span class="c1"># Ground Truth
</span>    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    

    <span class="c1"># conv1 weights [1,1,3,3]
</span>    <span class="n">w1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">standard_normal</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="c1"># fc weights [1,4]
</span>    <span class="n">w2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">standard_normal</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span>
    <span class="n">padding</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="c1"># L1 layer shape w,h
</span>    <span class="n">L1_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">w1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">padding</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">L1_w</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">-</span> <span class="n">w1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">padding</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="nf">print</span><span class="p">(</span><span class="s">"L1 output : ({}, {})"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">L1_h</span><span class="p">,</span> <span class="n">L1_w</span><span class="p">))</span> <span class="c1"># (4, 4)
</span>
<span class="c1"># -------------------- # 
</span>
<span class="n">L1</span> <span class="n">output</span> <span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></table></code></div></div><ul><li>x,y : 1epoch마다 2번을 진행하기 휘애 2개를 선언해주었다. 이 때 나중에 값을 비교할 때 정확한 판단을 위해 dtype을 지정해줘야 한다. 따라서 array로 생성한다.<li>conv1 weight : shape=[1,1,3,3] == [out_c, in_c, k_h, k_w]<li>fc weight : shape=[1,4] == [1, n_classes]<li>lr : learning rate<li>stride : convolution에서는 1, pooling에서는 2<li>L1_w, L1_h = convolution을 해서 나오는 출력 w, h</ul><p><br /></p><h2 id="convolution-fc-pooling-layer-선언">convolution, FC, pooling layer 선언 <a href="#convolution-fc-pooling-layer-선언" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
</pre><td class="rouge-code"><pre>    <span class="c1"># conv1
</span>    <span class="n">Convolution</span> <span class="o">=</span> <span class="nc">Conv</span><span class="p">(</span><span class="n">batch</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                       <span class="n">in_c</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                       <span class="n">out_c</span> <span class="o">=</span> <span class="n">w1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                       <span class="n">in_h</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                       <span class="n">in_w</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                       <span class="n">k_h</span> <span class="o">=</span> <span class="n">w1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                       <span class="n">k_w</span> <span class="o">=</span> <span class="n">w1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                       <span class="n">dilation</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                       <span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span><span class="p">,</span>
                       <span class="n">pad</span> <span class="o">=</span> <span class="n">padding</span><span class="p">)</span>

    <span class="c1"># conv1 backprop conv
</span>    <span class="n">Conv_diff</span> <span class="o">=</span>  <span class="nc">Conv</span><span class="p">(</span><span class="n">batch</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                      <span class="n">in_c</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                      <span class="n">out_c</span> <span class="o">=</span> <span class="n">w1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                      <span class="n">in_h</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                      <span class="n">in_w</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                      <span class="n">k_h</span> <span class="o">=</span> <span class="n">L1_h</span><span class="p">,</span>
                      <span class="n">k_w</span> <span class="o">=</span> <span class="n">L1_w</span><span class="p">,</span>
                      <span class="n">dilation</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                      <span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span><span class="p">,</span>
                      <span class="n">pad</span> <span class="o">=</span> <span class="n">padding</span><span class="p">)</span>
    
    <span class="c1"># max pooling
</span>    <span class="n">Pooling</span> <span class="o">=</span> <span class="nc">Pool</span><span class="p">(</span><span class="n">n_classes</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                   <span class="n">in_c</span> <span class="o">=</span> <span class="n">w1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                   <span class="n">out_c</span> <span class="o">=</span> <span class="n">w1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                   <span class="n">in_h</span> <span class="o">=</span> <span class="n">L1_h</span><span class="p">,</span>
                   <span class="n">in_w</span> <span class="o">=</span> <span class="n">L1_w</span><span class="p">,</span>
                   <span class="n">kernel</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
                   <span class="n">dilation</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                   <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
                   <span class="n">pad</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># FC
</span>    <span class="n">Fc</span> <span class="o">=</span> <span class="nc">FC</span><span class="p">(</span><span class="n">n_classes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">in_c</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">out_c</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">in_h</span> <span class="o">=</span> <span class="n">L1_h</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">in_w</span> <span class="o">=</span> <span class="n">L1_w</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
</pre></table></code></div></div><ul><li>convolution<ul><li>batch, in_c, in_h, in_w : input = [batch, in_c, in_h, in_w] 이므로 각각 지정<li>out_c, k_h, k_w : w = [out_c, in_c, k_h, k_w] 이므로 각각 지정</ul></ul><p>역전파에 사용될 convolution을 선언해준다. 자세한 내용은 아래에서 설명하겠다.</p><ul><li>conv_diff<ul><li>k_h, k_w : 1 conv layer의 출력값으로 지정</ul><li>pooling<ul><li>kernel,stride : pooling에서는 kernel size를 2로 설정하고, stride를 2로 설정하여 출력 크기를 1/2로 만듦</ul><li>FC<ul><li>n_classes, out_c : 출력 크기는 n_classes x 1<li>in_c : 입력 채널<li>in_h, in_w : FC layer는 1 conv layer의 출력값에서 max pooling하여 1/2 크기가 된 값을 입력으로 받으므로 1/2해줘야 한다.</ul></ul><p><br /></p><h2 id="forward">forward <a href="#forward" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre><td class="rouge-code"><pre>    <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>

    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span> <span class="c1"># 100 epoch
</span>        <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span> <span class="c1"># 2iter for each epoch
</span>            <span class="c1"># forward
</span>            <span class="n">L1</span> <span class="o">=</span> <span class="n">Convolution</span><span class="p">.</span><span class="nf">gemm</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">w1</span><span class="p">)</span>
            <span class="nf">print </span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">shape</span><span class="p">,</span> <span class="n">w1</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">L1</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

            <span class="n">L1_act</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">L1</span><span class="p">)</span> <span class="c1"># (1,1,4,4)
</span>            
            <span class="n">L1_max</span> <span class="o">=</span> <span class="n">Pooling</span><span class="p">.</span><span class="nf">maxpool</span><span class="p">(</span><span class="n">L1_act</span><span class="p">)</span>

            <span class="c1">#print (L1_max.shape) # (1,1,2,2)
</span>
            <span class="n">L1_max_flatten</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">L1_max</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="c1">#print (L1_max_flatten.shape) # (1,4)
</span>
            <span class="n">L2</span> <span class="o">=</span> <span class="n">Fc</span><span class="p">.</span><span class="nf">fc</span><span class="p">(</span><span class="n">L1_max_flatten</span><span class="p">,</span> <span class="n">w2</span><span class="p">)</span>
            <span class="c1">#print (L2.shape) # (1,1)
</span>            <span class="c1">#print (L2)
</span>
            <span class="n">L2_act</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">L2</span><span class="p">)</span>
            <span class="c1">#print (L2_act)
</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">L2_act</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
            <span class="c1">#print (loss)
</span>
<span class="c1"># -------------------- #
</span>
<span class="n">x1</span><span class="p">.</span><span class="n">shape</span> <span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">w1</span><span class="p">.</span><span class="n">shape</span> <span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">L1</span><span class="p">.</span><span class="n">shape</span> <span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">L1_act</span><span class="p">.</span><span class="n">shape</span> <span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">L1_max</span><span class="p">.</span><span class="n">shape</span> <span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">L1_max_flatten</span><span class="p">.</span><span class="n">shape</span> <span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">L2</span><span class="p">.</span><span class="n">shape</span> <span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

</pre></table></code></div></div><ul><li>epochs: 반복할 횟수 지정<li>x의 길이만큼 반복<li>forward<ol><li>1 layer : conv layer<ul><li>(b,in_c,in_h,in_w) * (out_c,in_c,k_h,k_w) = (b,out_c,out_h,out_w)<li>(1, 1, 6, 6) * (1, 1, 3, 3) = (1, 1, 4, 4)<li>out_h = (in_h - k_h + 2 * padding) // stride + 1<li>4 = (6 - 3 + 2 * 0) // 1 + 1</ul><li>1 layer activation<ul><li>activation은 차원이 달라지지 않고, 값만 바뀐다.</ul><li>1 layer max pooling<ul><li>max pooling에서 stride와 kernel의 크기를 통해 결과의 크기를 설정할 수 있다.<li>이 또한, out_h = (in_h - k_h + 2 * padding) // stride + 1</ul><li>1 layer flatten<ul><li>fc layer에 넣기 위해 1차원으로 변환시켜준다.</ul><li>2 layer : fc layer<ul><li>(n_classes, 1)</ul><li>2 layer activation</ol></ul><p><br /></p><h2 id="backward">backward <a href="#backward" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li><strong>w2 backpropagation</strong></ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre><td class="rouge-code"><pre>            <span class="c1"># backward
</span>            <span class="c1"># delta E / delta w2
</span>            <span class="n">diff_w2_1</span> <span class="o">=</span> <span class="n">L2_act</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="n">diff_w2_2</span> <span class="o">=</span> <span class="n">L2_act</span> <span class="o">*</span> <span class="p">(</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">L2_act</span><span class="p">)</span>

            <span class="n">diff_w2_3</span> <span class="o">=</span> <span class="n">L1_max</span>

            <span class="n">diff_w2</span> <span class="o">=</span> <span class="n">diff_w2_1</span> <span class="o">*</span> <span class="n">diff_w2_2</span> <span class="o">*</span> <span class="n">diff_w2_3</span>
            <span class="c1">#print (diff_w2) # 2x2 인데, fc layer.shape은 1x4이므로 변환해줘야 함
</span>
            <span class="n">diff_w2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">diff_w2</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># --------------- #
</span><span class="n">diff_w2_before</span><span class="p">.</span><span class="n">shape</span> <span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">diff_w2_after</span><span class="p">.</span><span class="n">shape</span> <span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></table></code></div></div><p><img data-src="/assets/img/dev/week10/day2/w2chainrule.png" data-proofer-ignore></p><ul><li>diff_w2_1, diff_w2_2, diff_w2_3 : chain rule을 통해 $ \frac{\partial E}{\partial W_2} $ 를 구한다.</ul><p>구한 diff_w2_1,2,3 을 곱해서 출력값을 구하면 (1,1,2,2) shape을 얻는다. 이는 w2를 최적화하는데 사용하는데 w2의 shape은 (1,4) 이므로 이를 변환시켜줘야 한다.</p><p><br /></p><ul><li><strong>w1 backpropagation</strong></ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre><td class="rouge-code"><pre>            <span class="c1"># delta E / delta w1
</span>            <span class="n">diff_w1_1</span> <span class="o">=</span> <span class="n">diff_w2_1</span> <span class="o">*</span> <span class="n">diff_w2_2</span>
            <span class="c1">#print (diff_w1_1.shape)
</span>            <span class="n">diff_w1_2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">w2</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="c1"># w2 [1,4] -&gt; reshape
</span>            <span class="c1">#print (diff_w1_2.shape) # 1,1,2,2
</span>
            <span class="n">diff_w1_2</span> <span class="o">=</span> <span class="n">diff_w1_2</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">).</span><span class="nf">repeat</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="c1"># array를 n번 증폭
</span>            <span class="c1">#print (diff_w1_2.shape) # 1,1,4,4
</span>
            <span class="c1"># diff maxpool
</span>            <span class="n">diff_w1_3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">equal</span><span class="p">(</span><span class="n">L1_act</span><span class="p">,</span> <span class="n">L1_max</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">).</span><span class="nf">repeat</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span> <span class="c1"># pooling의 input, output,, 동일한 값의 인덱스를 구해줌, 동일한 행렬 크기로 만든 후 비교
</span>            <span class="c1">#print (diff_w1_3)
</span>
            <span class="n">diff_w1_4</span> <span class="o">=</span> <span class="n">L1_act</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span> <span class="n">L1_act</span><span class="p">)</span>
            <span class="c1">#print (diff_w1_4.shape) # 1,1,4,4
</span>            <span class="n">diff_w1_5</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="n">diff_w1</span> <span class="o">=</span> <span class="n">diff_w1_1</span> <span class="o">*</span> <span class="n">diff_w1_2</span> <span class="o">*</span> <span class="n">diff_w1_3</span> <span class="o">*</span> <span class="n">diff_w1_4</span> 

            <span class="c1"># 위 4개의 결과는 4x4 이고, x[i]는 6x6이므로 x[i]에 conv를 진행해줘야 함
</span>            <span class="n">diff_w1</span> <span class="o">=</span> <span class="n">Conv_diff</span><span class="p">.</span><span class="nf">gemm</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">diff_w1</span><span class="p">)</span>
            
            <span class="c1">#print (diff_w1)
</span></pre></table></code></div></div><p><img data-src="/assets/img/dev/week10/day2/w1chainrule.png" data-proofer-ignore></p><p>chain rule에 의해 전개한 수식을 모두 곱하여 w1에 대한 diff를 구한다. 이 떄, 중요한 것은 diff_w1_5의 차원은 (1,1,6,6)인데, 나머지의 결과값들은 (!,1,4,4)이므로 이 둘을 곱하기 위해서 convolution 연산을 해야 한다. 그 이유는 6x6의 연소 개수는 36개인데, 이를 4x4에 reshape를 시켜줄 수 없다. 그러므로 연산을 위해 convolution을 진행한다.</p><p><br /></p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre><td class="rouge-code"><pre>            <span class="c1"># update
</span>            <span class="n">w2</span> <span class="o">=</span> <span class="n">w2</span> <span class="o">-</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">diff_w2</span>
            <span class="n">w1</span> <span class="o">=</span> <span class="n">w1</span> <span class="o">-</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">diff_w1</span>

        <span class="nf">print</span><span class="p">(</span><span class="s">"{} epoch loss {}"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>

<span class="c1"># ----------------- #
</span>
<span class="mi">0</span> <span class="n">epoch</span> <span class="n">loss</span> <span class="mf">0.18372559547424316</span>
<span class="mi">1</span> <span class="n">epoch</span> <span class="n">loss</span> <span class="mf">0.18269944936037064</span>
<span class="mi">2</span> <span class="n">epoch</span> <span class="n">loss</span> <span class="mf">0.18167604506015778</span>

<span class="p">...</span>

<span class="mi">97</span> <span class="n">epoch</span> <span class="n">loss</span> <span class="mf">0.10186305642127991</span>
<span class="mi">98</span> <span class="n">epoch</span> <span class="n">loss</span> <span class="mf">0.101227305829525</span>
<span class="mi">99</span> <span class="n">epoch</span> <span class="n">loss</span> <span class="mf">0.10059575736522675</span>

</pre></table></code></div></div><p>구한 가중치의 gradient를 통해 learning rate와 곱해서 가중치를 업데이트한다. 구한 total_loss는 x의 길이, 즉 반복한 횟수만큼 나눠주어 평균을 출력한다. loss가 줄어들고 있는 것을 확인할 수 있다.</p><p><br /></p><p><br /></p><h1 id="fashionmnist-using-lenet5">FashionMNIST using Lenet5</h1><p>지난 번에 만들어주었던 Lenet5를 사용하여 fashionMNIST를 학습시키고자 한다. 여기서 dropout, activation 변화 등을 추가했고, batch normalization 텀을 추가했다.</p><p><br /></p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="p">)</span>
</pre></table></code></div></div><p>batch normalization에서 나머지 인자는 디폴트 값을 사용한다. 이는 conv layer와 activation 사이에 넣는다. fc layer에는 넣지 않는다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">Lenet5</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">,</span> <span class="n">in_width</span><span class="p">,</span> <span class="n">in_height</span><span class="p">,</span> <span class="n">is_train</span> <span class="o">=</span> <span class="bp">False</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="p">...</span>
        <span class="n">self</span><span class="p">.</span><span class="n">bn0</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

        <span class="c1"># weight initialization
</span>        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">xavier_uniform_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">conv0</span><span class="p">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">xavier_uniform_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">xavier_uniform_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">conv2</span><span class="p">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">xavier_uniform_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">fc0</span><span class="p">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">xavier_uniform_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">fc1</span><span class="p">.</span><span class="n">weight</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">bn0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">pool0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">bn1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">pool1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">bn2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">batch</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
</pre></table></code></div></div><p><br /></p><p>그 후 weight의 초기값을 설정하기 위해 weight initialization을 사용했다. 이에 대한 종류로는 <code class="language-plaintext highlighter-rouge">torch.nn.init.xavier_</code> 들을 많이 사용한다. 이는 학습 데이터에서 통계를 기반으로 weight를 계산한다.</p><p>batchnorm만으로도 성능이 잘 나와서 dropout은 잘 사용하지 않으나, 성능 비교를 위해 마지막 layer에서 dropout을 함으로서 overfitting을 막을 수 있다. 만든 dropout은 fc layer에 추가한다.</p></div><div class="post-tail-wrapper text-muted"><div style="text-align: left;"> <a href="http://hits.dwyl.com/dkssud8150.github.io/posts/cnn/" target="_blank"> <img data-src="http://hits.dwyl.com/dkssud8150.github.io/posts/cnn.svg" data-proofer-ignore> </a></div><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/classlog/'>Classlog</a>, <a href='/categories/devcourse/'>devcourse</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/devcourse/" class="post-tag no-text-decoration" >devcourse</a> <a href="/tags/deeplearning/" class="post-tag no-text-decoration" >deeplearning</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=[데브코스] 10주차 - DeepLearning CNN - JaeHo Yoon&amp;url=https://dkssud8150.github.io/posts/cnn/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=[데브코스] 10주차 - DeepLearning CNN - JaeHo Yoon&amp;u=https://dkssud8150.github.io/posts/cnn/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https://dkssud8150.github.io/posts/cnn/&amp;text=[데브코스] 10주차 - DeepLearning CNN - JaeHo Yoon" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://dkssud8150.github.io/posts/cnn/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6611243953442169" crossorigin="anonymous"></script></div><script src="https://utteranc.es/client.js" repo="dkssud8150/dkssud8150.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/gitpage/">[깃허브 프로필 꾸미기] github 프로필 만들기</a><li><a href="/posts/product/">[깃허브 프로필 꾸미기] productive box 만들기</a><li><a href="/posts/regex/">[데브코스] 2주차 - linux 기초(REGEX)</a><li><a href="/posts/Kfold/">KFold Cross Validation 과 StratifiedKFold</a><li><a href="/posts/cmake/">[데브코스] 17주차 - CMake OpenCV, Eigen, Pangolin install </a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/devcourse/">devcourse</a> <a class="post-tag" href="/tags/deeplearning/">deeplearning</a> <a class="post-tag" href="/tags/cs231n/">CS231N</a> <a class="post-tag" href="/tags/ros/">ros</a> <a class="post-tag" href="/tags/coding-test/">coding test</a> <a class="post-tag" href="/tags/linux/">linux</a> <a class="post-tag" href="/tags/kooc/">kooc</a> <a class="post-tag" href="/tags/opencv/">OpenCV</a> <a class="post-tag" href="/tags/pytorch-tutorial/">pytorch tutorial</a> <a class="post-tag" href="/tags/autonomous-driving/">Autonomous Driving</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/numpy/"><div class="card-body"> <em class="timeago small" date="2022-04-11 14:40:00 +0900" >Apr 11, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[데브코스] 9주차 - DeepLearning Numpy & Matplotlib</h3><div class="text-muted small"><p> Numpy Numpy 설치 및 불러오기 pip install numpy import numpy as np 파이썬의 리스트는 머신러닝에서 가장 많이 사용되는 구조 중 하나일 것이다. 그러나 이 리스트는 연산 속도가 느리다. 그래서 연산을 효과적으로 할 수 있도록 하기 위해 만든 것이 Numpy이다. Numpy 연산 속도 nump...</p></div></div></a></div><div class="card"> <a href="/posts/dplearn/"><div class="card-body"> <em class="timeago small" date="2022-04-12 15:40:00 +0900" >Apr 12, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[데브코스] 9주차 - DeepLearning AI & machine learning</h3><div class="text-muted small"><p> 기계 학습 어떤 컴퓨터 프로그램이 T라는 작업을 수행할 때, 이 프로그램의 성능이 P라는 척도로 평가했을 때 경험 E를 통해 성능이 개선된다면 이 프로그램은 학습한다고 말할 수 있다. 따라서 최적의 알고리즘을 찾는 행위를 기계 학습이라 할 수 있다. 기계 학습의 중심은 경험, 과업, 성능에 있다. 예전에는 지식 기반의 학습을 했다. 즉, 인간이...</p></div></div></a></div><div class="card"> <a href="/posts/mlmath/"><div class="card-body"> <em class="timeago small" date="2022-04-13 15:40:00 +0900" >Apr 13, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[데브코스] 9주차 - DeepLearning Mathematics for Machine Learning</h3><div class="text-muted small"><p> 기계 학습에서 수학은 손실함수를 정의하고 손실함수의 최저점을 찾아주는 최적화 이론에 사용된다. 제어를 함에 있어서도 수학이 필요하다. 선형대수 데이터는 벡터나 행렬, 텐서 형태로 되어 있는데, 이에 대한 공간을 이해하고, 연산을 하기 위해서는 선형대수가 필요하다. 벡터와 행렬 벡터는 요소의 종료와 크기를 표현한다. [x \in R^n] ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/perception/" class="btn btn-outline-primary" prompt="Older"><p>[데브코스] 10주차 - DeepLearning Perception</p></a> <a href="/posts/od/" class="btn btn-outline-primary" prompt="Newer"><p>[데브코스] 10주차 - DeepLearning Object Detection</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">JaeHo YooN</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/devcourse/">devcourse</a> <a class="post-tag" href="/tags/deeplearning/">deeplearning</a> <a class="post-tag" href="/tags/cs231n/">CS231N</a> <a class="post-tag" href="/tags/ros/">ros</a> <a class="post-tag" href="/tags/coding-test/">coding test</a> <a class="post-tag" href="/tags/linux/">linux</a> <a class="post-tag" href="/tags/kooc/">kooc</a> <a class="post-tag" href="/tags/opencv/">OpenCV</a> <a class="post-tag" href="/tags/pytorch-tutorial/">pytorch tutorial</a> <a class="post-tag" href="/tags/autonomous-driving/">Autonomous Driving</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-NC7MWHVXJE"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-NC7MWHVXJE'); }); </script>