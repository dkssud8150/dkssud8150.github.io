<!DOCTYPE html><html lang="en" data-mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="CS231N chapter 5 - Convolutional Neural Networks" /><meta name="author" content="JaeHo-YooN" /><meta property="og:locale" content="en" /><meta name="description" content="4강 리뷰 1) backpropagation 2) Calculation of the local gradient in computational graph. 3) Neural Network linear layer을 쌓고 그 사이에 비선형 layer를 추가하여 neural network를 만듦" /><meta property="og:description" content="4강 리뷰 1) backpropagation 2) Calculation of the local gradient in computational graph. 3) Neural Network linear layer을 쌓고 그 사이에 비선형 layer를 추가하여 neural network를 만듦" /><link rel="canonical" href="https://dkssud8150.github.io/posts/cs231n5/" /><meta property="og:url" content="https://dkssud8150.github.io/posts/cs231n5/" /><meta property="og:site_name" content="JaeHo Yoon" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-09-14T13:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="CS231N chapter 5 - Convolutional Neural Networks" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@JaeHo-YooN" /><meta name="google-site-verification" content="znvuGsQGYxMZPBslC4XG6doCYao6Y-fWibfGlcaMHH8" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"JaeHo-YooN"},"dateModified":"2022-03-22T22:16:59+09:00","datePublished":"2021-09-14T13:00:00+09:00","description":"4강 리뷰 1) backpropagation 2) Calculation of the local gradient in computational graph. 3) Neural Network linear layer을 쌓고 그 사이에 비선형 layer를 추가하여 neural network를 만듦","headline":"CS231N chapter 5 - Convolutional Neural Networks","mainEntityOfPage":{"@type":"WebPage","@id":"https://dkssud8150.github.io/posts/cs231n5/"},"url":"https://dkssud8150.github.io/posts/cs231n5/"}</script><title>CS231N chapter 5 - Convolutional Neural Networks | JaeHo Yoon</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="JaeHo Yoon"><meta name="application-name" content="JaeHo Yoon"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/shin_chan.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">JaeHo Yoon</a></div><div class="site-subtitle font-italic">Mamba Mentality</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fab fa-angellist ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/dkssud8150" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['hoya58150','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="https://www.notion.so/18490713817d403696812c57d0abe730" aria-label="notion" target="_blank" rel="noopener"> <i class="fab fa-battle-net"></i> </a> <a href="https://www.linkedin.com/in/jaeho-yoon-90b62b230" aria-label="linkedin" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href="https://www.instagram.com/jai_ho8150/" aria-label="instagram" target="_blank" rel="noopener"> <i class="fab fa-instagram"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>CS231N chapter 5 - Convolutional Neural Networks</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>CS231N chapter 5 - Convolutional Neural Networks</h1><div class="post-meta text-muted"><div> By <em> <a href="https://github.com/dkssud8150">JaeHo-YooN</a> </em></div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6611243953442169" crossorigin="anonymous"></script><div class="d-flex"><div> <span> Posted <em class="timeago" date="2021-09-14 13:00:00 +0900" data-toggle="tooltip" data-placement="bottom" title="Tue, Sep 14, 2021, 1:00 PM +0900" >Sep 14, 2021</em> </span> <span> Updated <em class="timeago" date="2022-03-22 22:16:59 +0900 " data-toggle="tooltip" data-placement="bottom" title="Tue, Mar 22, 2022, 10:16 PM +0900" >Mar 22, 2022</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3399 words"> <em>18 min</em> read</span></div></div></div><div class="post-content"><blockquote><ul><li>4강 리뷰</ul><p>1) backpropagation</p><p>2) Calculation of the local gradient in computational graph.</p><p>3) Neural Network</p><ul><li>linear layer을 쌓고 그 사이에 비선형 layer를 추가하여 neural network를 만듦</ul></blockquote><p><br /></p><p><br /></p><p><br /></p><h1 id="history-of-convolutional-neural-network">History of Convolutional Neural Network</h1><p>이제 우리가 배울 것은 Convolutional layer이다. 이 layer은 <code class="language-plaintext highlighter-rouge">Spatial Structure</code>를 유지한다.</p><p><br /></p><p>1957년 최초로 perceptron을 구현했고, 여기서 가중치 w를 업데이트하는 방법이 처음 등장했다.</p><p><img data-src="https://media.vlpt.us/images/guide333/post/918b0615-bda5-483f-a7fc-ccf1f923d3b2/Screenshot%20from%202021-01-27%2000-34-55.png" alt="image" data-proofer-ignore></p><p><br /></p><p>1960년에 multi-layer perceptron network(MLP Network)를 발명했다.</p><p><img data-src="https://www.researchgate.net/profile/Mohamed_Zahran6/publication/303875065/figure/fig4/AS:371118507610123@1465492955561/A-hypothetical-example-of-Multilayer-Perceptron-Network.png" alt="image" data-proofer-ignore></p><p><br /></p><p>1986년에 backpropagation이 등장했고, 신경망의 학습이 시작되었다. 2006년에 deep learning의 학습 가능성이 거론되면서 전체 신경망을 backpropagation하거나 fine-tuning하는 식으로 진행되었다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="nf">resnet34</span><span class="p">(</span><span class="n">pretrained</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>   
</pre></table></code></div></div><p><br /></p><p>하지만 컴퓨터 속도와 용량 등의 환경적 요인에 의해 연구가 진행되기 어려웠다.</p><p><br /></p><p>그러다 2012년 imageNet 분류를 통해 에러를 극적으로 감소시키는 AlexNet이 처음 등장하면서 CNN이 알려지기 시작했다.</p><p><img data-src="https://media.vlpt.us/images/guide333/post/9eeecf67-fb62-4a5a-a25d-f80f8e007bf8/Screenshot%20from%202021-01-27%2000-35-58.png" alt="image" data-proofer-ignore></p><p>AlexNet에서 처음으로 batch normalization을 사용했고, GPU를 2대 활용하여 대규모의 데이터를 활용하였다.</p><p><br /></p><p>CNN은 이미지 classification, 이미지 검색, 객체 탐지, segmentation, Lidar와 함께 자율주행, 얼굴 인식, 비디오 분석, 포즈 평가 등 다양하게 활용되고 있다.</p><p><br /></p><p><br /></p><p><br /></p><h1 id="cnn">CNN</h1><ul><li>Fully-Connected Layer</ul><p>FC layer에서 하는 일은 어떤 벡터를 가지고 연산을 하는 것이다.</p><p><img data-src="https://media.vlpt.us/images/guide333/post/e11aea60-2cd5-45dc-bb07-b288373a258b/Screenshot%20from%202021-01-27%2000-37-29.png" alt="image" data-proofer-ignore></p><ol><li>우선 32x32x3 image를 input한다.<li>이 이미지를 길게 펴서 3072x1차원의 벡터로 만든다.<li>가중치 w를 곱한다. (W*x) - 이 예시에서는 w는 10x3072 행렬<li>activation, 즉 output을 얻는다. - 1x10 크기로 출력 될 것이다. 즉 class가 10개고, 그에 대한 각각의 score가 나올 것이다.</ol><p><br /></p><p><br /></p><h2 id="convolution-layer">Convolution layer <a href="#convolution-layer" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>convolutional layer와 기존의 FC layer의 차이점은 conv layer는 기존의 구조를 그대로 보존시킨다는 것이다.</p><p><br /></p><p><img data-src="https://media.vlpt.us/images/guide333/post/7a6ef716-24c5-4c8d-afbe-23d56a9eb5ef/Screenshot%20from%202021-01-27%2000-37-40.png" alt="image" data-proofer-ignore></p><p>이 작은 5x5x3 filter가 우리가 가진 가중치가 되는 것이다.</p><p>filter의 각 w와 공간적 내적을 통해 숫자를 출력한다. 즉, 32x32x3의 입력 이미지에 5x5의 filter를 슬라이딩하면서 값을 추출하는 것이다.</p><p>이때, 3이 의미하는 것은 RGB, 3채널을 뜻하고 depth라고 부른다. filter depth은 입력 이미지의 depth과 동일하게 부여해야 한다.</p><p><br /></p><p>convolution layer에서는 filter의 depth을 제외한 나머지의 크기(ex. 5x5)를 정할 수 있다.</p><p><br /></p><p>입력 이미지에 filter를 슬라이딩하여 내적을 구하는 것을 convolve한다고 한다.</p><p><br /></p><p><br /></p><p><img data-src="https://media.vlpt.us/images/guide333/post/2faccce9-e520-4a22-a924-91a4b7e47ca9/Screenshot%20from%202021-01-27%2000-37-49.png" alt="image" data-proofer-ignore></p><p>기본적으로 계산은 w^T * x + b (b: bias term) 의 식으로 내적을 계산한다.</p><p><br /></p><p><br /></p><p><img data-src="https://1.cms.s81c.com/sites/default/files/2021-01-06/ICLH_Diagram_Batch_02_17A-ConvolutionalNeuralNetworks-WHITEBG.png" alt="image" data-proofer-ignore></p><p>image가 5x5, filter이 3x3 일 경우 5x5 중에서 filter의 크기인 3x3크기만큼만 filter과 내적을 통해 1개의 결과값을 출력한다. 이를 이미지 좌측 상단부터 우측 하단까지 모든 픽셀을 슬라이딩하면서 계산을 하게 되는 것이다.</p><p>위의 사진을 참고했을 때, 다음 계산은 [(4 1 2),(1 1 0),(2 1 0)] 과 filter의 내적이 된다.</p><p>이 1개의 숫자가 나오는 계산식이 w^T * x + b이다.</p><p><br /></p><p><br /></p><p>이 슬라이딩을 통해 얻은 값을 모으면 28x28x1의 이미지가 되는데, 이를 activation map이라 한다.</p><p>출력된 activiation map의 크기는 filter의 크기와 숫자 그리고 슬라이딩을 어떻게 하느냐에 따라 달라진다.</p><p><br /></p><p>보통 convolution layer에서는 여러 개의 필터를 사용한다. 필터마다 다른 특징을 추출할 수 있기 때문이다.</p><p><br /></p><p><br /></p><p><img data-src="https://media.vlpt.us/images/guide333/post/b7380155-6847-48ed-8855-08f9119ab8e7/Screenshot%20from%202021-01-27%2000-38-02.png" alt="image" data-proofer-ignore></p><p>5x5x3의 또 다른 초록색 필터를 가져왔다. 이를 슬라이딩하여 동일하게 28x28x1의 activation map을 얻을 수 있다.</p><p><br /></p><p>6개의 필터를 사용하게 되면 총 6개의 map을 얻을 수 있다. 이렇게 나온 activation map을 모아 크기 28x28x6 의 map을 만들 수 있다.</p><p><br /></p><p><br /></p><p><img data-src="https://media.vlpt.us/images/guide333/post/f964081c-3ef7-4a3a-b2e4-53775e1195a2/Screenshot%20from%202021-01-27%2000-38-16.png" alt="image" data-proofer-ignore></p><p>사이 사이에 ReLU와 같은 actiavtion function을 넣어 conv-ReLU가 반복시킬 수 있다. 또한, 중간 중간에 pooling layer도 추가하기도 한다.</p><p>위의 그림은 32x32x3의 input image를 6개의 5x5x3 filter 6개를 각각 슬라이딩 하여 28x28x6의 activation map을 얻는다.</p><p>이 activation map이 다시 input image가 되어 10개의 5x5x6 filter를 통해 24x24x10의 activation map을 얻는다.</p><p><br /></p><p><br /></p><h3 id="pooling-layer">pooling layer <a href="#pooling-layer" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-src="https://media.vlpt.us/images/guide333/post/7b3c9748-5a84-44a0-8ed5-e1865268951e/Screenshot%20from%202021-01-27%2000-42-18.png" alt="image" data-proofer-ignore></p><p>pooling layer는 convolution시 downsampling을 할 때 이미지의 크기를 줄이면 데이터의 손실이 발생할 수 있다. 정보를 최대한 보존하면서 크기를 줄이기 위해 stride 값을 1로 지정하고 pooling을 통해 크기를 줄인다.</p><p><br /></p><p>또한 pooling을 하면 overfitting을 막을수도 있다. 입력 데이터에 과도하게 맞춰지는 경우를 방지하는 것이다.</p><p>즉, 입력 데이터로 학습한 데이터만 정답으로 인식하고, 그 데이터의 회전, 특정 좌표로 이동, 자름 등의 이미지에 대해서는 유연하지 못한 것을 방지한다.</p><p><br /></p><p>pooling 중에서도 max pooling을 주로 사용하는데, max pooling 이란 pool size내에서 최댓값만 뽑아내는 것을 말한다.</p><p><img data-src="/assets/img/cs231n/2021-09-14/maxpooling.png" alt="image" data-proofer-ignore></p><p>위의 그림은 2x2 max pooling 하는 과정이다. 첫번째 그림의 경우 1 2 0 1 중에서 가장 큰 2를 골라 추출한다.</p><p><br /></p><p>Pooling은 파라미터의 수를 줄이기 때문에 관리가 쉽고, 이미지의 차원을 공간적으로 줄여준다. 하지만 depth는 줄이지는 못한다.</p><p>또한 pooling은 downsampling을 위해 사용하기 떄문에, pooling할 때 비슷한 역할인 padding하지는 않는다.</p><p><br /></p><p><br /></p><h3 id="padding">padding <a href="#padding" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-src="https://blog.kakaocdn.net/dn/8AsqI/btqEzZVNeIx/wrH1PMu4uIaV3rhFfYt38k/img.gif" alt="gif" data-proofer-ignore></p><p>필터를 적용할 때, 모서리에 있는 이미지 데이터의 정보는 중앙에 있는 정보보다 비교적으로 적게 연산되므로 이를 조절해주기 위한 방법이다.</p><p><br /></p><p>즉, 패딩은 출력 데이터의 공간적 크기를 조절해주기 위해 사용하는 파라미터다. 공간적 크기를 조절하여 모서리에 있는 데이터 정보에 대한 연산 수와 중앙에 있는 데이터 정보에 대한 연산 수를 얼추 맞춰 정보가 누락되지 않도록 한다.</p><p><br /></p><p>입력 데이터의 크기와 출력 데이터의 크기를 같게 해주는 것을 zero-padding이라 한다.</p><p>zero-padding은 입력 이미지 바깥에 0으로 이루어진 pixel을 넣어주는 것이다.</p><p><img data-src="https://media.vlpt.us/images/guide333/post/ab12b32b-ce21-4173-b66c-bdff80c5402e/Screenshot%20from%202021-01-27%2000-40-31.png" alt="image" data-proofer-ignore></p><p><br /></p><p>따라서 conv layer에서는 zero padding으로 출력 이미지의 크기와 데이터를 보존하고, 이미지의 크기를 줄이는 것은 pooling에서 진행한다.</p><p><br /></p><p><br /></p><h3 id="stride">stride <a href="#stride" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>입력 데이터와 필터를 연산할 때 기본적으로 1칸씩 움직이면서 연산한다. 이를 stride 값이 1이라 할 수 있다.</p><p>즉, stride는 입력 데이터에 필터를 적용할 때 이동할 간격을 조절해주는 파라미터다.</p><p><br /></p><p>pooling 과 stride는 기능은 비슷하나 stride가 조금 더 좋은 성능을 보이기 떄문에 stride를 더 많이 쓰는 추세다.</p><p><img data-src="https://miro.medium.com/max/700/1*4wZt9G7W7CchZO-5rVxl5g@2x.gif" data-proofer-ignore></p><p>stride = 2 일 때의 pooling을 진행하는 모습이다.</p><p><br /></p><p><br /></p><p><br /></p><p><img data-src="https://media.vlpt.us/images/guide333/post/b88adbb8-ab1b-46e4-983f-cd63a3dc78ec/Screenshot%20from%202021-01-27%2000-38-42.png" alt="image" data-proofer-ignore></p><p>여러 개의 layer을 쌓다보면 각 필터들이 계층적으로 학습한다.</p><p>앞쪽 필터 즉, 입력층과 가까울수록 low-level feature을 학습한다. 뒤로 갈수록 점점 복잡해져 객체와 닮은 것들이 출력으로 나오는 것을 볼 수 있다.</p><p><br /></p><p><br /></p><p><img data-src="https://media.vlpt.us/images/guide333/post/e89bdea0-7d7f-44c8-9c76-09f21f5b4f33/Screenshot%20from%202021-01-27%2000-42-11.png" alt="image" data-proofer-ignore></p><p>수많은 conv-relu-pooling layer들을 지나 마지막에는 3D conv output을 1차원으로 펴서 FC(fully connected) layer에 집어넣어 최종 스코어를 계산한다.</p><p><br /></p><p><br /></p><p><img data-src="https://media.vlpt.us/images/guide333/post/58cf723b-fe26-4584-8620-a6b39f94a28c/Screenshot%20from%202021-01-27%2000-40-11.png" alt="image" data-proofer-ignore></p><p>activation map의 차원을 구하는 공식은 다음과 같다.</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>NxNx3 input image, fxfx3 filter 일 경우 activation map 의 크기는 :

[(N - f + 1)/stride size] x [(N - f + 1)/stride size]x number of filter
ex) N=6 , f=2, 5개 filter, stride=2 =&gt; 3x3x5 의 activation map
</pre></table></code></div></div><p>예를 들어 32x32x3 의 입력 이미지를 10개의 5x5 filter를 stride=1, padding=2 로 convolution 한다면</p><p>output size는 32x32x10이다.</p><p>padding=2 이므로 양쪽에 2씩 더한 후 [{(32 + 2*2)-5}/1] + 1 = 이므로 32가 된다.</p><p><br /></p><p>이 때 파라미터의 개수는</p><p>5 * 5 * 3 + 1(bias) = 76개의 파라미터를 가지고, 필터의 개수 10을 곱하면 760개의 파라미터가 존재한다.</p><p><br /></p><p>보통 filter의 갯수는 2의 제곱수로 설정하고, stride는 1 or 2로 설정한다. 필터는 3x3 또는 5x5를 많이 사용한다.</p><p><br /></p><p><br /></p><h3 id="1x1-convolution-layer">1x1 convolution layer <a href="#1x1-convolution-layer" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>이미지의 depth 크기를 줄이는 방법으로 1x1 convolution layer을 사용할 수 있다.</p><p><br /></p><p><img data-src="https://media.vlpt.us/images/guide333/post/a5e23037-9b44-471b-b84e-05acab26763e/Screenshot%20from%202021-01-27%2000-41-27.png" alt="image" data-proofer-ignore></p><p>위의 그림은 56x56x64의 입력이미지에 32개의 1x1 conv 필터를 적용한다.</p><p><br /></p><p><img data-src="https://mblogthumb-phinf.pstatic.net/MjAxOTA5MjNfMTgz/MDAxNTY5MTgwOTc0NzEy.u_h-966gHyXG_ySFfh0uw5l9wEl5N7orR-qdnTBVLpkg.vnutj6UmaoggZGeQvu9WgUeM8Aj08rkAxmyGjQjN6xsg.PNG.wjddudwo209/1x1_convolution.png?type=w2" alt="image" data-proofer-ignore></p><p>1x1 conv를 한다는 것은 1x1 만한 filter로 64개를 모두 내적한 다음 이것을 한 픽셀로 축소시킨다는 것이다.</p><p>즉 1x1 conv = 1x1x64 filter가 된다.</p><p><br /></p><blockquote><p>FC layer에서의 filter와 1x1 conv filter의 차이는 크기는 같을 수 있으나 FC layer는 고정된 크기를 입력이미지로 받지만, conv layer은 공간적으로 더 큰 입력 이미지를 받는다는 점이 다르다.</p></blockquote><p>이것을 32번을 수행하므로 차원은 줄어들지 않는 56x56이고, 32개 필터이므로 56x56x32 가 output size가 된다.</p><p><br /></p><p>1x1 convolution 은 depth를 줄여주는 역할을 한다.</p><p>위의 경우처럼 56x56x64 였던 이미지에 1x1 conv를 k개 필터를 적용한다면 output은 56x56xk가 된다.</p><p><br /></p><p><br /></p><p><br /></p><h3 id="convolution-layer-code">Convolution layer Code <a href="#convolution-layer-code" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>추가로</p><p>간단한 conv architecture을 가져와봤다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="c1"># keras CNN
</span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s">"same"</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">relu</span><span class="p">),</span> <span class="c1"># 32는 필터의 개수, kernel_size는 필터의 크기
</span>    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">MaxPool2D</span><span class="p">(</span><span class="nf">pool_size</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s">"same"</span><span class="p">),</span> <span class="c1"># (pool_size: 윈도우 크기, strides:윈도우가 움직이고자 하는 거리, padding:데이터가 없는 부분에 zero-padding)
</span>    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s">"same"</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">relu</span><span class="p">),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">MaxPool2D</span><span class="p">(</span><span class="nf">pool_size</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s">"same"</span><span class="p">),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Flatten</span><span class="p">(),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">"softmax"</span><span class="p">)</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
<span class="p">])</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
</pre><td class="rouge-code"><pre><span class="c1"># torch CNN
</span><span class="k">class</span> <span class="nc">CNN</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>                                                     <span class="c1"># 마찬가지로 nn.module 클래스를 상속받는다.
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">CNN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>                                       
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span>                                           <span class="c1"># 2차원 이미지 데이터를 nn.conv2d메서드를 이용해 convolution연산을 하는 filter
</span>                               <span class="n">in_channels</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>                           <span class="c1"># filter의 크기는 상관없지만, 채널 수를 이미지의 채널 수와 동일하게 맞춰야 한다. 그래서 3으로 지정
</span>                               <span class="n">out_channels</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>                          <span class="c1"># 설정해주는 filter개수만큼 depth가 정해진다. filter개수만큼 앞뒤로 쌓아 feature map을 형성하기 때문이다.
</span>                               <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>                           <span class="c1"># filter의 크기를 정하는 부분이다. 스칼라 값으로 설정하려면 가로*세로 크기인 filter을 이용해야 한다. 
</span>                                                                          <span class="c1"># 여기서 3x3 로 이용한다. 3x3 filter가 이미지 위를 9개의 픽셀 값과 filter 내에 있는 9개의 파라미터 값을 연산으로 진행
</span>                               <span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>                               <span class="c1"># 중앙에 비해 가장자리가 덜 연산되기에 테두리에 0을 채워 연산 횟수를 동일하게 맞춰주는 것
</span>                                                                          <span class="c1"># 1로 설정하면 왼쪽에 1층, 오른쪽에 1층, 위 1층, 아래 1층으로 채움
</span>        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>                           <span class="c1"># 앞에서 filter 수를 8로 했기에 입력을 8로 한다.
</span>                               <span class="n">out_channels</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>                         <span class="c1"># depth를 16으로 지정
</span>                               <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> 
                               <span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>             <span class="c1"># convolution을 통해 feature map이 생성됐을 때, feture map을 부분적으로 이용한다. 
</span>                                                                          <span class="c1"># convolution을 통해 다양한 수치가 생성되기 때문이다. maxpool2d는 2차원의 feature map 내에서 가장 큰 값만 이용
</span>        <span class="n">self</span><span class="p">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">8</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>                              <span class="c1"># convolution을 하는 이유는 이미지 내 픽셀과의 조합을 통한 특징을 추출
</span>                                                                          <span class="c1"># feature map을 다양한 convolution을 통해 추출 후 1차원으로 펼친 후 여러 층의 fully connected layer를 통과시켜 분류
</span>                                                                          <span class="c1"># 1차원으로 펼쳐도 이미 주변 정보를 반영한 결괏값으로 존재하기 때문에, 기존의 한계를 해결할 수 있다. 
</span>                                                                          <span class="c1"># 앞의 conv1,conv2 연산에서 feature map의 크기는 forward부분을 계산한 결과 8*8*16크기의 map이 된다.
</span>                                                                          <span class="c1"># 즉 8*8의 2차원 데이터 16개가 겹쳐 있는 형태이다. 이를 1차원 데이터로 펼쳐 이용한다.
</span>        <span class="n">self</span><span class="p">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>                        
        <span class="n">self</span><span class="p">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>                                      <span class="c1"># 원핫인코딩으로 표현된 벡터 값과 loss를 계산해야 하므로 10으로 설정
</span>        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>                                                 <span class="c1"># forward propagation을 정의
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>                                                     <span class="c1"># convolution연산을 통해 생성된 feature map값에 비선형 함수 relu를 적용
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>                                                  <span class="c1"># maxpooling을 통해 생성된 feature map에 다운 샘플링을 적용한다.
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">16</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></table></code></div></div><p><br /></p><p><br /></p><p><br /></p><h1 id="reference">Reference</h1><ul><li><a href="http://cs231n.stanford.edu/2017/syllabus.html">http://cs231n.stanford.edu/2017/syllabus.html</a><li><a href="https://velog.io/@guide333/%ED%92%80%EC%9E%8E%EC%8A%A4%EC%BF%A8-CS231n-5%EA%B0%95-2-Neural-Networks">https://velog.io/@guide333/%ED%92%80%EC%9E%8E%EC%8A%A4%EC%BF%A8-CS231n-5%EA%B0%95-2-Neural-Networks</a><li><a href="https://dsbook.tistory.com/72?category=780563">https://dsbook.tistory.com/72?category=780563</a></ul></div><div class="post-tail-wrapper text-muted"><div style="text-align: left;"> <a href="http://hits.dwyl.com/dkssud8150.github.io/posts/cs231n5/" target="_blank"> <img data-src="http://hits.dwyl.com/dkssud8150.github.io/posts/cs231n5.svg" data-proofer-ignore> </a></div><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/classlog/'>Classlog</a>, <a href='/categories/cs231n/'>CS231N</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/cs231n/" class="post-tag no-text-decoration" >CS231N</a> <a href="/tags/cnn/" class="post-tag no-text-decoration" >CNN</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=CS231N chapter 5 - Convolutional Neural Networks - JaeHo Yoon&amp;url=https://dkssud8150.github.io/posts/cs231n5/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=CS231N chapter 5 - Convolutional Neural Networks - JaeHo Yoon&amp;u=https://dkssud8150.github.io/posts/cs231n5/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https://dkssud8150.github.io/posts/cs231n5/&amp;text=CS231N chapter 5 - Convolutional Neural Networks - JaeHo Yoon" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://dkssud8150.github.io/posts/cs231n5/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6611243953442169" crossorigin="anonymous"></script></div><script src="https://utteranc.es/client.js" repo="dkssud8150/dkssud8150.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/gitpage/">[깃허브 프로필 꾸미기] github 프로필 만들기</a><li><a href="/posts/product/">[깃허브 프로필 꾸미기] productive box 만들기</a><li><a href="/posts/regex/">[데브코스] 2주차 - linux 기초(REGEX)</a><li><a href="/posts/Kfold/">KFold Cross Validation 과 StratifiedKFold</a><li><a href="/posts/cmake/">[데브코스] 17주차 - CMake OpenCV, Eigen, Pangolin install </a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/devcourse/">devcourse</a> <a class="post-tag" href="/tags/deeplearning/">deeplearning</a> <a class="post-tag" href="/tags/cs231n/">CS231N</a> <a class="post-tag" href="/tags/ros/">ros</a> <a class="post-tag" href="/tags/coding-test/">coding test</a> <a class="post-tag" href="/tags/linux/">linux</a> <a class="post-tag" href="/tags/kooc/">kooc</a> <a class="post-tag" href="/tags/opencv/">OpenCV</a> <a class="post-tag" href="/tags/pytorch-tutorial/">pytorch tutorial</a> <a class="post-tag" href="/tags/autonomous-driving/">Autonomous Driving</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/cs231n6/"><div class="card-body"> <em class="timeago small" date="2021-09-22 13:00:00 +0900" >Sep 22, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>CS231N chapter 6 - Training Neural Network part 1</h3><div class="text-muted small"><p> 5강 리뷰 1) History of CNN 2) CNN pooling padding stride 1x1 conv layer Training Neural Networks NN 학습을 위해 필요한 기본 설정들에는 Activation Functions, Data Prepr...</p></div></div></a></div><div class="card"> <a href="/posts/cs231n7/"><div class="card-body"> <em class="timeago small" date="2021-09-23 13:00:00 +0900" >Sep 23, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>CS231N chapter 7 - Training Neural Network part 2</h3><div class="text-muted small"><p> 6강 리뷰 1) Activation Functions Sigmoid tanh ReLU leaky ReLU ELU Maxout 2) Data Preprocessing 3) Weight Initialization Xavier initialization 4) ...</p></div></div></a></div><div class="card"> <a href="/posts/cs231n1/"><div class="card-body"> <em class="timeago small" date="2021-09-04 13:00:00 +0900" >Sep 4, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>CS231N chapter 1 - Course Introduction</h3><div class="text-muted small"><p> A brief history of Computer Vision Biological Vision 아주 먼 옛날, 눈을 통해 동물들은 진화했다. Human Vision 카메라와 같이 사람의 눈과 유사하게 사진을 담을 수 있도록 만들어졌다. Computer Vision ** David Mars** 이미지를 인식하고 최종...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/cs231n4/" class="btn btn-outline-primary" prompt="Older"><p>CS231N chapter 4 - Backpropagation and Neural</p></a> <a href="/posts/KFashion/" class="btn btn-outline-primary" prompt="Newer"><p>K-Fashion AI contest</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">JaeHo YooN</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/devcourse/">devcourse</a> <a class="post-tag" href="/tags/deeplearning/">deeplearning</a> <a class="post-tag" href="/tags/cs231n/">CS231N</a> <a class="post-tag" href="/tags/ros/">ros</a> <a class="post-tag" href="/tags/coding-test/">coding test</a> <a class="post-tag" href="/tags/linux/">linux</a> <a class="post-tag" href="/tags/kooc/">kooc</a> <a class="post-tag" href="/tags/opencv/">OpenCV</a> <a class="post-tag" href="/tags/pytorch-tutorial/">pytorch tutorial</a> <a class="post-tag" href="/tags/autonomous-driving/">Autonomous Driving</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { function updateMermaid(event) { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { const mode = event.data.message; if (typeof mermaid === "undefined") { return; } let expectedTheme = (mode === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* Re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } let initTheme = "default"; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); window.addEventListener("message", updateMermaid); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-NC7MWHVXJE"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-NC7MWHVXJE'); }); </script>