---
layout:   post
title:    "CS231N chapter 1 - Course Introduction"
subtitle: "Nearest Neighbors / linear Classification"
category: Classlog
tags:     CS231N

---

1. this ordered seed list will be replaced by the toc
{:toc}

## A brief history of Computer Vision

* Biological Vision

아주 먼 옛날, 눈을 통해 동물들은 진화했다.

* Human Vision

카메라와 같이 사람의 눈과 유사하게 사진을 담을 수 있도록 만들어졌다.

* Computer Vision

** David Mars**

![image](https://jeongukjae.github.io/images/cs231n/Lecture1-1.png)

이미지를 인식하고 최종 단계는 3D 표현이다. 이에 도달하기 위해 여러 프로세스를 거친다. 
1. 이미지가 들어온다.
2. primal sketch라고 하여 대부분의 가장자리나 막대 끝, 가상선, 곡선, 경계가 표현되는 곳을 정의한다. 
3. 그 다음 프로세스를 2.5D 스케치라고 한다. 여기에서는 표면, 깊이 정보, 레이어 또는 시각적 장면의 불연속성을 결합하기 시작한다.
4. 모든 것을 결합되면 표면 및 원시적 관점에서 계층적으로 구성된 3D 모델을 갖게 된다. <br>


![image](https://jeongukjae.github.io/images/cs231n/Lecture1-2.png)

70년대에 접어들면서 우리가 물체를 인식하고 표현할 수 있는 방법에 대해 생각하기 시작했다. 그래서 크게 두 가지 이론을 제시했다. 

하나는 `Generalized Cylinder`라고 하고, 다른 하나는 `Pictorial Structure`라고 한다.

두 아이디어는 모든 객체가 기본적인 기하학적 요소로 구성될 수 있다고 가정한다. 예를 들어, 사람은 일반화된 원통형 모양으로 만들수도 있고, 점으로 찍어 그 사이를 연결하는 모양으로 만들어 질수도 있다. 따라서 두 아이디어는 복잡한 구조를 더 간단한 모양으로 축소할 수 있다. 

이 물체 인식 기술은 SVM, Boosting, graphical model과 같은 기술로 인해 발전하기 시작했다. AdaBoost 알고리즘을 사용하여 *Paul Viola*와 *Michael Jones*의 실시간 얼굴 감지를 수행했다.

그 후, 전체론적 장면을 인식하기 시작했다. spatial pyramid matching이 이에 해당한다. 풍경, 부엌, 고속도로 등 어떤 장면인지에 대한 단서를 제공할 수 있는 이미지의 특징이 있다. 이것을 다른 해상도로 만들어 feature descriptor에 넣어서 특징을 가져온다. 이러한 기능을 잘 결합하여 사실적인 이미지를 인식할 수 있는 방법을 살펴보는 여러 작업이 있다. 

하나는 `histogram of gradients`(HOG) 

![image](https://i.imgur.com/EbXbVQl.png)


다른 하나는 `deformable part model`(DPM) 이라고 한다.

![image](https://www.researchgate.net/profile/Naimat-Khan-2/publication/327484494/figure/fig1/AS:837285243285505@1576635766724/Deformable-Parts-Model.png)<br><br>


## PASCAL Visual Object Challenge

![Full-width image](https://jeongukjae.github.io/images/cs231n/Lecture1-4.png)

2000년대 초반 객체 인식에 필요한 데이터셋을 구성했다. PASCAL 데이터셋이라 하여 20개의 객체 클래스로 구성되었다. 카테고리당 약 1만 개의 이미지로 구성되어있다. <br>



## ImageNet

위 대부분의 방법은 과적합될 가능성이 매우 높은 기계 학습 모델이다. 우리는 매우 높은 차원을 입력하고, 적합한 매개변수가 많이 있어야 하며 훈련 데이터가 충분하지 않을 때 과적합이 잘 발생하기 때문이다. 

이 과적합을 해결하고자 ImageNet이라는 것을 만들었다. 우리가 찾을 수 있는 모든 사진들을 가능한 가장 큰 데이터셋으로 모아 훈련시킨다. 거의 1500만의 이미지와 22000개의 카테고리를 구성했다. 



## Convolutional Neural Networks

object detection은 전체 이미지를 한 클래스로 분류하는 것이 아니라 bounding box를 그려 어디에 개가 있고, 어디에 고양이가 있는지를 표현한다.  

Convolutional Neural Networks(CNN)이 등장하면서 매우 복작합 모델도 가능하게 되었다. 이는 멀티 레이어를 가지는 복합적인 모델이다. 또한 부가적으로 pooling 등을 수행할 수도 있다. 이 결과를 Classifier에 입력하여 물체를 분류하게 된다. 



## Reference
* http://cs231n.stanford.edu/2017/syllabus.html
* https://jeongukjae.github.io/posts/CS231n-Lecture-1.-Introduction-to-Convolution-Neural-Networks-for-Visual-Recognition/



