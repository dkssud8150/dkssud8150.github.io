---
title:    "[KOOC] ì¸ê³µì§€ëŠ¥ ë° ê¸°ê³„í•™ìŠµ ê°œë¡  7ì£¼ì°¨ - Bayesian Network "
author:
  name: JaeHo YooN
  link: https://github.com/dkssud8150
date: 2022-10-15 18:10:00 +0800
categories: [Classlog, kooc]
tags: [kooc]
toc: true
comments: true
math: true
---

# Chapter 7. Bayesian Network

- ëª©ì°¨

1. Probability
  - recover the probability concepts
  - recover the probability theorems
  - recover the concepts of the marginal and the conditional independencies
2. Bayesian networks
  - syntax and semantics of Bayesian Networks
  - how to factorize Bayesian networks
  - calculate a probability with given conditions
3. inference of Bayesian networks
  - calculate parameters of Bayesian networks
  - list the exact inference of Bayesian networks

&nbsp;

&nbsp;

## 7-1. theorems of Probability

bayesian networkì— ë“¤ì–´ê°€ê¸° ì „ì—, probabilityì— ëŒ€í•œ ë³µìŠµì„ í•˜ê³ ì í•œë‹¤. 

&nbsp;

- Conditional Probability

conditional probabilityë€ íŠ¹ì • ìƒí™©ì´ ì£¼ì–´ì¡Œì„ ë•Œì˜ í™•ë¥ ì„ êµ¬í•˜ëŠ” ê²ƒì´ë‹¤.

<img src="/assets/img/kooc/week78/conditional_probability.png">

ì˜ˆë¥¼ ë“¤ì–´, Aì™€ Bì— ëŒ€í•œ ìƒí™©ì´ ì¡´ì¬í•œë‹¤ê³  ìƒê°í•´ë³´ì. Bê°€ ì£¼ì–´ì¡Œì„ ë•Œì˜ Aì˜ í™•ë¥ ì„ êµ¬í•œë‹¤ëŠ” ê²ƒì€ P(F=True)ì¸ ì˜ì—­ ì†ì—ì„œ P(H=True)ì¸ ì˜ì—­ì— í•´ë‹¹í•œë‹¤.

ì´ëŠ” P(A = true \| B = true) ì™€ ê°™ì´ í‘œí˜„í•œë‹¤.

$$ P(A = true | B = true) = \cfrac{P(A,B)}{P(B)} $$

&nbsp;

- Joint Probability

ë¹„ìŠ·í•œ ê°œë…ìœ¼ë¡œ Joint Probabilityë¼ëŠ” ê²ƒì´ ìˆë‹¤. P(A = true, B = true) ì™€ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆê³ , ì´ëŠ” A = true ì™€ B = true ì¸ í™•ë¥ ì„ ë‚˜íƒ€ë‚¸ë‹¤.

$$ P(A = true, B = true) = P(A|B)P(B) $$

<img src="/assets/img/kooc/week78/joint_probability.png">

&nbsp;

ì´ ë‘ ê°œë…ì„ í™œìš©í•˜ì—¬ ê°œë³„ í™•ë¥ ì¸ marginal probabilityë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤.

$$ P(a) = \sum_b P(a,b) = \sum_b P(a|b)P(b) $$

&nbsp;

ë§Œì•½, joint distributionì¸ P(a,b,c,d) ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ìš°ë¦¬ëŠ” P(b)ì— ëŒ€í•´ ì‹ì„ ì„¸ìš¸ ìˆ˜ ìˆë‹¤.

$$ P(b) = \sum_a \sum_c \sum_d P(a,b,c,d) $$

ë˜ëŠ”, joint distributionì„ í†µí•´ conditional probabilityë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤.

$$ P(c|b) = \sum_a \sum_d P(a,c,d | b) = 1/P(b) \sum_a \sum_d P(a,c,d,b) $$

ì´ ë•Œ, 1/P(b) ëŠ” normalization constant(ì •ê·œí™” ìƒìˆ˜) ì´ë‹¤.

&nbsp;

ì´ë ‡ê²Œë§Œ ë³´ë©´ joint probablityê°€ ë§¤ìš° ê°•ë ¥í•œ ê°œë…ì´ë¼ ìƒê°ì´ ë˜ì§€ë§Œ, joint probabilityë¥¼ êµ¬í•˜ê¸° ìœ„í•´ì„œëŠ” ê°œë³„ í™•ë¥ ë“¤ì„ ì•Œì•„ì•¼ í•˜ë¯€ë¡œ, featureì˜ ê°œìˆ˜ì™€ ê°œë³„ ê²½ìš°ì˜ ìˆ˜ì— ë”°ë¼ ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ íŒŒë¼ë¯¸í„°ê°€ ì¦ê°€í•œë‹¤.

ë§Œì•½ feature ê°œìˆ˜ê°€ 4ê°œì´ê³ , ê°œë³„ featureì´ true/falseë¡œ êµ¬ì„±ëœë‹¤ë©´ ì´ 16-1 ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ êµ¬í•´ì•¼ í•œë‹¤.

&nbsp;

joint probabilityì˜ ë˜ë‹¤ë¥¸ íŠ¹ì§•ìœ¼ë¡œëŠ” **chain rule** ì´ë‹¤.

$$ P(a,b,c,...z) = P(a|b,c,...,z)P(b,c,...,z) = P(a|b,c,...,z)P(b|c,...,z)P(c|...,z)...P(z) $$

&nbsp;

&nbsp;

- Independence

variable Aì™€ Bê°€ ë…ë¦½ì ì¼ ë•ŒëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê´€ê³„ê°€ ì„±ë¦½ëœë‹¤.

- P(A\|B) = P(A)
- P(A,B) = P(A)P(B)
- P(B|A) = P(B)

&nbsp;

ë”°ë¼ì„œ P(C1,...,Cn) ì˜ joint distributionì„ ê³„ì‚°í•˜ëŠ” ê²ƒì€ ê°„ë‹¨í•˜ë‹¤.

$$ P(C_1,...,C_n) = \prod_{i=1}^n P(C_i) $$

&nbsp;

- Conditional Independence & Marginal Independence
    - Marignal independence
        - P(A=true\|B=true) > P(A=true) ë¼ë©´ ì´ ê²½ìš°ëŠ” marginally independentê°€ ì•„ë‹ˆë‹¤.
        - ì¦‰, Aì™€ BëŠ” P(A) = P(A\|B) ì¼ë•Œë§Œ ë…ë¦½ì ì´ì–´ì•¼ í•œë‹¤.
    - Conditional Independence
        - P(A=true\|B=true, C=true) = P(A=true\|C=true) ì´ë©´, conditional independentí•˜ë‹¤.

&nbsp;

&nbsp;

## 7-2. Bayesian Network

ì´ì „ì— Naive Bayes Classifierì„ ë°°ì› ê³ , ì´ì— ëŒ€í•œ functionì„ ì •ì˜í–ˆë‹¤.

$$ f_{NB}(x) = argmax_{Y=y}P(Y=y) \prod_{1 \leq i \leq d} P(X_i = x_i | Y = y) $$

<img src="/assets/img/kooc/week78/bayesian_network.png">

bayesian networkëŠ” graphical notation í•œ íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆë‹¤. ì¦‰

- random variable
- conditional independence
- obtain a compact representation of the full joint distribution

ì— ëŒ€í•œ ì •ë³´ê°€ ë“¤ì–´ìˆë‹¤.

&nbsp;

- Syntax(ë¬¸ë²•)

bayesian networkëŠ”

- acyclic(ì‚¬ì´í´ì´ ì¡´ì¬x), directed graph
- nodes
    - random variable
    - P(X_i\| Parents(X_i)) (e.g. P(X1\|Y))
- link
    - Direct influence from the parent to the child

ë„¤íŠ¸ì›Œí¬ì˜ êµ¬ì¡°ëŠ” conditional independenceë¥¼ ê°€ì •í•˜ê³  ìˆë‹¤. 

<img src="/assets/img/kooc/week78/conditional_independence.png">

ì¦‰, toothache(ì¹˜í†µ)ê³¼ stench(ì•…ì·¨)ëŠ” ì¶©ì¹˜(cavity)ì™€ëŠ” ê´€ê³„ê°€ ìˆì§€ë§Œ, weatherê³¼ëŠ” ê´€ê³„ê°€ ì—†ë‹¤. ë”°ë¼ì„œ weatherì€ variableê³¼ëŠ” ë…ë¦½ì ì´ê³ , toothacheì™€ stenchëŠ” cavityì™€ conditionally independentí•˜ë‹¤.

&nbsp;

ìœ ëª…í•œ ì˜ˆì‹œë¥¼ í•˜ë‚˜ ë“¤ì–´ë³´ì.

<img src="/assets/img/kooc/week78/bayesian_network_example.png">

ë„ë‘‘(buglary)ì´ ë“¤ê±°ë‚˜, ì§€ì§„(earthquake)ì´ ë°œìƒí–ˆì„ ë•Œ, ì•ŒëŒ(Alarm)ì´ ìš¸ë¦¬ëŠ”ë°, ì•ŒëŒì´ ìš¸ë¦¬ë©´, ì´ì›ƒì¸ Johnê³¼ Maryê°€ ì „í™”ë¥¼ í•˜ëŠ” ìƒí™©ì´ë‹¤.

ì•ŒëŒì— ëŒ€í•œ í™•ë¥ ì€ P(A\|B,E) ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆê³ , Johnì´ ì „í™”í•˜ëŠ” ê²ƒì— ëŒ€í•œ í™•ë¥ ì€ P(J\|A), Maryê°€ ì „í™”í•  í™•ë¥ ì€ P(M\|A) ì´ë‹¤.

ì´ networkì—ì„œì˜ Variableì€ Burglary, Earthquake, Alarm, JohnCalls, MaryCalls, ëª¨ë‘ì´ë‹¤.

&nbsp;

ì •ì„±ì (Qualitative)ì¸ ìš”ì†Œë¡œëŠ” 

- ì¸ê³¼ê´€ê³„ì— ëŒ€í•œ ì‚¬ì „ì •ë³´
- ë°ì´í„°ë¡œë¶€í„°ì˜ í•™ìŠµ
- ë„¤íŠ¸ì›Œí¬ì˜ êµ¬ì¡°

&nbsp;

ì •ëŸ‰ì (Quantitative)ì¸ ìš”ì†Œë¡œëŠ”

- ì¡°ê±´ë¶€ í™•ë¥  í…Œì´ë¸”(ì´ë¯¸ì§€ì—ì„œì˜ ìš°í•˜ë‹¨ í‘œ)

&nbsp;

&nbsp;

<img src="/assets/img/kooc/week78/local_structure.png">

ìœ„ì˜ êµ¬ì¡°ëŠ” ê°„ë‹¨í–ˆì§€ë§Œ, ì´ëŸ¬í•œ networkë¥¼ ë³µì¡í•˜ê²Œ êµ¬ì„±í•  ìˆ˜ë„ ìˆë‹¤. ì´ëŸ´ ë•Œ, ì§€ì—­ì ì¸ variableë“¤ì— ëŒ€í•œ ê´€ê³„ë¥¼ ì •ì˜í•  ìˆ˜ ìˆë‹¤. 

- Common parent
  - ë™ì¼í•œ parent variableì„ ê°€ì§„ ë‹¤ë¥¸ variableì— ëŒ€í•´ì„œëŠ” ë…ë¦½ì ì´ë‹¤. ì¦‰, Johnì´ ì „í™”í•  í™•ë¥ ê³¼ Maryê°€ ì „í™”í•  í™•ë¥ ì€ ì„œë¡œ ë…ë¦½ì ì´ë‹¤.
  - ğ½ âŠ¥ ğ‘€\|ğ´
    - P(J,M\|A) = P(J\|A)P(M\|A)

- Cascading
  - ì—°ì‡„ì‘ìš©ìœ¼ë¡œì„œ, ì—°ê²°ë˜ì–´ ìˆëŠ” variableì¼ ë•Œ, Aê°€ ì£¼ì–´ì¡Œë‹¤ë©´, Bì™€ Mì€ ë…ë¦½ì´ë‹¤. maryê°€ ì „í™”í•  í™•ë¥ ì€ Aë¥¼ ì•Œê³  ìˆë‹¤ë©´ BëŠ” í•„ìš”ê°€ ì—†ë‹¤. ì¦‰ direct influenceì— ëŒ€í•œ í™•ë¥ ì„ ì•ˆë‹¤ë©´ indirect influence variableê³¼ëŠ” ë…ë¦½ì ì´ë‹¤.
  - B âŠ¥ M\|A
    - P(M\|B,A) = P(M\|A) 

- V-structure
  - Bì™€ EëŠ” ê³µí†µì˜ childë¥¼ ê°€ì§€ëŠ” ìƒí™©ì„ V-structureì´ë¼ í•˜ëŠ”ë°, Aê°€ ì£¼ì–´ì§€ì§€ ì•Šì•˜ë‹¤ë©´, Bì™€ Mì€ ê´€ê³„ê°€ ì—†ìœ¼ë¯€ë¡œ, ë…ë¦½ì ì´ë‚˜, Aê°€ ì£¼ì–´ì§„ë‹¤ë©´, Bì™€ EëŠ” ê´€ê³„ê°€ ìƒê¸°ëŠ” ê²ƒì´ë¯€ë¡œ ë…ë¦½ì´ ë˜ì§€ ì•ŠëŠ”ë‹¤.
  - ~ (B âŠ¥ E\|A)
    - P(B,E,A) = P(B)P(E)P(A\|B,E)

&nbsp;

<img src="/assets/img/kooc/week78/bayes_ball_algorithm.png">

ì´ëŸ¬í•œ ë³µì¡í•œ ê´€ê³„ë¥¼ ì‰½ê²Œ ì´í•´í•˜ê¸° ìœ„í•´ **Bayes Ball Algorithm** ì´ë¼ëŠ” ê°œë…ì„ ë„ì…í•œë‹¤. ë§Œì•½ $ X_A âŠ¥ X_B \| X_C $ ë¥¼ í™•ì¸í•˜ê³ ì í•  ë•Œ, ì¦‰ X_Cê°€ ì£¼ì–´ì¡Œì„ ë•Œ, X_Aì™€ X_Bê°€ ë…ë¦½ì¸ì§€ì— ëŒ€í•´ íŒë‹¨í•˜ê³ ì í•  ë•Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.

ê³µì„ êµ´ë¦°ë‹¤ê³  ìƒê°í•´ì„œ, ë§Œì•½ ë°©í–¥ì´ -\> ì¼ ë•Œ, ì˜¤ë¥¸ìª½ variableì´ ì£¼ì–´ì§„ë‹¤ë©´(íšŒìƒ‰) ê³µì´ êµ´ëŸ¬ê°€ì§€ì§€ ì•Šê³ , variableì´ ì£¼ì–´ì§€ì§€ ì•ŠëŠ”ë‹¤ë©´(ë¬´ìƒ‰) êµ´ëŸ¬ê°ˆ ìˆ˜ ìˆë‹¤. ë°˜ëŒ€ë¡œ ë°©í–¥ì´ \<- ì´ë¼ë©´, ì˜¤ë¥¸ìª½ variableì´ ì£¼ì–´ì¡Œì„ ë•ŒëŠ” êµ´ëŸ¬ê°€ì§€ê³ , variableì´ ì£¼ì–´ì§€ì§€ ì•Šì•˜ì„ ë•ŒëŠ” êµ´ëŸ¬ê°ˆ ìˆ˜ ì—†ë‹¤.

&nbsp;

ìœ„ì˜ local structureë“¤ì— ì ìš©í•´ë³´ì.

- Common parent

ë‘ ê°œì˜ variableì´ ê³µí†µì˜ í•œ ê°œ parentë¥¼ ê°€ì§€ëŠ”ë°, parentê°€ ì£¼ì–´ì§„ë‹¤ë©´, ê³µì´ êµ´ëŸ¬ê°ˆ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì´ ë‘ variableì€ ë…ë¦½ì ì´ê³ , ì£¼ì–´ì§€ì§€ ì•ŠëŠ”ë‹¤ë©´, ë…ë¦½ì´ ì•„ë‹ˆë‹¤.

&nbsp;

- Cascading

ì„¸ ê°œì˜ variableì´ ì—°ì†ì ìœ¼ë¡œ ì¡´ì¬í•˜ëŠ”ë°, ì¤‘ê°„ì˜ variableì´ ì£¼ì–´ì§„ë‹¤ë©´, ë‚˜ë¨¸ì§€ ë‘ ê°œì˜ variableì€ ê³µì´ êµ´ëŸ¬ê°ˆ ìˆ˜ ì—†ì–´ì„œ ë…ë¦½ì´ê³ , ì£¼ì–´ì§€ì§€ ì•ŠëŠ”ë‹¤ë©´, ê³µì´ êµ´ëŸ¬ê°ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë…ë¦½ì´ ì•„ë‹ˆë‹¤.

&nbsp;

- V-structure

ë‘ ê°œì˜ variableì´ ê³µí†µì˜ í•œ ê°œ childë¥¼ ê°€ì§€ëŠ”ë°, childê°€ ì£¼ì–´ì§„ë‹¤ë©´, V-structureì€ common parentì™€ ë°˜ëŒ€ë¡œ, ê³µì´ êµ´ëŸ¬ ê°ˆ ìˆ˜ ìˆì–´ì„œ ë‘ variableì€ ë…ë¦½ì´ ì•„ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì£¼ì–´ì§€ì§€ ì•ŠëŠ”ë‹¤ë©´ ê³µì´ êµ´ëŸ¬ê°ˆ ìˆ˜ ì—†ì–´ì„œ ë…ë¦½ì´ë‹¤.

&nbsp;

ê°„ë‹¨í•œ ì˜ˆì‹œë¥¼ ë“¤ì–´ë³´ì.

<img src="/assets/img/kooc/week78/example_of_bayesball.png">

x1~x6ì˜ variableì´ ì¡´ì¬í•˜ê³ , ìœ„ì™€ ê°™ì€ ê´€ê³„ë¡œ í˜•ì„±ë˜ì–´ ìˆë‹¤ê³  í•´ë³´ì.

1. x2ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, x1ê³¼ x4ì˜ ê´€ê³„ (x1 âŠ¥ x4 \| x2)

x2ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, x1ê³¼ x4ëŠ” x2 ë°©í–¥ìœ¼ë¡œëŠ” cascadingêµ¬ì¡°ì´ë¯€ë¡œ ì§€ë‚˜ê°ˆ ìˆ˜ ì—†ë‹¤. x3ë°©í–¥ìœ¼ë¡œ ì§€ë‚˜ê°„ë‹¤ í•˜ë”ë¼ë„, x1ê³¼ x6ëŠ” v-structureêµ¬ì¡°ì´ë¯€ë¡œ ì§€ë‚˜ê°ˆ ìˆ˜ ì—†ë‹¤.

ë”°ë¼ì„œ x1ê³¼ x4ëŠ” ë…ë¦½ì´ë‹¤.

&nbsp;

2. x1ì´ ì£¼ì–´ì¡Œì„ ë•Œ, x2ì™€ x5ì˜ ê´€ê³„ (x2 âŠ¥ x5 \| x1)

x1ì´ ì£¼ì–´ì¡Œì„ ë•Œ, x2ì™€ x5ëŠ” v-structure êµ¬ì¡°ì´ë¯€ë¡œ, x6ê°€ ì£¼ì–´ì¡Œì„ ë•Œë§Œ ì§€ë‚˜ê°ˆ ìˆ˜ ìˆë‹¤. x1ë°©í–¥ìœ¼ë¡œ ì§€ë‚˜ê°„ë‹¤ í•˜ë”ë¼ë„, common parent êµ¬ì¡°ì´ë¯€ë¡œ x1ì´ ì•Œë ¤ì ¸ ìˆì§€ ì•Šì•„ì•¼ ì§€ë‚˜ê°ˆ ìˆ˜ ìˆë‹¤.

ë”°ë¼ì„œ x1ê°€ ì£¼ì–´ì¡Œì„ ë•ŒëŠ” x2ì™€ x5ëŠ” ë…ë¦½ì´ë‹¤.

&nbsp;

3. x2,x3ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, x1ê³¼ x6ì˜ ê´€ê³„ (x1 âŠ¥ x6 \| {x2,x3})

x2ì™€ x3ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, x1ê³¼ x6ëŠ” x2ë°©í–¥ìœ¼ë¡œëŠ” cascading êµ¬ì¡°ì´ë¯€ë¡œ x2ê°€ ì£¼ì–´ì¡Œì„ ë•ŒëŠ” ì§€ë‚˜ê°ˆ ìˆ˜ ì—†ë‹¤. x3ë°©í–¥ìœ¼ë¡œ ì§€ë‚˜ê°„ë‹¤ í•˜ë”ë¼ë„, cascading êµ¬ì¡°ì´ë¯€ë¡œ x3ê°€ ì£¼ì–´ì¡Œì„ ë•ŒëŠ” ì§€ë‚˜ê°ˆ ìˆ˜ ì—†ë‹¤.

ë”°ë¼ì„œ x2ì™€ x3ê°€ ì£¼ì–´ì¡Œì„ ë•ŒëŠ” x1ì™€ x6ëŠ” ë…ë¦½ì´ë‹¤.


&nbsp;

4. x1,x6ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, x2ì™€ x3ì˜ ê´€ê³„ (x2 âŠ¥ x3 \| {x1,x6})

x1ê³¼ x6ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, x2ì™€ x3ëŠ” x1ë°©í–¥ìœ¼ë¡œëŠ” common parent êµ¬ì¡°ì´ë¯€ë¡œ x1ì´ ì£¼ì–´ì¡Œì„ ë•ŒëŠ” ì§€ë‚˜ê°ˆ ìˆ˜ ì—†ë‹¤. x6ë°©í–¥ìœ¼ë¡œ ì§€ë‚˜ê°„ë‹¤ í•˜ë©´, x2ì™€ x5ê°€ v-structure êµ¬ì¡°ì´ê³ , x6ê°€ ì£¼ì–´ì¡Œìœ¼ë¯€ë¡œ ì§€ë‚˜ê°ˆ ìˆ˜ ìˆê³ , x6,x5,x3ê°€ cascading êµ¬ì¡°ì¸ ìƒí™©ì—ì„œ x5ê°€ ì£¼ì–´ì§€ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ x3ë¡œ ë„ì°©í•  ìˆ˜ ìˆë‹¤. 

ë”°ë¼ì„œ x1ì™€ x6ê°€ ì£¼ì–´ì¡Œì„ ë•ŒëŠ” x2ì™€ x3ëŠ” ë…ë¦½ì´ ì•„ë‹ˆë‹¤.

&nbsp;

&nbsp;

ì´ëŸ¬í•œ bayes ball algorithmì„ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ê¸°ë²•ì„ ì •ì˜í•  ìˆ˜ ìˆë‹¤.

1. Markov Blanket

<img src="/assets/img/kooc/week78/markov_blanket.png">

Aë¼ëŠ” íŠ¹ì • variableì´ bayesian networkì•ˆì— ì¡´ì¬í•œë‹¤ê³  í•  ë•Œ, ì£¼ë³€ íŠ¹ì • ê´€ê³„ì— ìˆëŠ” variableë§Œ ì•Œë©´, ë‚˜ë¨¸ì§€ì˜ variableì— ëŒ€í•´ì„œëŠ” conditional independentí•˜ë‹¤.

íŠ¹ì • ê´€ê³„ì—ëŠ” parents, children, children's other parents ì´ë‹¤.

- parents -\> cascading ê´€ê³„ì— ìˆëŠ” variableê³¼ ê´€ë ¨
- children -\> cascading ê´€ê³„ì— ìˆëŠ” varableê³¼ ê´€ë ¨
- children's other parents -\> v-structure ê´€ê³„ì— ìˆëŠ” variableê³¼ ê´€ë ¨

&nbsp;

&nbsp;

2. D-Seperation(directly-seperated)

- Yê°€ ì£¼ì–´ì¡Œì„ ë•Œ, Zì™€ XëŠ” d-seperated ì´ë‹¤. (X âŠ¥ Z \| Y)

&nbsp;

&nbsp;

![](factorization.png)

bayesian networkê°€ ìˆì„ ë•Œ, ì´ëŸ¬í•œ joint probabilityë¥¼ êµ¬í•  ë•Œ, conditional independent ë¥¼ ê³ ë ¤í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ë‹¨ìˆœí™”í•  ìˆ˜ ìˆë‹¤.

$$ P(X) = \prod_i P(X_i | X_{\pi_i}) $$

$$ P(X1,X2,X3,X4,X5,X6,X7,X8) = P(X1)P(X2)P(X3|X1)P(X4|X2)P(X5|X2)P(X6|X3,X4)P(X7|X6)P(X8|X5,X6) $$

ì´ë ‡ê²Œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆëŠ” ì´ìœ ëŠ” joint probabilityì™€ conditional probabilityì˜ ê´€ê³„ì™€, cascading, common parent ë“±ì˜ êµ¬ì¡°ë¡œ ì¸í•´ ê°€ëŠ¥í•˜ë‹¤.

&nbsp;

![](plate_notation.png)

ì˜¤ë¥¸ìª½ê³¼ ê°™ì´ $ \mu $ ì™€ $ \sigma $ ì˜ ê³µí†µì˜ parentë¥¼ ê°€ì§€ëŠ”, X ë“¤ì´ ìˆë‹¤ê³  í•˜ë©´, ì‚¬ê°í˜•ì˜ ê³µê°„ì„ ë§Œë“¤ì–´ ê°„ë‹¨í•˜ê²Œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. ìˆ˜ì‹ë„ ê°„ë‹¨í•˜ê²Œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤.

$$ P(D|\theta) = P(X_1,...,X_N|\mu, \sigma) = \prod_N P(X_1|\mu, \sigma) $$

&nbsp;

&nbsp;

## 7-3. Inference on Bayesian Networks

### 1. Likelihood

![](inference_question1.png)

ëª¨ë“  variable, X = {X_1,...,X_N} ì´ ìˆì„ ë•Œ, XëŠ” $ X_H$ ì™€ $ X_V $ ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤. $ X_V $ëŠ” evidence variable, ì¦‰ ê´€ì¸¡ëœ variableì´ê³ , $ X_H $ ëŠ” hidden variable, ì¦‰ ê´€ì¸¡í•˜ì§€ ì•Šì€ variableì´ë‹¤.

evidence value, $ x_V $ ì— ëŒ€í•œ í™•ë¥ (Likelihood)ì€ ë‹¤ìŒê³  ê°™ë‹¤.

$$ P(x_V) = \sum_{X_H} P(X_H, X_V) = \sum_{x_1} \dots \sum_{x_k} P(x_1, ..., x_k, x_V) $$

bayesian networkì™€ conditional probability tableì´ ì¡´ì¬í•˜ë©´, Joint Probabilityë¥¼ êµ¬í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì í•©í•˜ë‹¤. ë”°ë¼ì„œ, êµ¬í•˜ê³ ì í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ X_Hì— ëŒ€í•´ marginalizationì„ ìˆ˜í–‰í•˜ì—¬, X_Hì— ëŒ€í•œ ê´€ê³„ë¥¼ ëª¨ë‘ í¬í•¨ì‹œí‚¨ë‹¤.

ë„ë‘‘ê³¼ ì§€ì§„ì— ëŒ€í•œ ì•ŒëŒ taskì—ì„œì˜ P(X_H, X_V) ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

$$ P(X_H, X_V) = P(B)P(E)P(A|B,E)P(M|A)P(J|A) = P(B,E,A,M,J) $$

&nbsp;

### 2. Conditional Probability

![](inference_question2.png)

Bì™€ Mì— ëŒ€í•´ ì£¼ì–´ì¡Œì„ ë•Œ ì•ŒëŒì˜ conditional probabilityë¥¼ êµ¬í•´ë³´ì. hidden variableì„ ë˜ë‹¤ì‹œ 2ê°€ì§€ë¡œ ì„¸ë¶„í™”í•  ìˆ˜ ìˆë‹¤. 

X_H = {Y,Z}
- Y : ê´€ì¸¡ì´ ë˜ì§€ ì•Šì•˜ì§€ë§Œ, ê´€ì‹¬ì€ ìˆëŠ” variable (interested hidden variable)
- Z : ê´€ì¸¡ë„ ë˜ì§€ ì•Šì•˜ê³ , ê´€ì‹¬ë„ ì—†ëŠ” variable (uninterested hidden variable)

Bì™€ Mì€ ê´€ì¸¡ì´ ë˜ì—ˆìœ¼ë¯€ë¡œ X_Vì— í•´ë‹¹í•˜ê³ , Aì— ëŒ€í•´ êµ¬í•˜ê³  ì‹¶ìœ¼ë¯€ë¡œ, YëŠ” A, ë‚˜ë¨¸ì§€ëŠ” Zì— í•´ë‹¹í•œë‹¤.

ê·¸ë˜ì„œ ê´€ì¸¡ëœ variableë“¤ì— ëŒ€í•œ interested hidden variableì— ëŒ€í•œ ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$ P(Y|x_V) = \sum_z P(Y, Z=z | x_V) = \sum_z \cfrac{P(Y, Z, x_V)}{P(x_V)} = \sum_z \cfrac{P(Y, Z, x_V)}{\sum_{y,z} P(Y=y, Z=z, x_V)} $$

full jointë¡œ ë§Œë“¤ê¸° ìœ„í•´ Zë¥¼ ì‚½ì…í•˜ê³ , P(x_V)ì— ëŒ€í•´ì„œëŠ” ì•ì„œ ì •ì˜í–ˆìœ¼ë¯€ë¡œ, x_V ê°€ ì£¼ì–´ì¡Œì„ ë•Œì˜ Yì˜ conditional probabilityëŠ” ìœ„ì™€ ê°™ë‹¤.

&nbsp;

### 3. Most Probable Assignment

![](inference_question3.png)

ë§ˆì§€ë§‰ìœ¼ë¡œ, P(Y|x_V)ê°€ ìµœëŒ€ê°€ ë  íŒŒë¼ë¯¸í„°ë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤. ( $argmax_a P(A\|B=true, M=true)$)

ë§Œì•½ P(A\|B,E) ì— ëŒ€í•œ posteriorië¥¼ êµ¬í•˜ë©´, prediction taskì— í•´ë‹¹í•˜ê³ , ë°˜ëŒ€ë¡œ P(B,E\|A)ì— ëŒ€í•œ posteriorië¥¼ êµ¬í•˜ë©´ diagnosis taskê°€ ëœë‹¤.

&nbsp;

&nbsp;

joint probabilityë¥¼ êµ¬í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•œë°, ì´ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ì„œëŠ” ë„ˆë¬´ ë§ì€ ê³±ì…ˆê³¼ ë§ì…ˆì´ ì¡´ì¬í•œë‹¤.

$$ P(a = true, b=true, mc=true) = \sum_{JC}\sum_{E} P(a,b,E,JC,mc) = \sum_{JC} \sum_{E} P(JC|a)P(mc|a)P(a|b,E)P(E)P(b) $$

&nbsp;

![](variable_elimination.png)

ì¡°ê¸ˆ ë” ê°„ë‹¨í•˜ê²Œ êµ¬í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì€ ì—†ì„ê¹Œ? ì´ëŸ¬í•œ í™•ë¥ (P)ë¥¼ í•¨ìˆ˜ì˜ í˜•íƒœë¡œ ìƒê°í•´ë³´ì. ì†Œë¬¸ìê°€ evidence variable, ëŒ€ë¬¸ìê°€ hidden variableì— ëŒ€í•œ ê°’ì´ë‹¤.

$$ P(e,jc,mc,B,A) = P(e)\sum_B P(b)\sum_A P(a|b,e)P(jc|a)P(mc|a) => f_E(e)\sum_B f_B(b) \sum_A f_A(a,b,e) f_J(a) f_M(a) $$

MCì— ëŒ€í•œ í•¨ìˆ˜ $ f_m $ ì™€ JCì— ëŒ€í•œ í•¨ìˆ˜ $ f_j $ ë¥¼ ê³±í•´ì„œ $ f_{JM} $ ì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤. 

&nbsp;

![](variable_elimination2.png)

ê·¸ë¦¬ê³ , $ f_A $ ì™€ $ f_JM $ ì„ ê²°í•©í•˜ê³ , Aì— ëŒ€í•´ marginalizationì„ ìˆ˜í–‰í•˜ê²Œ ë˜ë©´, $ f_{\bar{A}JM}(b,e) $ ê°€ ëœë‹¤. ì´ë ‡ê²Œ ê³„ì† ë‹¨ìˆœí™”ì‹œí‚¤ë©´, $ f_E\bar{B}\bar{A}JM(e) $ ë¥¼ ë§Œë“¤ì–´ ë‚¼ ìˆ˜ ìˆë‹¤.

&nbsp;

&nbsp;

![](potential_function.png)

ì´ë²ˆì—ëŠ” ê°„ë‹¨í•œ bayesian networkì¸ `A <- B <- C <- D ` ë¥¼ ì •ì˜í•˜ê³ , ì´ì— ëŒ€í•œ full jointë¥¼ êµ¬í•˜ë©´, 

$ P(A,B,C,D) = P(A\|B)P(B\|C)P(C\|D)P(D) $

ê°€ ëœë‹¤. ì´ ë•Œ, A,B,C,Dì— ëŒ€í•œ networkë¥¼ ë‹¤ë¥´ê²Œ í‘œí˜„í•˜ê³ ì í•œë‹¤. **clique**ì™€ **separator** ê°œë…ì„ ì‚¬ìš©í•˜ì—¬, ë…¸ë“œ(clique)ë¥¼ A,B/B,C/C,D ë¡œ êµ¬ì„±í•˜ê³ , ê·¸ ì‚¬ì´ì— ë§í¬(separator)ë¥¼ B,C ë¡œ ì •ì˜í•œë‹¤. 

ê·¸ë¦¬ê³ ë‚˜ì„œ, *potential function* ì„ ì •ì˜í•œë‹¤.

- potential function on nodes

$$ \psi(a,b), \psi(b,c), \psi(c,d) $$

- potential function on links

$$ \phi(b), \phi(c) $$

&nbsp;

ê·¸ í›„, potential functionì„ í™œìš©í•˜ì—¬ P(A,B,C,D)ë¥¼ ì •ì˜í•œë‹¤. ì •ì˜í•˜ëŠ” ë°©ë²•ì—ëŠ” 2ê°€ì§€ê°€ ìˆë‹¤.

1. $ P(A,B,C,D) = \cfrac{\prod_N \psi(N)}{\prod_L \phi(L)} = \cfrac{\psi(a,b)\psi(b,c)\psi(c,d)}{\phi(b)\phi(c)} $

- Ïˆ(a,b) = P(A\|B), Ïˆ(b,c) = P(B\|C), Ïˆ(c,d) = P(C\|D)P(D)
- Ï†(b) = 1, Ï†(c) = 1

&nbsp;

2. $ P(A,B,C,D) = \cfrac{\prod_N \psi(N)}{\prod_L \phi(L)} = \cfrac{\psi(a,b)\psi(b,c)\psi(c,d)}{\phi(b)\phi(c)} $

- Ïˆ(a,b) = P(A,B), Ïˆ(b,c) = P(B,C), Ïˆ(c,d) = P(C,D)
- Ï†(b) = P(B), Ï†(c) = P(C)

&nbsp;

&nbsp;

![](absorption_in_clique_graph.png)

ìœ„ì˜ potential functionì„ clique graphë¥¼ ì ìš©í•˜ê²Œ ë˜ë©´

- P(B) = $ \sum_A \psi(A,B) $
  - Aì— ëŒ€í•´ marginalizationì„ ìˆ˜í–‰í•˜ë©´ P(B)ê°€ ëœë‹¤.
- P(B) = $ \sum_C \psi(B,C) $
- P(B) = Ï†(B)

ì´ ë•Œ, ë§Œì•½ Aê°€ ê´€ì°°ëœë‹¤ë©´, $ \phi(B) $ ê°’ë„ ë°”ë€” ê²ƒì´ê³ , ê·¸ë ‡ë‹¤ë©´, ê·¸ ë’¤ì— ìˆëŠ” B,C/C/C,D ì— ëŒ€í•œ ê²ƒë“¤ë„ ëª¨ë‘ ë°”ë€Œê²Œ ëœë‹¤. ì´ë¥¼ **belief propagation**ì´ë¼ í•œë‹¤.

&nbsp;

beliefë¥¼ ì „íŒŒ(propagation)í•˜ê¸° ìœ„í•´ì„œëŠ” *Absorption(update) rule* ì„ ì ìš©í•´ì•¼ í•œë‹¤. updateëœ separatorì™€ updateëœ cliqueë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•œë‹¤.

- Ï†^*(B) = $ \sum_A \psi^*(A,B) $
- Ïˆ^*(B,C) = $ \psi(B,C)\frac{\phi^*(B)}{\phi(B)} $

&nbsp;

ì´ë ‡ê²Œ ì •ì˜ê°€ ë˜ë©´, ë‹¤ìŒê³¼ ê°™ì´ ì ìš©ëœë‹¤.

![](local_consistency.png)

ì´ë¥¼ *local consistency*, ì§€ì—­ì  ì¼ê´€ì„±ì´ë¼ í•œë‹¤.

&nbsp;

&nbsp;

ì´ì œ ì‹¤ì œ ì˜ˆì œì— ì ìš©í•  ê²ƒì¸ë°, ìš°ë¦¬ëŠ” conditional probabilityëŠ” ì•Œê³  ìˆì§€ë§Œ, joint probabilityëŠ” ëª¨ë¥´ëŠ” ìƒíƒœì´ë¯€ë¡œ, ì¼ì „ì— ì •ì˜í–ˆì—ˆë˜ P(A,B,C,D)ì—ì„œ conditional probabilityë¥¼ í™œìš©í•œ ë°©ì‹ì„ ì‚¬ìš©í•  ê²ƒì´ë‹¤.

&nbsp;

![](example_belief_propagation.png)

1. P(b) ë¥¼ êµ¬í•´ë³´ì.

- $ \phi^*(b) = \sum_a \psi(a,b) = 1 $
  - absorption ruleì„ ìˆ˜í–‰í•  ë•Œ, Ï†*(b)ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ì„œ aì— ëŒ€í•´ marginalizationì„ í•˜ë©´ ëœë‹¤. 
  - ì´ë ‡ê²Œ ë˜ë©´, ëª¨ë“  caseì— ëŒ€í•œ í™•ë¥ ì´ ë˜ë¯€ë¡œ 1ì´ ëœë‹¤.
- $ \psi^*(b,c) = \psi(b,c)\frac{\phi^*(b)}{\phi(b)} = P(b\|c)P(c) \times 1 = P(b,c) $
  - ì•ì„œ Ïˆ*ì— ëŒ€í•´ ì •ì˜í–ˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì •ì˜í•˜ê³ , ìœ„ì—ì„œ b separatorì— ëŒ€í•œ ê°’ì€ ë‘˜ë‹¤ 1.
  - conditional probabilityì˜ ì •ì˜ì— ë”°ë¼ joint probabilityë¡œ ì •ì˜ëœë‹¤.
- $ \phi^{**}(b) = \sum_c \psi(b,c) = \sum_c P(b,c) = P(b) $
  - ì´ë²ˆì—ëŠ” B,C ì—ì„œ A,Bë¡œ ì§„í–‰í•´ë³¸ë‹¤.
  - ë™ì¼í•˜ê²Œ cì— ëŒ€í•´ marginalizationì„ ìˆ˜í–‰í•˜ì—¬ apsorption ruleì´ ì ìš©ëœ bë¥¼ ê³„ì‚°í•œë‹¤.
- $ \psi^*(a,b) = \psi(a,b)\frac{\phi^{**}(b)}{\phi^*(b)} = \frac{P(a\|b)P(b)}{1} = P(a,b) $
  - Ïˆ*ì— ëŒ€í•´ ì•ì„œ ì •ì˜í–ˆìœ¼ë¯€ë¡œ, ê·¸ëŒ€ë¡œ ì •ì˜í•˜ì—¬ ì‚¬ìš©í•œë‹¤.
- $ \phi^{***}(b) = \sum_a \psi^*(a,b) = P(b) $
  - A,Bì—ì„œ B,Cë¡œ í•œë²ˆ ë” ì§„í–‰í•´ë³´ë©´ ë™ì¼í•œ ê°’ì´ ë‚˜ì˜¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

&nbsp;

2. P(b\|a=1,c=1) ë¥¼ êµ¬í•´ë³´ì.

ê´€ì¸¡ì´ ìˆëŠ” ìƒíƒœì—ì„œ ì•Œì§€ ëª»í•˜ëŠ” variableì— ëŒ€í•œ í™•ë¥ ì„ êµ¬í•˜ê³ , ì¶”ê°€ë¡œ í™•ë¥ ì´ ìµœëŒ€ê°€ ë˜ëŠ” ê°’ì„ ì°¾ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.

- $ \phi^*(b) = \sum_a \psi(a,b) \delta(a=1) = P(a = 1\|b) $
  - ë™ì¼í•˜ê²Œ aì— ëŒ€í•´ marginalizationì„ ìˆ˜í–‰í•˜ì§€ë§Œ, a=1ì´ë¼ëŠ” ê´€ì¸¡ì´ ì´ë¯¸ ìˆì—ˆìœ¼ë¯€ë¡œ a=1ì¼ ë•Œì˜ ê°’ë§Œ ì‚¬ìš©í•œë‹¤.
  - ì´ë¡œ ì¸í•´, ëª¨ë“  caseë¼ì„œ ë‚˜ì˜¨ 1ì´ ì•„ë‹Œ, a=1ì¼ë•Œì˜ í™•ë¥ 
- $ \psi^*(b,c) = \psi(b,c)\frac{\phi^*(b)}{\phi(b)} = P(b\|c=1)P(c=1)\frac{P(a=1\|b)}{1} $
  - ì•ì„œ absorption ruleì—ì„œ ì •ì˜í•œ ê²ƒì„ ì‚¬ìš©í•˜ë˜, c=1ì´ë¼ëŠ” ê´€ì¸¡ì´ ìˆì—ˆìœ¼ë¯€ë¡œ ì´ë¡œ ì œí•œí•˜ì—¬ ì‚¬ìš©í•œë‹¤.
- $ \phi^{\*\*}(b) = \sum_c \psi(b,c) \delta(c=1) = Ïˆ^*(b,c) = P(b\|c=1)P(c=1)P(a=1\|b) $
  - B,Cì—ì„œ A,Bë¡œ ì§„í–‰í•˜ë¯€ë¡œ Ï†**ëŠ” cë¥¼ marginalizationì„ ìˆ˜í–‰í•œ ê²ƒê³¼ ë‹¨ë‹¤. ë”°ë¼ì„œ ìœ„ì— ê²ƒì´ ê·¸ëŒ€ë¡œ ë‚´ë ¤ì˜¨ë‹¤.
- $ \psi^*(a,b) = \psi(a,b)\frac{\phi^{\*\*}(b)}{\phi^*(b)} = P(a=1\|b) \frac{P(b\|c=1)P(c=1)P(a=1\|b)}{P(a=1\|b)} = P(b\|c=1)P(c=1)P(a=1\|b) $
  - absorption ruleì—ì„œ ì •ì˜í•œ ê²ƒì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•œë‹¤.
- $ \phi^{\*\*\*}(b) = \sum_a \psi^*(a,b) \delta(a=1) = P(b\|c=1)P(c=1)P(a=1\|b) $
  - A,Bì—ì„œ ë‹¤ì‹œ B,Cë¡œ ì´ë™ì„ ì‹œì¼œë³´ë©´ ë™ì¼í•œ ê°’ì´ ë‚˜ì˜¨ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

ì´ë ‡ê²Œ êµ¬í•´ì§„ seperatorë¡œ P(b\|a=1,c=1) ë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤.

&nbsp;

&nbsp;

