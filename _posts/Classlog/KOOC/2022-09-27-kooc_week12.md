---
title:    "[KOOC] 1,2주차 - MLE, MAP, Decision Tree, Entropy"
author:
  name: JaeHo YooN
  link: https://github.com/dkssud8150
date: 2022-09-27 00:40:00 +0800
categories: [Classlog, kooc]
tags: [kooc]
toc: true
comments: true
math: true
---

# Chapter 1. Motivation and Basics

- 목차

1. Motivation
  - Machine Learning, AI, Datamining
2. What is Machine Learning?
  - MLE
  - MAP
3. Basics
  - Probability
  - Distribution
  - And some Rules

&nbsp;

&nbsp;

## Motivation

<img src="/assets/img/kooc/week1/example_ml.png">

&nbsp;

&nbsp;

<img src="/assets/img/kooc/week1/type_ML.png">

Machine Learning에는 학습 방법에 따라 supervised learning, unsupervised learning, reinforcement learning 이 있다. 먼저 supervised learning에는 요약하거나 예측과 같은 것들이 이에 해당하고, 요약하고 정리하고 군집을 찾는 것이 unsupervised learning에 해당한다. 마지막으로 어떤 것이 지능적이고, 원하는 계획인가에 대한 학습이 reinforcement learning이다.

더 자세하게 살펴보자.

&nbsp;

- supervised learning

<img src="/assets/img/kooc/week1/supervised_learning.png">

사람이나, 기계가 지정한 가이드가 있는 것이 supervised라 할 수 있다. 예를 들어, 스팸 필터링은 매우 많은 데이터들에 의해 어떤 것을 필터링할지 판단한다. 또한, 자동 카테고리화도 수많은 데이터의 축적에 의해 분류하는 모델을 생성하는 것이다.

또는, 특정 값에 대해 가격을 예측하는 것과 같은 것들은 regression, 또는 prediction 도 supervised learning task에 해당한다.

&nbsp;

- unsupervised learning

<img src="/assets/img/kooc/week1/unsupervised_learning.png">

그에 반해, 순수히 주어진 데이터에 의해 기계가 군집을 찾고, 패턴을 찾도록 하는 것이 unsupervised learning이다. 또는 잠재적인 현상을 분석할 때도 활용한다. 예를 들어 신문기사가 엄청 많을 때, 주제를 10개로 추려보는 것은 직접 가이드를 제작해주기 힘들어서, 기계가 직접 군집을 찾아야 하므로 unsupervised learning에 해당한다.

&nbsp;

## What consists of Machine Learning?

<img src="/assets/img/kooc/week1/thumbpack.png">

Thumbtack, 압정을 활용하여 게임을 해보자. 동전과 달리, 압정은 앞과 뒤가 50:50이라 하기 어렵다. 그래서 앞 또는 뒤가 나올 확률을 직접 구해보고자 한다. 가장 먼저 해야 할 방법은 직접 던져보는 것이다.

&nbsp;

<img src="/assets/img/kooc/week1/experience_trial.png">

뾰족한 부분이 아래일 때를 `Head`, 뾰족한 부분이 위일 때를 `Tail` 이라 하고, 5번을 던져봤을 때 Head가 2번 Tail이 3번 나온다면, 확률은 각각 2/5, 3/5 인 것은 당연한 결과다. 그러나 이 2/5, 3/5라는 값은 사실 그리 간단하게 구해지는 것이 아니다.

&nbsp;

<img src="/assets/img/kooc/week1/binomial_distribution.png">

이 2/5, 3/5로 구하는 것은 Binomial distribution이라 하는데, 이는 뚜렷한, 이산적인 사건에 대한 확률 분포를 말한다. 즉, Head가 나오든, Tail이 나오든 2가지의 경우만 존재하므로 Binomial distribution이라 한다.

먼저 head가 나올 경우, 다음에 Tail이 나올 때 앞서 나온 값이 영향을 주지는 않으므로 독립적인 상황이다. 만약 Head가 나올 경우를 `P(H) = Theta`, Tail이 나올 경우를 `P(T) = 1 - Theta` 라 하자. 이럴 때, 방금 전 상황인 HHTHT에 대한 확률은 $ P(HTTHT) = \theta (1-\theta) (1-\theta) \theta (1-\theta) = \theta^2 (1-\theta)^3 $ 이다. 전체 Data를 D, Head가 나온 횟수를 a_H, 반대의 경우를 a_T라 한다면 theta, 즉 head가 나올 확률은 다음과 같다. 

$$ P(D | \theta) = \theta^{a_H}(1-\theta)^{a_T}$$

이러한 추정값이 최적의 $ \theta $ 라는 것을 증명해야 하는데, 이를 증명하는 것이 **확률**이라 할 수 있다. 이를 증명할 때 사용하는 대표적인 방법에는 MLE, MAP이 있다.

&nbsp;

### MLE(Maximum Likelihood Estimation)

관측된 데이터의 확률이 최대가 되는 값 theta를 찾는 방법이 MLE이다. MLE를 수식적으로 나타내면 다음과 같다.

$$ \hat{\theta} = argmax_{\theta} P(D|\theta) $$

즉, P(D|\theta)가 최대가 되는 theta를 theta hat이라 표현한다는 것이다. 여기에 위에서 구한 식을 대입하면

$$ \hat{\theta} = argmax_{\theta} P(D|\theta) = argmax_{\theta} \theta^{a_H}(1-\theta)^{a_T}$$

&nbsp;

이를 구할 때, 쉽게 구하는 방법은 log를 씌우는 것이다. log를 씌운 값이 최대가 되면, 그 log 안의 값도 최대가 된다는 특성이 있다.

$$ \hat{\theta} = argmax_{\theta} ln\theta^{a_H}(1-\theta)^{a_T} = argmax_{\theta} (a_H ln\theta + a_T ln(1-\theta)) $$

&nbsp;

그 후, 미분을 통해 최솟값을 찾는다. 그러면 `theta_hat = a_H / (a_T + a_H)` 가 된다.

&nbsp;

&nbsp;

그런데, 만약 5번이 아닌 50번을 수행해서 동일하게 head가 나올 확률이 0.6이 나온다면, 효율상 5번이 더 좋다고 생각할 수 있다. 여기에는 조금의 오류가 존재한다. 우리가 이때까지 구한 것은 정답(Ground Truth)이 아니라 추론(estimation)값이므로, 오류가 항상 존재한다. 정답인 $ \theta* $ 와 $ \hat{\theta} $ 사이의 오차값과 error boundary($ \epsilon $) 에 대한 수식이 있다.

$$ P(|\hat{\theta} - \theta*| \geq \epsilon) \leq 2e^{-2N\epsilon^2} $$

정답과 추론의 차이가 특정 에러보다 클 확률은 우항보다 작다는 것이다. N은 trial, 즉 반복횟수인데, N이 커질수록 우항은 작아지므로 오차가 특정 error boundary보다 클 확률도 작아지게 될 것이다. 

이러한 방식이 PAC(Probably Approximate Correct)이라 하는데, 즉 아마도 특정 확률과 오차범위 안에서 존재하는 theta를 추정하는 기법이다.

&nbsp;

&nbsp;

### MAP

MLE에서 구한 확률은 사전정보가 포함되어 있지 않다. 그러나 만약 사전정보를 가미하여 확률을 구하고자 한다면 다른 방식을 통해 구해야 할 것이다. Bayes라는 학자는 다음과 같이 확률에 대한 식을 정의했다.

$$ P(\theta | D) = \cfrac{P(D | \theta)P(\theta)}{P(D)} \: == \: Posterior = \cfrac{Likelihood \: x \: Prior \: Knowledge}{Normalizing\:Constant} $$

`theta가 주어졌을 때 data를 관측할 확률 x theta에 대한 사전정보 / 데이터를 관측할 확률` 를 하면 데이터가 주어졌을 때 theta의 확률을 구할 수 있다. 이 떄 우리는 theta에 대해 구하고 있으므로, P(D)는 상수가 된다. 그리고 P(D|theta)는 이전에 구했으므로 P(theta)만 지정해둔다면 p(theta|D)를 구할 수 있다.

&nbsp;

또한, Bayes는 P(theta)를 binomial distribution이 아닌 Beta Distribution을 통해 구하고자 했다.

$$ P(\theta) = \cfrac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)},\: B(\alpha,\beta) = \cfrac{r(\alpha)r(\beta)}{r(\alpha+\beta)},\:r(\alpha) = (\alpha - 1)! $$

이 때, B(alpha, beta)는 theta와 관련이 없으므로 상수 취급할 수 있다. 그렇다면, P(theta|D)는

$$ P(\theta|D) \propto P(D|\theta)P(\theta) \propto \theta^{a_H}(1-\theta)^{a_T} \theta^{\alpha-1}(1-\theta)^{\beta-1} = \theta^{a_H+\alpha-1} (1-\theta)^{a_T+\beta-1}$$

이 식은 P(D|theta) 와 유사한 것으로 보아, theta_hat은 쉽게 추정할 수 있다.

$$ \hat{\theta} = \cfrac{a_H+\alpha-1}{a_H+\alpha+a_T+\beta-2} $$

&nbsp;

이 때, MLE와 MAP의 값이 다를 수 있다. 그러나 만약 반복 횟수를 증가시킨다면, alpha와 beta에 비해 a_H와 a_T는 증가하여 비중이 커질 것이므로 같아질 수 있다.

&nbsp;

&nbsp;

## Basics

### Normal Distribution

<img src="/assets/img/kooc/normal_distribution.png">

가장 많이 사용되는 기본적인 확률분포의 형태이다. 이 평균(mean) 또는 분산(variance)를 통해 함수의 모양을 바꿀 수 있을 것이다. Normal distribution에는 양쪽에 롱테일, 즉 무한대로 가는 긴 꼬리가 존재한다.

&nbsp;

### Beta Distribution

<img src="/assets/img/kooc/beta_distribution.png">

beta에서는 롱테일이 존재하지 않는다. 따라서 확률을 모델링할 때 0과 1이라는 확실한 범위가 존재하므로 beta distribution을 사용할 수 있다.

&nbsp;

### Binomial Distribution

<img src="/assets/img/kooc/binomial_distribution_2.png">

이 binomial distribution은 앞서 배운 함수 형태를 가지고 있고, 이산적인(discrete) 함수 형태를 가지고 있다.

&nbsp;

### Multinomial Distribution

binomial distribution은 2가지의 경우만 판단하지만, 만약 2가지 이상의 선택지가 존재한다면 더 다양한 예제를 판단할 수 있어야 한다. 대화를 할 때, 수많은 단어 중 하나를 선택하므로 수많은 데이터를 가진 이산적인 함수를 사용한다.

<img src="/assets/img/kooc/multinomial_distribution.png">