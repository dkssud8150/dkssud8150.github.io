---
title:    H-모빌리티 클래스 (H-Mobility Class) 2주차. 자율주행 자동차 인지 기술 기초
author:
name: JaeHo-YooN
link: https://github.com/dkssud8150
date: 2023-07-27 23:49:00 +0800
categories: [Classlog, h-mob]
tags: [h-모빌리티, autonomous]
toc: True
comments: True
math: true
mermaid: true
---

&nbsp;

# 자율주행 자동차 인지 기술 기초

2주차 자율주행 자동차 인지 기술에 대해 배워본다.

&nbsp;

## 1. 자율주행 자동차의 센서 구성

목차

1. 자율주행차 센서의 종류
2. 자율주행차 센서의 장단점

&nbsp;

### 1-1. 자율주행차 센서의 종류 및 장단점

- 센서 종류
  - 카메라(CAMERA)
  - 라이다(LIDAR)
  - 레이더(RADAR)
  - 초음파

각 장치에는 제한된 FOV(Field of View) 가 존재하므로 360도 및 전방 200m의 주변 정보를 얻기 위해서는 여러 개의 센서를 사용해야 한다.

&nbsp;

1. 카메라
   - 빛을 렌즈를 통해 모은 후 CCD/CMOS와 같은 전기장치를 통해 전기적 신호로 변환
   - 장점
     - 해상도가 높다.
     - 주변 환경에 대한 색상, 형태 정보 수집 가능
     - 상대적 저렴한 가격
   - 단점
     - 날씨, 밝기 변화에 민감
     - 정확한 거리, 속도 정보를 제공받지 못함
     - 높은 해상도로 인한 계산량 증가

2. 레이더(RADAR)
   - 전자기파를 송출한 후 목표물에 반사되는 수신파를 분석
   - 장점
     - 환경 변화에 강인함
     - 거리 측정 정확도 높음
     - 물체와의 거리와 각도, 물체의 이동속도 측정 가능
     - 상대적 저렴한 가격
   - 단점
     - 횡방향 물체 위치 측정 정보가 정확하지 않음
     - 장애물에 의해 방해되는 신호를 클러터라고 하는데, 레이더는 클러터 현상으로 인해 높은 오탐률을 가짐.

3. 라이다(LIDAR)
   - 고출력 펄스 레이저를 송출 -\> 반사되는 신호의 시간차를 분석하고 이를 통해 3차원 공간(point cloud)을 스캔
   - 기계적 회전 스캐닝 방식이 전통적이었으나 내구성 문제로 인해 솔리드 스테이트 방식이나 Mems 등 새로운 구조의 라이다 개발 중
   - 장점
     - 거리, 각도 측정 정확도가 높음
     - 날씨, 습도, 밝기 등의 환경 변화에 강인함
   - 단점
     - 상대적 비싼 가격
     - 습기있을 경우 수신 신호 세기 약해짐

<!-- &nbsp;

### Summary

1. 자율주행차 센서의 종류
   - 주변에 대한 정보를 얻는 것으로 사람의 감각기관에 해당
   - 카메라, 레이더, 라이다, 초음파 센서 등이 있음
2. 자율주행차 센서의 장단점
   - 카메라
     - 빛을 전기적 신호로 변환하여 주변 정보를 2차원 배열로 획득
     - 운전자보조시스템(ADAS)에 가장 많이 사용
   - 레이더
     - 전자기파인 RF신호를 송출하고, 목표물에 반사되는 수신파를 분서가형 물체와의 거리, 각도, 속도등의 정보 획득
   - 라이다
     - 고출력의 펄스레이저를 송출하여 물체에 반사되어 돌아오는 신호의 시간차를 분석하여 3차원 공간을 스캐닝하여 point cloud 데이터 생성 -->

&nbsp;

&nbsp;

## 2. 자율주행 인지 기술

목차

1. 자율주행차 인지 기술 개요
2. 인지 기술의 발전 방향
3. 인지를 위한 AI(딥러닝) 기술
4. 딥러닝 기반 인지시스템 사례

&nbsp;

### 2-1. 자율주행 인지 기술 개요

- 자율주행에서의 주변 환경 요소는 동적 환경 객체, 정적 환경 객체로 나눌 수 있다.
  - 동적 환경 객체
    - 시간에 따라서 그 위치와 상태가 계속 변화할 수 있는 객체
    - 타 차량, 보행자, 사이클리스트, 바이크
  - 정적 환경 객체
    - 위치가 잘 변하지 않는 객체
    - 차로, 건널목, 횡단보도, 신호등, 교통표지판, 과속방지턱, 중앙분리대
    - 이러한 정적 객체를 통해 제한 속도 파악, 신호등 상태, 횡단보도 유무 등을 파악 -\> 도로 및 교통 상황에 맞게 주행
    - 측위 시 나의 위치를 파악하는데 중요한 정보를 제공

&nbsp;

- 인지 기술
  - 센서로부터 얻은 신호를 분석하여 차량 주변의 환경에 대한 정보를 분석하는 기술
  - 인지 기술을 통해 동적 객체의 위치와 종류, 움직임 파악 및 객체 추적
    - 객체 추적은 매 시점마다 얻은 검출 결과를 시간적으로 연결하여 추적하는 기술
    - 시점마다의 프레임(이미지)에서 검출된 같은 객체에 동일한 물체 ID를 부여하여 객체의 주변 환경에의 등장, 이동, 퇴장을 파악
    - 파악된 움직임을 토대로 미래에 어떤 행동을 보일지에 대한 예측
      - ex. 주변 타 차량이 차선을 유지해서 갈지 아니면 차선을 변경할지
      - ex. 보행자가 횡단보도를 건널지 말지, 건너편 차량이 비보호 좌회전을 하는지 아닌지
  - 정적 환경 객체의 위치와 종류 파악
    - 도로 구조 및 환경 이해에 도움
    - 교통 정보를 파악함으로서 교통상황에 맞는 주행을 가능하게 함.
      - ex. 제한 속도에 맞게 주행
      - ex. 신호에 맞게 정지 또는 주행
      - ex. 횡단보도에서 일단 정지
    - 정적 객체 파악을 통해 지도 기반 측위 부분에 정보 제공

&nbsp;

&nbsp;

### 2-2. 인지 기술의 발전 방향

- 자율주행차 인지 기술의 어려움
  1. 높은 정확도
     - 인지 기술에 오류가 생기게 된다면 전체 자율주행 기능이 무력화되고, 이것이 사고 발생으로 이어지게 되므로 높은 정확도 요구
     - 무엇보다 근거리 환경 인지에 대해서는 100%에 가까운 정확도를 요구
  2. 예측하기 힘든 다양한 주행 환경과 상황
     - 공사, 타 차량 사고 등과 같은 예측하기 힘든 다양한 주행 환경과 상황
     - 악천후, 조도 변화, 낮과 밤 등에 대한 환경 변화 존재
  3. 문맥적 의미 파악
     - 자동차와 간격 유지, 타 차량 및 보행자의 행동 예측 등과 같은 다양한 문맥적 의미를 파악해야 하는 어려움
     - 자전거, 킥보드, 오토바이 등 새로운 객체들 계속 등장
  4. 고성능의 하드웨어
     - 여러 인지 기능을 동시에 수행할 수 있는 고성능의 하드웨어가 필요
     - 하드웨어 성능이 떨어지게 되면 빠른 판단이 불가능해지게 되므로 위험 발생

&nbsp;

- 인지 기술의 도전적 과제
  1. 다양한 환경 변화 및 주행 환경에서 강인함과 신뢰성 필요
  2. 문맥적 의미 파악 및 활용을 통한 인지기능 정확도 향상
  3. 다양한 동적 객체 행동 패턴 파악
  4. 새롭게 변화하는 환경 적응
  5. 통합적인 인지 기술 처리를 위한 시스템 최적화 및 알고리즘 개발

&nbsp;

## 2-3. 인지를 위한 AI(딥러닝) 기술

- AI 기술
  - 인공지능에는 머신러닝과 딥러닝이 있는데, 큰 범위부터 인공지능(AI), 머신러닝(ML), 딥러닝(DL) 순이다.
  - AI를 사용하기 위한 5단계 과정
    - 데이터 취득 -\> 데이터 라벨링 -\> 딥러닝 모델 학습 -\> 차량 탑재 -\> 인지 기능 수행

&nbsp;

- 딥러닝 기술(Deep Neural Network)
  - 딥러닝이란 사람의 뉴런을 모사하는 신경망 구조를 본따 만든 것으로 요구하는 기능에 따라 다양한 역할 가능
  - 딥러닝은 2012년 ImageNet Chanllange 에서 우승한 **AlexNet** 이라는 모델이 발견된 이후 급격하게 발전해오고 있음.
  - 딥러닝 기술 대표적 기능
    - 카메라 영상 입력 -\> 딥러닝 모델 -\> 동적 객체 검출
    - 라이다 데이터 -\> 딥러닝 모델 -\> 동적 객체 검출
  - 딥러닝 모델 구조
    - 입력은 1층부터 마지막층까지 순차적으로 통과하여 원하는 결과를 출력
    - 딥러닝 모델은 Feed-forward 라는 수많은 노드들의 집합으로 이루어져 있다.
      - 노드란 입력 데이터와 비선형 연산을 수행하여 결과를 출력하는 최소 단위
  - 딥러닝 모델 학습 과정
    - 수많은 데이터를 모델에 입력하여 출력 결과를 정답에 맞춰가는 과정을 학습이라 함
  - 딥러닝 모델 추론 과정
    - 학습한 모델을 실제 사용할 플랫폼에 탑재하여 원본 데이터를 입력하여 예측하는 과정을 추론이라 함.
  - 딥러닝 모델 예시
    - CNN (Convolutional Neural Network)
      - 카메라 영상을 입력으로 하여 원하는 결과를 얻어내는 데 특화된 구조
      - 동적 객체(타 차량 보행자, 사이클리스트), 정적 객체(신호등) 등을 인식하는데 사용
    - RNN (Recurrent Neural Network)
      - 시간적, 순차적으로 들어오는 데이터를 입력으로 하여 원하는 출력을 얻어내는 구조
      - 음성 인식, 자연어 처리, 시계열 데이터 처리 등에 사용
      - 자율주행에서는 주변 동적 객체의 과거 경로로부터 미래 경로를 예측하는 데 사용
      - LSTM (Long Short Term Memory) 가 가장 유명

&nbsp;

## 2-4. 딥러닝 기반 인지시스템 사례

딥러닝 기반 인지시스템 사례에는 대표적으로 테슬라, 구글 웨이모가 있다.

- 테슬라 - FSD(Full Self Driving)
  - 테슬라 차량에는 라이다 없이 카메라 8대, 전방 레이더 1대, 초음파 센서 12대 장착
  - 무선 통신 (OTA)를 통해 각 차량의 소프트웨어 업그레이드
  - 딥러닝 적용을 위한 컴퓨팅 하드웨어를 직접 설계
  - 차량, 보행자, 신호등, 정지선 인식

- 구글 웨이모
  - 구글은 2018년 미국 아리조나 피닉스에 무인택시 `웨이모 One` 서비스 출범
  - 자율주행차 회사 중 가장 많은 자율주행 테스트 및 시뮬레이션 시간을 가지고 있다.
  - 테슬라와는 달리 라이다를 주로 사용하고 카메라와 레이더는 보조 수단으로 사용
  - 라이다를 직접 설계하여 사용
  - 라이다와 레이더의 광범위한 측정 범위를 통해 최대 500m 거리까지 물체 검출

&nbsp;

- 자율주행 사고 사례
  - 2016년 5월에 `테슬라` 모델 S 차량이 흰색 트레일러를 오인식하여 충돌해서 운전자가 사망하는 사건
  - 2018년 3월 `우버` 차량이 자전거를 인식하지 못해 충돌하게 되면서 사고 여성이 사망하는 사건

<!-- &nbsp;

### Summary

1. 자율주행차 인지 기술 개요
   - 인지 기술이란 센서로부터 얻은 데이터를 분석하여 차량 주변 환경 정보 취득
   - 인지를 통해 동적/정적 환경 객체 탐지
   - 동적 객체 검출 및 추적, 예측 : 동적 객체 위치 및 종류 판별, 매 시점마다 얻은 검출 결과를 토대로 객체 움직임 추적, 추적된 움직임을 바탕으로 움직임 예측
   - 정적 객체 검출 : 정적 객체의 위치 및 종류 판별
2. 인지 기술의 발전 방향
   - 자율주행차 인지 기술의 어려움
   - 인지 기술의 도전적 과제
3. 인지를 위한 AI(딥러닝) 기술
   - 인공지능 개요
   - 인공지능 적용 과정
   - 딥러닝 기술
4. 딥러닝 기반 인지시스템 사례
   - 테슬라
     - FSD는 카메라와 레이더 센서만 사용
     - 딥러닝을 위한 하드웨어 직접 설계
   - 구글 웨이모
     - 라이다 주로 사용, 카메라와 레이더는 보조
     - 라이다 센서 직접 설계 -->

&nbsp;

&nbsp;

## 3. 카메라 센서

### 3-1. 카메라 센서 개요

- 카메라 센서 원리
  - 카메라는 CCD나 CMOS 이미지 센서에 빛을 입력시키는 센서
  - 카메라에는 **초점거리**와 **화각**이라는 용어가 있다.
    - 초점거리는 렌즈와 센서 사이의 거리를 의미
    - 화각은 카메라가 볼 수 있는 시야각으로서 화면을 구성하는 각도
    - 카메라의 렌즈에는 망원렌즈, 표준렌즈, 광각렌즈, 어안렌즈가 있다.
      - 망원렌즈 : FOV 40° 이하, 초점거리 70 ~ 200 mm
      - 표준렌즈 : FOV 40° ~ 60°, 초점거리 35 ~ 38 mm
      - 광각렌즈 : FOV 60° ~ 80°, 초점거리 15 ~ 35 mm
      - 어안렌즈 : FOV 180° 이상, 초점거리 7 ~ 15 mm
- 카메라 구조
  - 핀홀 카메라
    - 기본적인 카메라 구조
    - 일반적으로 사용되지는 않지만, 카메라 구조가 간단하여 이론에 많이 사용됨
  - 렌즈 카메라
    - 렌즈의 빛 굴절 특성을 이용
    - 렌즈에 의한 왜곡 보정 필요

&nbsp;

- 영상의 표현 방법
  - 카메라는 2차원 배열로 이미지가 저장되는데, 배열의 크기로 해상도가 결정된다. 배열의 최소 단위를 픽셀(Pixel)이라 한다. 해상도의 종류는 다음과 같다.
    - HD 해상도 : 1280 x 720
    - FHD 해상도 : 1290 x 1080
    - UHD 해상도 : 3840 x 2160
    - 4K 해상도 : 4096 x 2160
    - 8K 해상도 : 8192 x 4320
  - 영상은 프레임 단위로 저장이 되는데, 프레임의 단위는 fps(frame per second), 즉 1초당 프레임의 수로 나타낸다.
  - 영상의 색상은 Red, Green, Blue 세 가지 컬러를 조합해서 표현한다. 일반적으로 각 색상의 밝기를 8비트(0 ~ 255)로 표현한다. RGB 단위로 하기도 하나, HSV YCbCr 등으로도 표현이 가능하다.

&nbsp;

### 3-2. 카메라 캘리브레이션(보정) 기술

1. 카메라 좌표계
   - 카메라라는 3차원 공간을 2차원으로 변환하는 과정을 이해하기 위한 카메라의 물체를 표현하는 좌표계
   - +방향 기준 카메라의 전방을 z축, 아래방향을 y축, 오른쪽 방향을 x축으로 정한다.
2. 카메라 내부 파라미터
   - 카메라 내부의 기계적인 설정을 의미하는 파라미터(초점거리, 주점, 왜곡계수 등)
     - 초점거리(focal length) - fx, fy
       - 렌즈의 중심과 이미지 센서(CMOS, CCD)와의 거리
       - 픽셀 단위로 표현
     - 주점(pricipal point) - cx, cy
       - 렌즈의 중심에서 이미지 센서를 수직으로 지나는 점의 이미지 좌표
       - 픽셀 단위로 표현
     - 비대칭 계수(skew coefficient) - skew_c
       - 이미지 센서의 cell array의 y축이 기울어진 정도
       - 요즘 카메라는 대체로 skew 에러가 없음
3. 카메라 캘리브레이션
   - 카메라 내부 파라미터를 알아내고, 카메라 렌즈에 의해 생긴 왜곡을 보정하는 과정
   - 반복적인 패턴이 있는 체커보드를 카메라로 촬영하고, 이미지에서 체커보드의 코너점들을 검출하여 카메라 내부 파라미터값을 계산
   - 이미지 좌표계에서 월드 좌표계로의 변환 시 반드시 필요한 작업

&nbsp;

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F192F8344510E9B3A33">

카메라 비대칭 계수

&nbsp;

### 3-3. 카메라 기반 물체 검출/추적 기술

1. 카메라 기반 객체 **검출** 기술
   - 딥러닝을 활용해 카메라 영상을 입력으로 하여 물체의 위치와 종류를 알아내는 기술
   - 딥러닝 적용 과정
     1. 영상 데이터 취득
     2. 라벨링 진행
     3. 딥러닝 모델 학습
     4. 딥러닝 모델 인퍼런스
        - 모델 종류에 따라 결과가 다름
          - object detection : 물체의 위치와 종류, 확률을 나타내는 box와 label
          - image segmentation : 물체에 해당하는 픽셀 위치에의 확률 값
   - 딥러닝 기반 객체 검출 방법
     - 구조에 따라 1stage와 2stage로 분류함
       - 1stage : 계산시간이 빠른 구조로, YOLO, SSD 가 있음
         - 물체의 위치와 종류를 동시에 판별
       - 2stage : 검출 정확도가 높은 구조로, RCNN 가 있음
         - 물체의 존재여부 파악 후 정밀한 위치 및 종류 파악
       - 다양한 환경에서도 잘 추론하기 위해 최대한 다양한 환경에서의 데이터를 수집해야 함
2. 카메라 기반 객체 **추적** 기술
   - 비디오에서 각 프레임마다 검출 결과를 시간적 흐름을 파악하여 물체를 추적하는 기술
   - 같은 물체로 판단되면 다른 프레임이어도 같은 ID 부여
   - 등장 및 퇴장 파악 가능
   - 추적 과정
     1. 여러 프레임 입력
     2. 두 프레임 간의 검출 결과를 연결(Association)
     3. 연결을 위해서는 이전 프레임에서의 검출 정보와 추적중인 검출 예측 결과를 비교하여 가장 비슷한 물체끼리 연결
     4. 같은 물체끼리는 물체 ID를 부여
     5. 새로 등장/퇴장을 관리

&nbsp;

### 3-4. 카메라 기반 영역 분할 기술

1. 카메라 기반 영역 분할 기술
   - 카메라 영상에서 물체에 해당하는 픽셀들에 클래스 넘버를 부여하여 영역을 분할하는 기술
   - 주행할 수 있는 곳과 하지 못하는 곳을 분할하는 데에도 사용됨
   - 지도 기반 자기 차량 위치 측위에 해당 검출 결과 정보 활용
   - Semantic 영역 분할 기술
     - 같은 클래스끼리는 분류하지 않음
     - 차선, 도로, 횡단보도, 과속방지턱 등 검출에 사용
   - instance 영역 분할 기술
     - 같은 클래스라도 다른 ID를 부여하여 구분
   - 동적 객체 검출 모델과 비슷한 구조를 이루고 있어 모델을 공유함으로서 계산시간을 단축할 수도 있다.
     - ex. 테슬라의 RegNet

&nbsp;

&nbsp;

## 4. 레이더 센서

### 4-1. 레이더 센서 종류 및 작동 원리

1. 레이더 센서 종류
   1. 사용 주파수 대역에 따른 구분
      - 24GHz 대역 : 근거리용 레이더(SRR, Short Range RADAR)에 많이 사용
      - 77GHz 대역 : 원거리용 레이더(LRR, Long Range RADAR)에 많이 사용
   2. 신호 송신 방식에 따른 구분
      - 펄스 레이더
        - 1nm 이내의 짧은 펄스 신호를 송신
        - 송수신 신호 간의 전파지연 시간을 이용하여 상대 차량과의 거리 추정
        - 근거리 차랑용 레이더에 주로 사용됨
      - 연속파 레이더
        - 주파수 변조 연속파(FMCW) 레이더
          - 가장 많이 사용되는 레이더
          - 시간에 따라 주파수가 변하는 연속파 신호를 휴지시간 없이 지속적으로 송신
          - 송신 신호와 수신 신호를 이용해 목표와의 거리 및 상대속도 추출
          - 중장거리 차량용 레이더에 주로 사용됨
        - FSK 레이더
          - 디지털 변조에 이용
          - 자율주행에는 거의 사용되지 않음
2. 레이더 센서 작동원리
   1. 펄스 레이더
      - 주기적으로 펄스를 반송파에 실어 송신 후 수신까지의 지연시간을 계산하여 상대거리 예측
      - 하나의 안테나를 사용하므로 송수전환기(송수신격리기)를 통해 송신 신호와 수신 신호를 분리하여 처리
      - 다음 펄스의 송신이 일어나기 전에 반사 펄스가 들어오도록 하고 수신된 시간과 전력으로부터 거리 계산을 수행
   2. FMCW 레이더
      - 시간에 따라 선형적으로 변하는 주파수를 연속적으로 신호 생성하여 목표물에서 반사되는 신호 수신
      - 디처핑 방법(송신 신호 x 수신 신호)을 적용하여 송 수신 신호 주파수의 합과 차로 구성된 비트 신호를 얻게 됨
        - 수신 신호의 주파수 대역폭에 비해 비트 신호의 주파수 대역폭이 작기에 샘플링하기 위한 하드웨어 비용 절감 효과
      - 비트 신호의 스펙트럼을 분석하여 물체의 거리와 속도 계산
      - 송 수신 안테나가 분리되어 있음

&nbsp;

### 4-2. 레이더 신호 특성

1. 레이더 센서 신호
   - 자율주행차에는 밀리미터 파장 대역인 24GHz와 77GHz의 부근의 레이더 주파수 대역이 사용됨
     - 더 큰 대역폭일수록 거리 측정 정확도 증가
   - 전자기파는 날씨, 밝기, 시야가림 등의 환경 변화에 강한 특성을 가짐
   - 77GHz는 24GHz에 비해 안테나 모듈 크기를 작게 만들 수 있고, 지향성이 더 좋고, 인체에 미치는 영향도 적음
   - 클러터 문제 : 물체가 아닌 주변 장애물로 인해 신호가 검출되어 오탐률 증가
     - **실제 물체와 클러터를 구별할 수 있는 고성능 신호처리 알고리즘이 요구됨**
2. 레이더 신호를 이용한 물체 검출
   1. 레이더 신호의 주파수 분석
      - 수신 신호에 **고속 푸리에 변환(FFT) 기법**을 적용하여 시간에 따른 주파수의 변화를 분석한 결과를 바탕으로 물체 검출 수행
      - 주파수 성분에 배경 잡음과 클러터 등의 간섭 신호들이 존재
        - 간섭 신호 하에서도 일관된 오탐률을 유지하는 기술인 CFAR(Constant False Alarm Rate) 적용
   2. 배열 안테나를 이용한 각도 측정
      - 하나 이상의 안테나 원소로 구성된 배열안테나 이용
      - 수신된 신호의 위상 차이를 이용하여 수신 신호의 각도 추정
      - 안테나 원소 개수가 많을수록 각도 측정값 해상도 증가

&nbsp;

### 4-3. 레이더 송수신기 구성

1. 레이더 송수신기 구조
   - 디지털 신디사이저 : FMCW 송신 신호 발생
   - 오실레이터 - 믹서 - 파워앰프 - 송신안테나 : FMCW 송신 신호를 반송파에 실어 송신
   - 수신안테나 - 증폭기 : 시간적으로 지연된 반사 신호가 수신 안테나를 통해 수신
   - 믹서 - 저대역 필터 : 송신 신호와 수신 신호를 곱하여 저대역 필터 통과시켜 비트 주파수 성분 발생
   - 아날로그 디지털 컨버터 : 비트 주파수 성분을 디지털 신호로 변환
   - 디지털 신호 처리부 : 주파수 성분을 추출하여 상대거리와 속도 측정

   <img src="Fmcw 레이더 송수신기 구조.png">

2. 레이더 신호처리 기술
   1. 믹서
      - 송신 신호와 수신 신호를 곱하여, 두 신호의 주파수와 합과 차를 주파수로 갖는 신호를 발생시킴
   2. 저대역 필터
      - 고주파 신호를 걸러내고 저주파 신호만을 그대로 통과시키는 필터
      - 믹서에 의해 발생된 합과 차의 주파수는 저대역 필터를 통해 차 성분만 남게 되고, 이를 비트 주파수 성분이라 함
   3. 아날로그 디지털 컨버터 (ADC)
      - 디지털 신호처리 알고리즘에 의해 아날로그 신호를 디지털 신호로 변환
      - 출력된 디지털 신호는 디지털 신호처리 프로세서나 마이크로프로세서에 의해 처리
   4. 고속 푸리에 변환 (Fast Fourier Transform)
      - 시간에 따라 변화하는 비트 주파수 성분을 분석한 후 임계값보다 높은 값을 물체로 인식
   5. CFAR (Constant False Alarm Rate) 검출기
      - 시간-주파수 성분의 에너지를 임계값과 비교하여  오탐률을 일정하게 하는 검출기
      - 주변의 잡음 환경에 따라 임계값(Threshold)을 적응적으로 조절

&nbsp;

### 4-4. 레이더 기반 물체 검출 기술

1. 레이더 기반 타겟 물체 검출 과정
   - 수신 신호 x 윈도우 -\> 주파수 분석 적용
     - 윈도우 : 특정 영역의 신호만 처리하기 위한 값
   - 윈도우를 시간축으로 움직이면서 주파수 성분 변환을 수행하여 시간-주파수 영역의 신호 영상을 얻음
   - 이를 거리-도플러 영역으로 환산할 수 있으며 2차원 영상에서의 하나의 원소를 셀이라 부름
   - 거리 도플러 영역에서의 하나의 셀 = 차량에서 물체까지의 거리와 상대 속도
   - 각 셀에서의 신호의 세기를 임계값(Threshold)과 비교하여 수신 신호의 에너지가 임계값(Threshold) 보다 높으면 물체가 검출이 된 것으로 판단
2. 레이더 기반 물체 검출 기술 원리
   - 정해진 오탐률을 달성하기 위해 적절한 임계값(Threshold)을 결정해야 함
   - CFAR 검출기를 이용하여 임계값(Threshold)을 환경에 따라 조절
   - CFAR 검출기의 원리
     - 주어진 셀에서의 신호의 세기를 임계값(Threshold)과 비교하는 경우, 주변셀들의 신호의 세기를 파악하고, 이를 잡음의 에너지(세기)이라 가정하여 임계값(Threshold)을 결정하는 방법
     - 가장 많이 사용되는 것이 `셀-평균 CFAR 검출기`
       - 잡음의 세기 = 주변셀들의 신호 에너지의 평균으로 가정
       - 타겟셀(신호를 검출하고자 하는 셀)이 존재하고, 주변에 가드셀(타겟셀 신호 영향을 배제하기 위한 예외 처리 공간)이 있고, 앞뒤로 일정 간격의 주변셀이 있다. 이 주변셀들의 평균 에너지를 잡음으로 가정하고 임계값을 설정
   - 횡(가로)방향의 각도 검출
     - 도달각 추정 기술
       - 배열 안테나(Phased array)를 이용한 방향 측정
       - 위상 차이(각 요소에 들어오는 신호의 지연시간이 다름)를 분석하여 신호의 입사 방향(신호가 들어오는 방향) 측정

&nbsp;

&nbsp;

## 5. 라이다 센서

### 5-1. 라이다 센서 종류 및 개요

1. 라이다 센서 개요
   - 직진성이 강한 고출력 펄스 레이저를 송신하고 수신 시 지연시간을 분석하여 물체 탐지와 거리 측정 수행
   - 장점
     - 먼 거리의 물체까지 정확히 감지 가능하고, 위치 측정의 정확도도 높음
   - 단점
     - 높은 가격
2. 라이다 센서 종류
   1. 회전형과 고정형
      - 회전형
        - 센서를 직접 기계적으로 회전하여 넓은 각도의 환경 정보 획득
        - 수직으로 동시에 송신하는 레이저 빔의 수를 `채널 수`라 함
      - 고정형
        - 환경 정보를 획득하고자 각도에 설치하여 운용
        - 장점 : 구성이 비교적 단순하여 가격이 저렴
        - 단점 : 화각 한계로 인해 탐지 범위가 작음
   2. 라이다의 구현방식
      - 기계식 라이다
        - 현재 가장 많이 사용되는 방식
        - 기계적인 모터를 사용하여 주변 영역을 스캐닝
      - MEMS 라이다
        - MEMS 기술을 이용하여 작은 반사 거울을 제어하여 주변 영역을 스캐닝
      - 플래시 라이다
        - 단일 레이저 빔을 광 시야각으로 확장하여 송신하고 반사되는 레이저 빔을 다중 배열 수신 소자를 통하여 수신
      - FMCW 라이다
        - 레이더에 사용되는 FMCW 신호 분석 원리를 적용
        - 거리뿐만 아니라 속도 측정도 가능

&nbsp;

### 5-2. 라이다 센서 특성 및 데이터

1. 라이다 센서 특성
   - 라이다에서 발사한 레이저가 물체에 반사되어 돌아오는 지연 시간으로부터 물체까지의 거리 측정
   - 3차원 영역에서 인지를 수행하는 데 좋은 성능을 가짐
   - 해상도가 높을수록 고가
   - 반사체의 반사율이 낮을 경우 반사되어 들어오는 신호 성분 약화
   - 라이다 해상도 결정 요소
     - 화각 : 가로 방향으로 얼마만큼의 포인트를 얻어내는가?
     - 채널 수 : 수직적으로 몇 개의 채널을 사용하는가?
   - 먼 물체의 경우, 라이다 데이터의 분포가 희소하여 검출 성능이 저하됨
     - 카메라와의 센서 융합을 통해 극복
2. 라이다 데이터 표현 형식
   - 물체에 반사되어 돌아온 위치를 4차원 데이터 (X, Y, Z, I) 로 표현
     - location(X,Y,Z) + intensity
   - 여러 개의 (X, Y, Z) 포인트 데이터가 모여서 라이다 포인트의 집합인 포인트 클라우드(Point Cloud) 형성
     - 라이다 채널 수, 회전 속도 등에 의하여 해상도 결정
   - 자율주행 상황에서는 스캐닝 과정동안 차량이 이동하므로 차의 속도 정보를 활용하여 데이터 보정 필요
   - 라이다를 여러 개 장학하는 경우 서로 간섭이 발생할 수 있으므로 스캐닝 주기와 동기화 확인 필요

&nbsp;

### 5-3. 라이다 기반 물체 검출 기술

1. 라이다 기반 물체 검출 기술
   - 라이다 센서 데이터를 분석하여 물체의 위치와 종류 추정
   - 포인트 클라우드 데이터를 분석하여 주변 동적 객체 검출
2. 라이다 기반 물체 검출 기술 분류
   1. 3차원 검출 **결과 표현 방법**에 따른 분류
      - 3차원 영역의 물체 검출 방법
        - 3차원 영역에 물체를 포함하는 3차원 박스로 물체의 위치 표현
        - 카메라는 3차원 정보가 없으므로 3차원 검출이 불가능하나 라이다는 거리 정보가 측정되므로 3차원 검출이 가능
        ![Alt text](3d_box.png)
      - 조감도(Bird's eye view) 영역의 물체 검출 방법
        - 주변을 위에서 내려다 보는 방향에서 물체를 2차원 박스로 표현
        - 카메라는 원근감에 의해 거리가 멀수록 크기가 작으나 조감도 영역에서의 point cloud는 물체의 크기가 비슷
        - 물체 움직임에 따라 물체의 각도도 계산해야 함
        ![Alt text](bev.png)
   2. 라이다 데이터 전처리 방식에 따른 분류
      - 라이다 포인트 클라우드를 직접 처리
        - pointNet이라고 하는 딥러닝 방법을 적용하여 포인트 클라우드에서 직접 물체와 관련된 정보 추출
      - 복셀 기반 라이다 처리
        - 3차원 공간을 복셀이라고 불리는 작은 3차원 블럭으로 나눈 후 각 복셀 안에 있는 라이다 포인트 클라우드를 처리하여 물체에 대한 정보 추출
        - 라이다 데이터는 희박한 특징이 있으므로 대부분의 복셀은 비어있게 되므로 계산량을 줄일 수 있음.

&nbsp;

### 5-4. 라이다 기반 물체 추적 기술

1. 라이다 기반 물체 추적 기술 개요
   - 라이다 센서를 통해 얻은 검출 결과들을 시간적으로 연결하고 연결된 검출 결과에 물체 ID를 부여하는 작업
   - 라이다로부터 3차원 물체 검출 결과를 연결함으로써 3차원 공간에서의 물체 움직임 추적
   - 물체 추적 기술은 동적 객체들의 트랙(각 물체들이 현재 시간까지 움직여 온 경로)을 관리하는 것이 핵심
2. 라이다 기반 물체 추적 과정
   1. point cloud를 통한 3d 객체 검출 결과 도출
   2. 현재 관리하고 있는 물체들의 트랙과 검출 결과를 연결
   3. 새로이 등장한 객체 또는 퇴장한 객체 관리
   4. 연결된 검출 결과를 물체들의 트랙에 추가 후 필터링
3. 라이다 기반 물체 추적 기술 동향
   - 최근에 딥러닝 기술이 물체 검출 기술뿐만 아니라 물체 추적에도 적용되는 추세
     - 딥러닝으로 검출된 특징값을 활용해 트랙과 물체의 유사도를 측정
     - 트랙과 검출 결과의 관계를 파악하는 곳에도 그래프 구조의 최신 딥러닝 구조를 사용(Graphing Neural Network)
     - 필터링 시에도 LSTM 또는 RNN 딥러닝 모델을 사용
   - 물체 검출, 추적을 통합적으로 설계하여 보다 좋은 인지 성능 달성 가능
     - 검출 기술에서 추출된 특징값들을 활용하여 추적 기술의 성능 개선
     - 추적 기술에서 사용하는 시간적인 상관도를 활영하여 물체 검출 성능 개선

&nbsp;

&nbsp;

## 6. 센서 퓨전

### 6-1. 복합센서 적용 기술

1. 복합센서 적용 기술 개요
   - 센서 : 측정 대상물로부터 외부 물리적 신호들(빛, 소리, 화학물질, 온도 등)의 정보를 측정하여 기계가 이해할 수 있는 신호로 변환하는 소자 또는 장치
   - 자율주행차에서는 주로 카메라, 레이더, 라이다 센서 사용
2. 복합센서 융합 기술
   - 센서 융합 기술
     - 하나 이상의 복합 센서를 사용하여 주변 정보를 취득하고 이를 융합하여 인지 수행
   - 가능한 센서 융합 조합
     - 카메라 + 레이더
     - 카메라 + 라이다
     - 카메라 + 레이더 + 라이다
   - 복합 센서 융합 전략
     - 초기 융합
       - 센서1 + 센서 2 =\> 정보 융합 =\> 인지 처리
       - 인지 처리 1번
       - 계산량이 적으나, 카메라 + 라이다 처럼 데이터의 분포가 확연히 다를 경우 융합에 의한 성능 이득이 낮음
     - 후기 융합
       - 센서 1 인지 처리 + 센서 2 인지 처리 =\> 정보 융합
       - 인지 처리 2번
       - 계산량이 많으나, 최종 단계에서 융합하기 때문에 센서 오작동에 대한 분석 가능 및 각 센서의 신뢰도 파악 가능
     - 중기 융합
       - 센서 1 인지 처리 + 센서 2 인지 처리 =\> 정보 융합 =\> 인지 처리
       - 인지 처리 3번
       - 초기 융합과 후기 융합을 종합한 전략으로, 최근 딥러닝 기술이 인지에 적용되면서 선호되고 있음

&nbsp;

### 6-2. 센서융합 기술 사례

1. 카메라 + 레이더 센서융합
   - 카메라 : 물체에 대한 정확한 인식 결과를 주는 데 반해 위치 측정 정확도는 떨어짐
   - 레이더 : 물체의 거리에 대한 정확한 측정 결과를 제공하나 클러터나 잡음으로 인한 오탐률이 높음
   - 두 가지 센서의 장단점을 보완하기 위한 카메라 + 레이다 센서 융합
     1. 레이더 검출 결과 또는 중간 단계를 카메라 좌표계로 투영하여 병합하는 방법
     2. 카메라 영상 기반 물체 검출 결과 또는 중간 단계 결과를 레이더의 3차원 좌표계로 변환하여 융합하는 방법
2. 카메라 + 라이다 센서융합
   - 라이다 : 3차원 공간에 대한 정확한 거리 정보를 제공하지만 물체에 대한 색상과 형태 정보는 얻지 못함
   - 카메라와 라이다 센서 융합을 통한 검출 성능 개선
     1. 카메라 중심의 융합
        - 카메라를 통한 검출이 메인으로 하고, 라이다의 point cloud를 카메라 좌표계로 투영하여 보조
     2. 라이다 중심의 융합
        - 라이다 데이터의 해상도가 높은 경우 위치 정보는 라이다 데이터로 하고, 색상을 point cloud에 적용하는 방식으로, 카메라의 영상 데이터는 보조
3. 카메라 + 레이더 + 라이다 센서융합
   - 인지의 높은 신뢰성이 요구되는 레벨 4 이상의 자율주행을 위해 필요함
   - 실시간 센서융합 처리를 위한 알고리즘, 하드웨어 구현 필요

&nbsp;

&nbsp;

## 7. 고성능 인지를 위한 하드웨어/소프트웨어/통신 플랫폼

1. 고성능 인지 요구 사항
   - 센서 데이터 **고속 실시간 처리** 능력
   - **인지** 부분에 대한 **통합 처리 및 결과 상호 연결 능력**
   - **대용량 데이터 수집, 저장, 송신** 능력
   - **고신뢰성, 저전력**
   - 하드웨어, 소프트웨어 **오류**에 대한 **강인성** 및 **오류 검출** 능력
   - 주변 차량, 보행자, 인프라와의 **무선 통신** 능력
2. 고성능 인지를 위한 하드웨어
   - **고성능 컴퓨팅**을 위한 차량용 반도체 프로세서로의 진화
   - 다중센서 데이터 전달을 위한 **차량용 고속 네트워크 링크**
   - 실시간 **센서 데이터 고속 처리**를 위한 프로세스
   - 딥러닝 고속 연산을 위한 가속기 및 병렬처리 프로세서(**GPU**)
   - **오류에 대한 강인성** 확보하기 위한 하드웨어 설계
3. 고성능 인지를 위한 소프트웨어
   - 안드로이드와 같은 **오픈 소프트웨어 플랫폼** 필요
   - **AI 처리를 위한 소프트웨어**
   - 개발, 시뮬레이션, 테스트, 구현까지 **연결 가능한 개발자**
   - **딥러닝 모델 경량화**
4. 고성능 인지를 위한 통신 플랫폼
   - 자율주행 통신 플랫폼
     - V2X ( Vehicle to X )
       - V2V(차량끼리 정보 통신), V2I(차량과 인프라 간 정보 통신)
       - 자율주행차 및 인프라(주변 정보), 엣지(기지국)에서 주행 관련 데이터 정보 수집하고 주변 차량으로 정보 전송
       - 차량 또는 보행자와 사이드링크를 통해 인지 정보 공유
       - 인프라와 주변 동적 객체로부터 수신된 주행 관련 정보를 활용하여 협력 인지 수행
       - 안전한 자율주행을 위해 초저지연 통신 기술 필요
     - OTA ( Over The Air )
       - OTA 를 통한 인지 소프트웨어 기능을 주기적 업그레이드 필요
   - 통신 플랫폼 사용 시 **정보에 대한 보안 및 개인정보 보호 기술** 중요

&nbsp;

&nbsp;

## 8. AI 기반 인지시스템을 위한 지능형 반도체 기술

1. AI 기반 인지를 위한 반도체 기술
   - 자율주행차에서 실시간 AI 인지 시스템을 구현하기 위한 지능형 반도체 하드웨어 요구됨
   - AI 성능이 고도로 발전함에 따라 계산 복잡도가 빠르게 증가
   - AI 하드웨어 종류
     - GPU(그래픽 프로세싱 유닛) : 병렬처리에 특화된 범용 프로세서
     - NPU(뉴럴 프로세싱 유닛)
       - 엣지나 디바이스에서 사용하기 위한 저전력, 고속 AI 반도체 칩셋
       - 딥러닝에 많이 사용되는 계산을 빠르게 저전력으로 수행하는 가속기 사용
2. AI 기반 인지를 위한 지능형 반도체 사례
   1. 테슬라 FSD 컴퓨터
     - 칩셋과 파워서플라이를 여분으로 2개를 두어 고장이나 오류 발생 시 계산의 신뢰성 높임
     - 센서 정보를 수신할 수 있는 인터페이스 장착
     - 40 와트 이하의 전력 소모량
     - 가속기를 장착하여 딥러닝 연산을 50 테라 초당 명령 수 속도로 수행
     - 일반적인 전처리, 후처리 등의 범용계산을 위해 GPU와 CPU 장착
     - 고성능 영상처리칩과 비디오 인코더 장착
   2. 구글 TPU (Tensor Processing Unit)
     - 구글에서 디자인한 가속기 아키텍쳐 사용
     - Nvidia GPU V100보다 27배 연산속도가 빠름
     - 최근 v3버전은 1024개의 코어 사용
     - 가격 다소 저렴
     - 8비트 연산 기반의 딥러닝 모델 설계 지원
3. 자율주행을 위한 지능형 반도체 발전 방향
   - 소프트웨어 성능 극대화를 위한 하드웨어 직접 설계하여 자율주행 솔루션의 경쟁력 좌우
   - 하드웨어 플랫폼이 한번 결정되면 교체가 어렵고 독점 가능
   - ISO26262와 같은 자동차 하드웨어의 **기능안전성**에 대한 요구사항을 만족해야 함
   - 딥러닝 기술과 시스템이 계속 진화될 것이므로 확장가능성을 지원하는 하드웨어 플랫폼 필요

&nbsp;

&nbsp;

## 9. 측위 기술

### 9-1. 고정밀 지도 기반 자율주행 개요

1. 고정밀 지도 기반 자율주행의 필요성
   - 센서만으로 주변의 정적 주행 환경 및 도로, 교통 환경에 대한 정보 수집은 한계가 있음
   - 차량 주위의 정적 환경에 대한 정밀한 정보를 제공함으로써 자율주행의 안전성을 향상
   - 자율주행에서 고정밀 지도는 이미 오프라인에서 구축한 후 활용 -\> 고정밀 지도 기반의 측위 기술은 인지 기능에 비해 시스템, 계산량 오버헤드가 작은 편
   - 고정밀 지도의 장점
     - 정확한 정적 환경 정보 취득을 통한 자율주행 안전성 향상
     - 주행, 교통 환경에 대한 빠르고 정확한 판단 가능
     - 센서 데이터의 의존성 축소
   - 고정밀 지도를 사용하기 위해 요구되는 사항
     - 주행 관련 도로 정보 포함
     - 0.2m 이하의 매우 정밀한 정확도
     - 자율주행차의 고정밀 지도 위의 정확한 위치 파악 필요 -\> 맵매칭을 효과적으로 수행하기 위한 환경 정보 포함
     - 도로, 주행 환경이 바뀔 때마다 실시간 업데이트 지원 -\> 보통 클라우드에서 관리
     - 고정밀 지도 업데이트 -\> OTA를 통한 자율주행 차량에 새로운 지도 정보 무선 전송
2. 자율주행에서의 고정밀 지도의 활용
   - 자율주행 차량 위치 정밀 측위
     - 맵매칭 기법을 통한 자율주행차의 지도상 위치를 정확히 파악
   - 주행 경로 생성 및 예측
   - 도로의 곡률, 횡단보도 등의 교통 환경 반영
   - 신호등, 표지판 등 위치 정보를 통한 인지 정확도 향상
   - 동적 정보 시스템(LDM, Local Dynamic Map) 활용
     - 자율주행차, 인프라, 엣지에서 얻은 동적 객체의 위치와 상태를 고정밀 지도 위에 표현하여 LDM 구축
     - 특정 지역에 주행 상황에 대한 종합적인 정보 표현 및 다른 자율주행차들과 공유하여 더 원활한 자율주행 가능

&nbsp;

### 9-2. 고정밀 지도 및 측위 기술

1. 고정밀 지도의 필요성
   - 센서의 제한된 인식 범위 보완 - 수 km 이상의 도로 정보 취득
   - 환경 영향에 따른 센서 기능 보완
   - 센서 객체 인식 성능 향상 : 센서가 감지해야 하는 영역을 지도 정보로 보완하여 연산 속도 및 인지 기능 인식률 향상
2. 기존 측위 기술 소개
   - GPS 활용
     - 위성 신호를 수신하여 위치 추정
     - 장점 : 대부분의 차량에 기본적으로 탑재되어 있음
     - 단점
       - 전파 수신 상황에 따라 위치 정밀도가 좌우됨
       - 위치 오차가 미터 단위
       - 실내, 터널, 지하 등 음영지역 존재
   - RTK(Real Time Kinematic) 사용
     - 정밀한 위치를 확보한 기준점의 반송파 오차 보정치를 적용하여 수 cm 정밀도를 표현하는 고정밀 이동측량 기법
     - 장점 : 높은 측위 정확도
     - 단점
       - 비싼 가격
       - 위성을 사용하기에 음영지역 존재
   - 관성항법 장치 활용
     - IMU 등 관성 센서 정보를 활용하는 장치
     - 단점
       - 시간이 지속됨에 따라 오차 누적
3. 고정밀 지도 기반 측위 기술
   - SLAM(Simultaneous Location And Mapping) 기술 : 측위와 지도 생성을 동시에 하는 기술
   - 자율주행에서는 MMS 기술을 이용하여 고정밀 지도 미리 생성
     - 주행 시 고정밀 지도를 활용하여 측위만을 수행
   - 고정밀 지도 기반 측위를 위한 두가지 단계
     1. Odometry 기술 : 차량이 과거 위치에서부터 얼마나 움직였는지 측정
     2. 맵매칭 기술 : 센서 정보를 활용하여 맵매칭을 통해 고정밀 지도 위에 정확한 위치 측정
   - 맵매칭 방식의 측위 기술
     - 인지 기술을 통해 얻은 주변의 정적 환경 정보를 고정밀 지도의 환경 정보와 매칭하여 측위
4. 측위 정확도 향상 기술
   1. Odometrty 정확도 향상
      - 시간에 따라 오차가 누적되는 한계 존재
      - 주행 시 자율주행 차량의 움직임에 따른 카메라, 라이다 등의 센서 데이터 변화를 분석하여 오차 보정
   2. 맵매칭 기술 정확도 향상
      - 고정밀 지도에 어떤 환경 정보를 어떤 형태로 넣을지를 적절하게 선택한 후 AI를 통한 센서 데이터와의 정밀한 매칭을 통해 정확도 향상

&nbsp;

### 9-3. MMS 기반 고정밀 지도 구축 기술

1. MMS 의 개념
   - Mobile Mapping System(이동식 도면화 시스템)의 약자
   - 주행 중인 차량의 다양한 센서를 이용하여 세밀한 지형 정보를 획득하여 지도 구축
   - 수집 후에도 차로, 표지판 등을 위성사진을 통해 가공하는 후작업 필요
2. MMS 차량 구성
   - DGPS (Differential Global Positioning System)
     - 2개 이상의 GPS 수신 신호를 이용하여 정밀한 위치 측정
   - IMU (Inertial Measurement Unit)
     - 관성 센서 장치
     - 음역 지역에서도 움직임에 의한 상대 위치 변화 측정 가능
   - LiDAR
   - DMI (DIstance Measuring Instrument)
     - 바퀴 회전 수 측정을 통한 주행 거리 측정
   - INS (Inertial Navigation System) 관성항법장치
     - 자이로스코프를 통해 가속도를 구해 적분하여 속도를 계산한 후 이동거리를 계산하는 장치
3. MMS 기반 고정밀 지도 구축 과정
   1. 작업 계획 수립 : 작업지역 현황 분석 및 노선계획 수립
   2. MMS 시스템 구축 : MMS 장비 성능 및 품질 검사
   3. 기준점 선점 및 측량
      - DGPS 장치를 활용하기 위한 기준점에 대한 수신신호를 분석하여 GPS 데이터의 오차를 보정
   4. MMS 표준자료 제작 : GPS 측정 데이터와 LIDAR + 카메라 데이터를 비교 분석하여 제작된 3차원 point cloud 데이터를 통해 지상영상자료 제작
   5. 포인트 클라우드 데이터 후처리 및 보정
   6. 객체 추출 후 품질 검사, 벡터 데이터 상대정확도 검증
   7. 편집 및 정리 점검
4. MMS 기반 고정밀 지도 구축 기술 현황
   - 자율주행 기업뿐만 아니라 많은 스타트업 기업이 고정밀 지도 제작, 관리 연구
   - 대표 사례
     - 히어(Here)
       - 2010년에 시작하여 서유럽, 북미지역의 방대한 지도 데이터베이스 보유
       - 크라우드 소싱 차량의 센서 데이터를 통해 드라이브 경로, 차선 정보 수집
     - 톰톰(TomTom)
       - 우버 등에 지도 플랫폼 서비스 제공
       - 5100만 km 이상의 지도 데이터 보유
     - 현대엠앤소프트
       - MMS 장비를 도입해 지도 구축
       - 국내 일반/고속도로 정밀 지도 데이터 구축

&nbsp;

### 9-4. AI 기반 측위 기술

1. 자율주행을 위한 측위 기술
   - 자율주행 차량의 위치를 알아내는 측위기술 필요
   - 측위의 정확도 향상을 위해 주변 환경 인지 센서(카메라, 라이다, 레이더)에 대한 활용이 고려되고 있음
   - AI 기술을 적용하여 Odometry 기술, 맵매칭 기술의 정확도와 신뢰성 향상 기대
2. 측위를 위한 AI 기술
   1. AI 기반의 카메라, 라이다, 통합 Odometry 기술
      - 카메라 Visual Odometry 기술 : 카메라의 움직임에 의한 영상 프레임 사이의 변화를 분석하여 차량의 이동 위치 추정
      - 라이다 Odometry 기술 : 라이다 데이터의 시간적인 움직임을 분석
      - 통합 Odometry 기술 : 관성항법장치와 카메라/라이다 센서데이터 정보를 융합
   2. AI 기반의 맵매칭 측위 기술
      - 지형 지도 기반 측위
        - 주변 지형의 장면의 형태나 구조를 직접 표현
        - 깊이, 복셀, 점, 매쉬 형태로 표현
        - 딥러닝 모델을 통해 센서 데이터와 지형 지도로부터 특징값을 추출하여 위치 정보 보정
      - 시맨틱 지도 기반 측위
        - 랜드마크 또는 도로 정보를 지형 지도에 추가하여 만든 형태
        - 딥러닝 모델을 통해 정적 주행 환경 객체를 검출하고 지도에 포함된 랜드마크 정보들과 정합하여 위치 추정

&nbsp;
