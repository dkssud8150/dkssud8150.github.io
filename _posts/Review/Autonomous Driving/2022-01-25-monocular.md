---
title:    "[논문 리뷰] Monocular 3D Object Detection for Autonomous Driving"
author:
  name: JaeHo YooN
  link: https://github.com/dkssud8150
date: 2022-01-25 22:53:00 +0800
categories: [Review, Autonomous Driving]
tags: [Autonomous Driving, monocular]
toc: True
comments: True
math: true
mermaid: true
image:
  src: /assets/img/autodriving/mono/fig7.png
  width: 800
  height: 500
---

`Monocular 3D Object Detection for Autonomous Driving` 논문에 대한 리뷰입니다. 이 논문은 2016 CVPR에 투고된 논문이며 약 669회 인용되었다고 합니다. 혼자 공부하기 위해 정리한 내용이니 이해가 안되는 부분이 많을 수 있습니다. 참고용으로만 봐주세요.

<br>

# Abstract

본 논문은 자율주행에서 단안 이미지로부터 3D 객체 검출을 수행하는 것이 목표이다. 먼저 높은 퀄리티의 객체 검출을 얻기 위한 기본적인 CNN 파이프라인을 통해 돌아가는 클래스 객체 제안 후보 셋을 발생시키는 것을 목표로 한다. 이 논문의 중점은 제안 발생이다. 특히, 물체는 지면 위에 있어야만 한다는 사실을 이용하여 객체 후보를 3D로 배치하는 에너지 최소화 접근법을 제시한다. 그러고 나서 의미 분할, 문맥 정보, 이전의 크기 및 위치, 일반적인 객체 모양을 인코딩하는 몇가지 직관적인 잠재력을 통해 이미지 평면으로 투영된 각 후보 박스에 대해 점수를 매긴다. 우리의 실험 결과는 우리의 객체 제안 발생 접근법이 모든 단안 접근법을 엄청나게 능가하고, 단안 경쟁 모델 중 까다로운 KITTI benchmark 에서 최고의 검출 성능을 달성한다는 것을 볼 수 있다.

<br>

# 1. Introduction

최근에, 자율주행은 요즘 많이 주목받고 있다. 초기에는 벨로다인, 환경을 손으로 그린 맵과 같이 비싼 LIDAR 시스템에 의존한다. 그러나, 최근에는 LIDAR를 대부분 현대의 차들에 손쉽게 사용가능한 값싼 카메라로 바꾸려고 하고 있다. 

또한 이 논문의 중점은 자율주행에서 단안 이미지로부터 높은 성능의 2D 와 3D 객체 검출이다. 대부분의 최근 객체 검출 파이프라인들은 전형적으로 상대적으로 빠른 계산과 높은 리콜을 가진 객체 제안의 다양한 셋을 발생시킨다. 이렇게 함으로서, CNN시리즈와 같이 계산이 강도 높은 분류기는 대량의 필요 없는 후보 세트에 대한 계산을 피할 수 있다. 

다른 타입의 객체 제안 방법들 중, 일반적인 접근 방식은 이미지를 매우 작은 픽셀로 세분화하고, 몇 가지 유사성 측정을 사용하여 이들을 그룹화한다. 단순한 객체 특징 또는 외곽선 정보를 사용하여 전체 창들을 효율적으로 탐색하는 접근법도 제안되었다. 대부분의 최근 작업들은 이진 세분화 모델, 파라메트릭 에너지, CNN 특징 기반의 윈도우 분류기 중 하나를 사용하여 좋은 객체 후보를 제안하는 방법을 만드는 것을 목표로 한다.

이 제안 발생 접근 방식들은 다소 루즈한, 즉 검출이 GT와 0.5 IOU가 생기는 경우를 긍정으로 보는 경우로 하는 위치화 개념을 필요로 하는 PASCAL VOC 챌린지에 매우 효과적인 것으로 나타났다. 그러나 자율 주행에서는 자동차 스스로 잠재적 장애물까지의 거리를 정확하게 추정하기 위한 더 많은 엄격한 중복을 요구한다. 결과적으로, R-CNN과 같은 인기있는 KITTI와 같은 자율주행 벤치마크에서의 다른 경쟁자들보다 엄청나게 떨어진다. 그러나, 대부분의 차들은 단일 카메라가 장착되어 있고, 그래서 단안 객체 검출은 중요한 기술이다.

이러한 접근 방식에 영감을 받아, 이 논문은 의미론뿐만 아니라 상황별 모델을 활용하여 매우 높은 회수율로 클래스별 3D 객체 제안을 생성하는 방법을 제안한다. 이 제안들은 지면에 3D 경계 상자를 철저히 배치하고 단순하고 효율적으로 계산 가능한 이미지 기능을 통해 점수를 매김으로써 생성된다. 특히, semantic 과 instance 세그멘테이션, 컨텍트 뿐만 아니라 형상 특징들과, 박스들을 점수 매기기 위한 이전 위치 정보을 사용한다. 저자는 각각의 개별 객체 클래스에 적응되어 있는 S-SVM을 사용한 피쳐들에 대한 각 클래스마다의 가중치들을 학습한다. 그러고 나서 가장 높은 객체 후보들은 CNN을 통해 점수 매겨지고, 검출의 최종 셋의 결과로 추출된다. 이 논문의 실험은 우리의 접근 방식이 KITTI에서 모든 공개된 단안 객체 검출을 능가하고 스테레오 이미지를 이용하는 선두모델과 거의 동등하게 수행하고 있음을 보여준다.

<br>

# 2. Related Work

본 논문의 작업은 객체 제안 발생 뿐만 아니라 단안 3D 객체 검출에 대한 방법들과 관련이 있다. 자율주행에서 문학적 리뷰를 주로 집중할 것이다. 심층 신경망에서의 중요한 프로세스는 슬라이딩 윈도우 창을 계산적으로 만드는 심층망때문에 객체 제안 발생에 대한 방법에 사용된다. 제안 발생에 대한 대부분의 현존하는 작업은 RGB, RGB-D 또는 영상을 사용한다. RGB에서 대부분의 방법들은 색깔과 텍스쳐를 사용하는 것과 같이 여러 유사성 함수를 통해 슈퍼픽셀들과 큰 지역과 결합한다. 이러한 접근 방식은 PASCAL VOC에서 거의 완벽한 호출을 달성하면서 이미지당 약 2K개의 제안으로 전체 윈도우를 전환한다. BING 제안들은 객체성에 대한 프록시로서 객체 측정에 기반된 박스들을 점수매긴다. Edgeboxes는 각 창의 경계와 내부 윤곽 정보를 기반으로 전체 위도우 셋에 점수를 매긴다. 우리와 가장 관련있는 접근법들은 객체를 제안하는 방법을 배우는 것을 목표로 한다. 

우리의 접근 방식은 후보들을 점수매기기 위해 통합 이미지를 활용하기도 하지만, 이전의 정보들을 사용하여 3D 경계 상자를 배치하고 의미론적 특징으로 점수매긴다. 저자는 grid CNN의 출력 계층에서 픽셀 단위의 클래스 점수와 상황별 및 모양 특징을 사용한다. 또한, 저자는 3D bounding box를 평가하지만, semantic 과 instance 세그멘테이션과 3D priors를 사용하여 지면에 제안들을 배치한다. 이 논문의 RGB 전위는 부분적으로 2D 객체 검출을 위해 효율적으로 계산된 세그멘테이션 전위를 활용하는 데 영감을 받았다.

<br>

# 3. Monocular 3D Ojbect Detection

<img src="/assets/img/autodriving/mono/fig1.png">

본 논문에서 정확한 3D 객체 검출을 수행하기 위해 세그멘테이션(segmentation), 컨텍트(context), 이전 위치(location priors)들을 추출하는 객체 검출에 대한 접근법을 제시한다. 특히 먼저 지면 가까이에 있는 물체를 제안하기 위해 지면을 사용한다. 단안 이미지를 입력으로 하기 때문에, 지상 평면은 이미지 평면과 직각을 이루고, 카메라에서 멀리 떨어져 있다고 가정한다. 그 값은 보정을 통해 알 수 있다고 가정한다. 이 지면은 각각의 이미지에서 완벽한 현실을 반영하지 않을 수 있으므로, 물체를 지면에 놓지 않고 가까이 있도록 한다. 그러고 나서 클래스 세그멘테이션, 인스턴스 레벨 세그멘테이션, 형상이나 문맥적 특징과 이전 위치들을 활용하여 이미지 평면에서 3D 객체 후보들을 점수매긴다. 그러고 나서 결과로 나온 3D 후보들은 점수를 기준으로 정렬되고, NMS를 통해 추출된 가장 높은 확률의 것들은 CNN을 통해 또다시 점수매겨진다. 이 과정을 통해 3D 검출에 대해 빠르고 정확하게 된다.

## 3.1 Generating 3D Object Proposals

3D bounding box를 다음과 같이 정의한다. 

```markdown
y = (x,y,z,0,c,t), (x,y,z): 3D box의 중심 좌표, 0: 방위각, c: object class, t: 훈련 데이터로부터 학습된 대표 3D 템플릿 셋
```

t를 사용하여 bounding box의 사이즈를 정의한다. 각 클래스마다 3개의 템플릿과 두 개의 각도(0∈{0,90}) 를 사용한다. 그 후 semantic and instance segmentation과 location prior, context를 결합하여 정의된 스코어 함수는 다음과 같다.

<img src='/assets/img/autodriving/mono/scrfc.png'>

이 함수를 좀 더 디테일하게 들여다 보자.

<br>

* Semantic segmentation

맨 앞부분부터 보자면, 이 부분은 픽셀 단위의 의미 분할(semantic segmentation)을 입력으로 받는다. 그 후 두 가지의 특징을 통합하여 의미 분할을 수행한다. 첫번째 특징은 관련 클래스로 분류된 픽셀들의 확률을 활용해서 객체의 bounding box를 구성한다. 사용하는 식은 다음과 같다.

<img src='/assets/img/autodriving/mono/cseg.png' width="30">

이 때, Ω(y)는 이미지 평면으로 3D 박스, y를 투영하여 생성된 2D 박스의 픽셀 집합이고, Sc는 클래스,c 의 세그멘테이션 마스크이다. 

<br>

두번째 특징은 픽셀들이 해당 클래스 대비 다른 클래스로 속할 확률을 계산한다.

<img src='/assets/img/autodriving/mono/nonseg.png' width="30">

이는 크게 두 가지로 구성되어 있는데, 1개는 길을 뜻하고, 다른 1개는 다른 모든 클래스들을 합친 것을 의미한다. 이 식을 통해 bounding box안에 다른 객체를 뜻하는 픽셀의 비율을 최소화한다. 

이 특징들은 클래스 수만큼의 통합 이미지만을 사용하여 매우 효율적으로 계산할 수 있다. 

SegNet의 경우, fully convolutional 인코더-디코더를 통해 semantic 라벨링을 수행한다. 저자는 PASCAL VOC + COCO에서 차량 세그멘테이션에 대해 pretrained model을 사용한다. 그리고, 다른 클래스의 불일치를 줄이기 위해, 보행자와 자전거 이용자에 대한 pretrained SegNet model을 사용한다. KITTI에는 semantic 주석(annotation)이 거의 없으므로 모델을 fine-tune을 하지 않았다. 게다가 KITTI의 로드 benchmark에서 주석을 추출했고, 로드에 대해 네트워크를 fine-tune했다.

* Shape

여기서는 객체의 형상을 포착한다. 특히, 먼저 원래의 이미지 대신 세그멘테이션의 출력에서 윤곽을 계산한다. 

