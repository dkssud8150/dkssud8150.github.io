---
title:    "[논문 리뷰] PointRCNN: 3D Object Proposal Generation and Detection from Point Cloud"
author:
  name: JaeHo YooN
  link: https://github.com/dkssud8150
date: 2022-02-02 00:17:00 +0800
categories: [Review, Autonomous Driving]
tags: [Autonomous Driving, pointrcnn]
toc: True
comments: True
math: true
mermaid: true
image:
  src: /assets/img/autodriving/pointrcnn/fig1.png
  width: 500
  height: 800
---

`PointRCNN: 3D Object Proposal Generation and Detection from Point Cloud` 논문에 대한 리뷰입니다. 이 논문은 2019 CVPR에 투고된 논문이며 약 803회 인용되었다고 합니다. 혼자 공부하기 위해 정리한 내용이니 이해가 안되는 부분이 많을 수 있습니다. 참고용으로만 봐주세요.

<br>

# Abstract

본 논문에서는 포인트 클라우드로부터 3D 객체 검출에 대한 PointRCNN을 제안한다. 전체 프레임워크는 2단계로 구성되어 있는데, 1단계는 상향식 3D 제안 발생을 진행하고, 2단계에서는 표준 좌표안에서 제안을 정제하여 최종적인 객체 결과를 얻는다. RGB 이미지로부터 제안을 발생하거나 이전 방식대로 조감도나 복셀들로 포인트 클라우드를 투영하는 것 대신, 이 1단계 서브 네트워크는 전체 포인트 클라우드를 전경/배경으로 분할을 통해 상향식으로 포인트 클라우드에서 작은 수의 하이 퀄리티의 3D 제안을 직접 생성한다. 2단계 서브 네트워크는 각 제안의 풀링된 포인트를 표준 좌표로 변환하여 더 나은 로컬 공간적 특징을 학습하고, 이는 1단계에서 학습된 각 포인트의 전역 의미론적 특징과 결합되어 정확한 박스 세분화 및 신뢰도 예측을 제공한다. KITTI 데이터셋의 3D 객체 벤치마크에서의 실험은 제안된 아키텍쳐가 입력으로서 포인트 클라우드만을 사용하여 최첨단 방법들을 엄청난 차이를 보이면서 능가한다는 것을 보여준다. 코드는 [이 주소](https://github.com/sshaoshuai/PointRCNN)를 참고하면 된다.

<br>

# 1. Introduction

딥러닝은 객체 검출과 인스턴스 세그멘테이션을 포함한 2D 컴퓨터 비전에서 엄청난 진보를 이루고 있다. 2D 장면을 이해하는 것 이상으로 3D 객체 탐지는 중요하고 로봇이나 자율주행과 같은 현실에 적용하기에 필요 불가결하다. 최근 개발된 2D 탐지 알고리즘은 이미지에서 큰 범위의 뷰 포인트 및 배경 클러터를 처리할 수 있지만, **포인트 클라우드가 있는 3D 개체를 감지**하는 것은 여전히 3D 개체의 6DoF(Degrees-of-Freedom)의 불규칙한 데이터 형식과 대규모 검색 공간에서 큰 어려움에 직면해 있다. 

<img src='/assets/img/autodriving/pointrcnn/fig1.png'>

자율주행에서 보통 3D 센서로 장면들의 3D 구조를 포착하여 3D 포인트 클라우드를 발생시키는 LIDAR 센서를 사용한다. 포인트 클라우드 기반의 3D 객체 탐지의 어려움은 주로 포인트 클라우드의 불규칙성에 있다. 최첨단 3D 객체 탐지 방법들은 위의 그림a처럼 조감도 뷰나 전방뷰 또는 규칙적인 3D 복셀로 포인트 클라우드를 투영하는 좋은 2D 탐지 프레임워크를 활용하는데, 이는 최적이 아니며 정보 손실을 겪을 수 있다. 특징 학습을 위해 포인트 클라우드를 복셀이나 다른 규칙적인 데이터 구조로 변환하는 대신, 포인트 클라우드 분류와 분할에 대한 포인트 클라우드 데이터로부터 직접적으로 3D 표현을 학습하기 위해 PointNet을 제안한다. 

위의 그림b와 같이, 이 아키텍처는 pointNet을 적용하여 2D RGB 탐지 결과로부터 자른 frustum 포인트 클라우드를 기반으로 한 3D 바운딩 박스를 측정했다. 그러나 이 방법의 성능은 2D 탐지에 크게 의존하고, 강인한 바운딩 박스 제안을 생성하기 위한 3D 정보의 장점을 활용할 수 없다.

2D 이미지로부터 객체 탐지와는 달리 자율주행에서 3D 객체는 주석이 달린 3D 바운딩 박스에 의해 자연스럽고 잘 분리된다. 즉, 3D 객체 탐지에 대한 훈련 데이터는 직접적으로 3D 객체 분할에 대한 의미론적 마스크를 제공한다. 이는 2D 탐지와 3D 탐지 훈련 데이터 사이의 중요한 차이가 된다. 2D 객체 탐지에서 바운딩 박스는 오직 시멘틱 분할에 대한 약한 지도(supervision)를 제공할 수 있다.

이 관찰을 기반으로 정확하고 강인한 3D 탐지 성능을 달성하고 3D 포인트 클라우드에서 직접적으로 동작하는 `PointRCNN`이라는 새로운 2단계 3D 객체 탐지 프레임워크를 제시한다. 이에 대한 설명은 위의 그림c를 통해 볼 수 있다. 이 제시된 프레임워크는 2단계로 구성되어 있는데, 1단계는 상향식으로 3D 바운딩 박스 제안 생서을 목표로 한다. GT 분할 마스크를 생성하기 위한 3D 바운딩 박스를 활용하여 1단계는 배경 점을 분할하고, 분할된 점들로부터 소수의 바운딩 박스 제안을 생성한다. 이러한 전략은 전체 3D 공간 안에서 많은 3D 앵커 박스 사용을 피하고, 계산을 줄인다. 

두번쨰 단계에서는 표준 3D 박스 교정을 수행한다. 3D 제안이 발생된 후에, 포인트 클라우드 영역 풀링 작업을 적용하여 1단계로부터 학습된 점 표현을 풀링한다. 전역 박스 좌표를 직접적으로 측정하는 3D 방법들과 달리 풀링된 3D 점들은 표준 좌표로 변형되고, 상대 좌표 교정을 학습하기 위해 1단계의 분할 마스크뿐만 아니라 풀링 포인트 특징과 결합된다. 이 전략은 1단계의 분할과 제안으로부터 제공된 모든 정보를 활용한다. 더 효과적인 좌표 정제를 위해, 제안 생성 및 개선을 위한 전체 **bin 기반의 3D 상자의 회귀 손실**도 제안하며, 절제 실험 결과 다른 3D 상자의 회귀 손실보다 수렴 속도가 빠르고 회수율이 높은 것으로 나타났다. 

이 논문을 통해 3가지를 기여할 수 있다. (1)첫번째는 포인트 클라우드를 전경 객체 및 배경으로 분할하여 소수의 고품질 3D 제안을 생성하는 새로운 상향식 포인트 클라우드 기반의 3D 바운딩 박스 제안 알고리즘을 제안한다. 분할로부터 학습된 점 표현은 제안 발생에 좋을 뿐만 아니라 추후의 박스 정제에도 도움을 준다. (2)제안된 표준 3D 바운딩 좌표 정제는 1단계로부터 생성된 높은 리콜 박스 제안의 이점을 활용하고, 강력한 빈 기반의 손실로 표준 좌표의 박스 좌표 정제를 예측하는 방법을 학습한다. (3)제안된 3D 탐지 프레임워크인 pointRCNN은 엄청난 차이로 최첨단 기술들을 능가하고, 입력으로 포인트 클라우드만을 사용함으로써 KITTI 3D 탐지 테스트에서 공개된 모든 모델 중 1등을 차지했다.

<br>

# 2. Related Work

* 3D object detection from 2D images

이미지로부터 3D 바운딩 박스를 추정하는 방법들이 있다. 3D와 2D 바운딩 박스 사이의 공간적 제약 조건을 활용하여 3D 객체 자세를 복구하기도 하며, 이미 정의된 3D 박스들을 평가하기 위한 에너지 함수로서 객체의 3D 구조적 정보를 형성하기도 한다. 이러한 작업들은 깊이 정보가 부족하여 대략적인 3D 감지 결과만 생성할 수 있으며, 외관 변화에 상당한 영향을 받을 수 있다.

* 3D object detection from point clouds

최첨단 3D 객체 탐지 방법들은 희박한 3D 포인트 클라우드로부터 뚜렷한 특징을 학습하기 위한 다양한 방법들을 제안했다. 포인트 클라우드를 조감도로 투영하고, 2D CNN을 활용하여 3D 박스 발생을 위한 포인트 클라우드 특징을 학습하기도 한다. 점들을 복셀로 그룹화하고, 3D CNN을 활용하여 3D 박스들을 발생시키기 위한 복셀의 특징들을 학습하기도 한다. 그러나 조감도 투영과 복셀화는 데이터 정량화하는 동안에 정보 손실을 겪고, 3D CNN은 메모리와 계산이 너무 많다. 그래서 정확한 2D 탐지기를 활용하여 이미지로부터 2D 제안을 생성하고, 각 잘린 이미지 영역안에서 3D 점의 크기를 줄이기도 했다. 그런 다음 PointNet은 3D 박스 추정에 대한 포인트 클라우드의 특징들을 학습하는데 사용되기도 했다. 그러나 2D 이미지 기반의 제안 생성은 3D 공간에서만 잘 관찰될 수 있는 일부 까다로운 사례에 대한 것은 잘 적용되지 않는다. 그러한 실패는 3D 박스 추정 단계로는 복구할 수 없었다. 

대조적으로 우리의 상향식 3D 제안 생성 방법은 포인트 클라우드에서 직접적으로 강력한 3D 제안을 생성하는데, 이는 효율적이다.

* Learning point cloud representations

복셀이나 멀티뷰 포맷으로서 포인트 클라우드를 표현하는 대신, 포인트 클라우드 분류 및 분할의 속도와 정확도를 크게 높이는 포인트 클라우드에서 점들의 특징을 직접 학습할 수 있는 PointNet 아키텍처를 제시한다. 후속 작업에서는 포인트 클라우드의 로컬 구조를 고려하여 추출된 특징 품질을 더욱 개선한다. 

우리의 작업은 점 기반의 특징 추출기를 3D 포인트 클라우드 기반의 객체 탐지로 확장하여 원시 포인트 클라우드에서 3D 박스 제안과 감지 결과를 직접 생성하는 새로운 2단계 3D 탐지 프레임워크를 제시한다.

<br>

