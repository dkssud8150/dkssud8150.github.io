---
title:    "[논문 리뷰] YOLO-based lane detection system"
author:
  name: JaeHo YooN
  link: https://github.com/dkssud8150
date: 2022-03-30 00:17:00 +0800
categories: [Review, Autonomous Driving]
tags: [Autonomous Driving, YOLO]
toc: True
comments: True
math: true
mermaid: true
image:
  src: /assets/img/autodriving/yolo/main.png
  width: 800
  height: 500
---

`YOLO based lane detection system` 논문에 대한 리뷰입니다. 본 논문은  혼자 공부하기 위해 정리한 내용이니 이해가 안되는 부분이 많을 수 있습니다. 참고용으로만 봐주세요.

<br>

# Abstract

자율주행과 반자율주행 자동차가 개발되고 이러한 기술들은 주변 환경 문제로 인해 차선 이탈 경우와 자율주행 자동차에서 판단하지 못하는 상황이 생기고, 차선 검출기에서는 차선을 인식하지 못하는 경우가 있다. 이런 문제점에 대한 성능을 향상시키기 위해 본 논문에서는 YOLO(You Only Look Once)의 특성인 빠른 인식을 사용하고 CSI Camera를 사용하여 주변 환경으로부터 영향을 받는 상황을 인지하고 주행 데이터를 수집하여 관심 영역을 추출하는 차선 검출 시스템을 제안한다.

<br>

# 서론

자율주행 분야는 운전자의 조작이 없이 주행 상황을 판단하고 스스로 운행을 제어하여 스스로 주어진 목적지까지 주행하는것을 목표로 한다. 첨단 감지 센서, 통신 및 영상 장비 등을 사용하여 운전자에게 서비스를 제공하는 **ADAS**(Advanced Driver Assistance Systems)가 있는데, 이 기술에는 차선 검출과 트롤리 딜레마(trolley dilemma) 기술 등이 포함된다.

차선 검출 기술은 주변 환경의 영향을 받아 차선을 인식하지 못하는 문제가 존재한다. 따라서, 본 논문에서 제안하는 차선 이탈에 대한 성능을 향상하기 위해 객체 인식 기술을 활용하여 차선 검출 시스템에 관한 연구를 제안한다. 

CSI Camera를 사용하여 **YOLO** 기반 실시간 영상에서 차선의 특징을 추출하여 차선이 지워지거나 흐려진 차선을 판별하고 직진과 커브 같은 수많은 상황의 주행 데이터를 수집 및 저장하고 차선 검출을 하며 차선 검출을 잘 하기 위해 노출 및 밝기 등을 활용하여 인식률을 향상시켜야 한다.

> CSI camera란?
카메라 직렬 인터페이스(camera serial interface)는 MIPI(Mobile Industry Processor Interface)의 일종이다. 이는 카메라와 프로세서 사이의 연결을 의미하는데, CSI-1,CSI-2,CSI-3 등이 있다. 이는 카메라와 호스트 프로세서 사이의 연결을 규정하는 아키텍처 버전을 의미한다. 이와 비슷한 것으로 DSI(Display Serial Interface)가 있다. 이 둘은 OSI 7계층 중 프로토콜 계층에 속한다.
>
>[위키디피아](https://en.wikipedia.org/wiki/Camera_Serial_Interface)
>
>[참고 블로그](https://en.wikipedia.org/wiki/Camera_Serial_Interface)
>

<br>

# 시스템 설계

여기서는 yolo를 통한 차선 인식 시스템을 설계하고, CSI Camera에서 촬영된 영상을 크기와 대비를 조정하여 전처리를 제어하는 과정을 나타낸다. 사용자 차량의 블랙박스에 CSI Camera를 설치하여 영상을 촬영하여 데이터를 수집한다. 수집된 데이터는 전처리 과정을 통해 차선을 추출하고, 관심 영역(ROI)를 자른 후 차선의 특성을 추출한다. 후처리로는 차선 검출 결과는 사용자에게 차선 검출이 되지 않았을 경우 경고 시스템을 작동시켜 알림 서비스를 제공한다.

<br>

## 시스템 흐름

아래 그림은 데이터 처리 과정이다.

<img src="/assets\img\autodriving\yolo\fig2.png">

이 논문에서 Jetson nano developer kit에 micro SD카드를 부팅 장치나 주저장장치로 사용했다고 한다. CSI Camera에서 데이터를 추출해서 jetson nano로 보내서 데이터를 처리한다. 처리 과정에는 흰색 차선 검출, ROI(region of interest)를 자르고, 라인 특징을 인식한다. 그리고 그 결과를 통해 라인과 떨어져 있는지, 라인이 없는지 확인하여 사용자에게 경고 알림을 보낸다.

<br>

### 1. 관심 영역 추출

주행 영상에서 얻은 데이터를 사용해서 DarkNet을 기반으로 관심 영역을 추출하고 객체마다 바운딩박스를 그려주어 관심 영역으로 설정한다. 아래 그림은 이를 시각화한 그림이다.

<img src="/assets\img\autodriving\yolo\fig3.png">

원본 영상에서 단일 프레임을 추출해서 관심 영역 인식을 하였고, 이미지 크기를 작게 만들어 연산량을 줄였다. 줄인 이미지는 CNN에 보내져 특징맵(feature map)으로 리턴되고, 여기서 찾아진 바운딩박스에서 같은 물체를 가르키는 박스들을 전부 제거해줘야 한다. 이 때 IOU(intersection of union), 즉 겹치는 정도가 지정해둔 임계값(threshold)보다 높으면 같은 물체를 가르키고 있다고 판단하여 NMS(non-max supression)을 통해 제거해준다. NMS는 말 그대로 가장 높은 것만 놔두고 나머지는 제거하는 방식이다. 

이 때, 차선이 아닌 객체만 인식하도록 클래스를 지정하여 객체만 인식시킨다. 이 상자 좌표를 기반으로 관심 영역을 추출하고 자른 이미지를 따로 저장한다. 

<img src="/assets\img\autodriving\yolo\fig4.png">

(나의 의견으로, 자른 이미지를 저장하는 이유는 프레임에서 물체를 인식하여 저장해서 객체 인식 훈련에 사용될 데이터 셋을 쌓는 것 같다.)

<br>

### 2. 차선 인식

주행 영상을 Video 폴더에 저장하고, 차선을 검출하지 못했을 경우에는 출력화면에 경고 알림으로 사용자에게 알린다. 

<img src="/assets\img\autodriving\yolo\fig5.png">

이에 대한 자세한 설명은 아래 전처리에서 설명한다.

<br>

## 3. 데이터베이스 설계

PyMySQL의 라이브러리를 사용하여 시스템을 설계했다고 한다. 카메라에서 실시간 영상을 실시간으로 받아 저장된 데이터는 데이터베이스에 저장된다. 설계한 데이터베이스는 3가지 테이블을 갖추고 있다.

1. Video storage : 실시간으로 받아진 영상 데이터
2. ROI setting : CNN을 통해 추출된 ROI로 자른 이미지
3. Lane detection : 차선 영상을 저장

<br>

### 1. 전처리

수집된 영상 데이터는 전처리된다. 전처리라 함은 이미지 크기 조정 및 관심 영역 추출이다.

<img src="/assets\img\autodriving\yolo\fig6.png">

위는 전처리 과정을 나타낸 것으로, CNN을 통해 추출된 차선의 특징맵(feature map)에서 후보 순위를 두는 proposal과 ROI들을 뽑아낸다. 그 후 수많은 ROI를 pooling하여 score가 가장 높은 것만 남겨서 개수를 축약시킨 뒤 proposal과 겹치는 바운딩 박스들을 classifier로 보낸다. classifier는 보통 FC layer을 사용하거나 1-dimension convolutional layer를 사용한다. classifier를 통해 차선을 검출한다.

전처리 과정에서 차선의 특징 추출을 통해 흰색 차선을 관심 영역으로 자르고 차선의 특성에 대해 감지한다. 후처리로 차선 검출의 결과값을 받아 차선 검출을 확인하여 사용자에게 제공하고, 되지 않으면 경고 시스템을 작동시킨다. 아래 그림은 시스템의 검출 과정을 나타낸 것이다.

<img src="/assets\img\autodriving\yolo\fig7.png">

<br>

<br>

# 시스템 구현

촬영된 영상과 실시간 촬영으로 수집된 데이터를 기반으로 ROI 설정과 관심 영역설정에 대해 설명한다.

## 1. 객체 인식 기반 차선 검출 구현

<img src="/assets\img\autodriving\yolo\fig8.png">

수집된 영상 데이터에서는 출력 크기를 조정하기 위해 훈련된 모델을 활용하여 검출 module을 초기화했다. 출력 크기를 임의로 설정하고 검출기에서 특징점 module 초기화를 통해 shape_predictor를 사용한다. 

차선을 찾는 기본적인 방법은 차선의 특징점을 찾아 RGB 색상으로 인해 흰색 또는 노란색 차선, 직선 또는 곡선 차선의 특징을 파악하여 ROI를 설정하고 관심 영역을 추출하여 차선을 검출한다. 

그림 9는 흰색 차선 시각화 프로세스, 그림 10은 관심 영역설정과 흰색 차선 추출, 그림 11은 ROI 설정과 RGB색 변경, 그림 12는 결과 차선검출 화면을 나타낸다.

<img src="/assets\img\autodriving\yolo\fig9.png">
<img src="/assets/img/autodriving/yolo/fig10.png">
<img src="/assets/img/autodriving/yolo/fig11.png">
<img src="/assets/img/autodriving/yolo/fig12.png">

그림9의 차선 시각화라 함은 이미지의 노출이나 밝기 등을 조절하여 찾기 쉽도록 설정하는 것이고, 그림 10은 차선이 있는 영역을 추출해서 그에 대한 흰색 차선 추출, 그림 11은 관심 영역 추출이라는 것이 흰색 차선 부분만 출력한다는 말인 듯하고, 이를 통해 추출된 흰색 차선을 RGB 색상으로 변경하였고, 그림12는 검출된 차선을 원본 이미지에 오버레이한 것이다.

<br>

## 2. 데이터 셋 생성 및 데이터 증각

데이터 증강을 위해, 수집한 데이터에 ImageDataGenerator 클래스를 활용해서, CNN을 통해 차선 검출 과정 이미지를 분류하고, 이 이미지를 데이터셋으로 생성했다.

<br>

<br>

## reference

- [YOLO based lane detection system](https://dasd.asdnm)
- [darknet 참고 자료](https://leejw0083.tistory.com/entry/Darknet-YOLO-%EB%9E%80)